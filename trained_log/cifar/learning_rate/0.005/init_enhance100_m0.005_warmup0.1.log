results_path : None
log_path : ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance_m0.005_warmup0.1.log
norm : True
ft_interval_weight : 50
model_name : init_enhance_m0.005_warmup0.1
n_pruning_steps : 1
enhance_learning_rate : 0.1
enhance_method : nat
transfer : False
schedule_length : 10
learning_rate : 0.1
init : True
init_path : ./trained_models_new/cifar/vgg16/init/pure_vgg16_init.pth
model_type : vgg16
init_type : pure
max_pruning_ratio : 80
batch_size : 64
mask_path : ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/pruned_lr0.005_mask_r80.npy
early_stop : 100
verbose : 200
finetune_method : nat
starting_epsilon : 1e-05
prune_method : unstructured
test_batch_size : 100
create_init : False
model_path : ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance_m0.005_warmup0.1.pth
trades_beta : 6.0
train_method : nat
last_model_path : ./trained_models_new/
seed : 7
noise_sd : 1.0
n_classes : 10
eps_step : 0.00784313725490196
warmup : True
enhance_epochs : None
interval_weight : 0.1
gpu : 3
clip_max : 1.0
dataset : cifar
weight_decay : 0.0001
parallel : False
mask_name : pruned_lr0.005_mask_r80
attack_iter : 10
init_step : 1400
clip_min : 0
train_epochs : 100
epsilon : 0.03137254901960784
targeted : False
optm : sgd
resume : 0
model_width : 8
eval : False
CUDA enabled.
Enhance training config:
Enhance training method: nat
model will be saved in: ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance_m0.005_warmup0.1.pth
Init model is: ./trained_models_new/cifar/vgg16/init/pure_vgg16_init.pth
Init mask used from: ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/pruned_lr0.005_mask_r80.npy
Log will be saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance_m0.005_warmup0.1.log
Random seed is: 7

model loading from ./trained_models_new/cifar/vgg16/init/pure_vgg16_init.pth
Epoch [0/100]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 2.2123, training acc = 0.28
Batch [200/704] training loss = 1.0278, training acc = 0.75
Batch [400/704] training loss = 1.0272, training acc = 0.62
Batch [600/704] training loss = 0.4524, training acc = 0.84
Valid Test with nat
Test accuracy: 79.26% (3963/5000), Test loss:0.6115
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance_m0.005_warmup0.1.pth
Test on test set:
Test accuracy: 79.69% (7969/10000), Test loss:0.6042
Epoch [1/100], Passed time:[126.817/126.817]
learning rate: 0.020000000000000004
Batch [0/704] training loss = 0.4721, training acc = 0.86
Batch [200/704] training loss = 0.4876, training acc = 0.84
Batch [400/704] training loss = 0.6272, training acc = 0.81
Batch [600/704] training loss = 0.6459, training acc = 0.80
Valid Test with nat
Test accuracy: 75.42% (3771/5000), Test loss:0.7836
Epoch [2/100], Passed time:[124.723/249.445]
learning rate: 0.030000000000000006
Batch [0/704] training loss = 0.4480, training acc = 0.84
Batch [200/704] training loss = 0.6535, training acc = 0.77
Batch [400/704] training loss = 0.4022, training acc = 0.88
Batch [600/704] training loss = 0.6015, training acc = 0.81
Valid Test with nat
Test accuracy: 80.26% (4013/5000), Test loss:0.6157
Epoch [3/100], Passed time:[123.357/370.070]
learning rate: 0.04000000000000001
Batch [0/704] training loss = 0.4965, training acc = 0.86
Batch [200/704] training loss = 0.3716, training acc = 0.86
Batch [400/704] training loss = 0.7094, training acc = 0.75
Batch [600/704] training loss = 0.4849, training acc = 0.86
Valid Test with nat
Test accuracy: 79.78% (3989/5000), Test loss:0.6485
Epoch [4/100], Passed time:[122.753/491.013]
learning rate: 0.05
Batch [0/704] training loss = 0.7266, training acc = 0.78
Batch [200/704] training loss = 0.8792, training acc = 0.75
Batch [400/704] training loss = 0.3947, training acc = 0.88
Batch [600/704] training loss = 0.4340, training acc = 0.84
Valid Test with nat
Test accuracy: 80.08% (4004/5000), Test loss:0.6014
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance_m0.005_warmup0.1.pth
Test on test set:
Test accuracy: 79.43% (7943/10000), Test loss:0.6317
Epoch [5/100], Passed time:[123.645/618.224]
learning rate: 0.06000000000000001
Batch [0/704] training loss = 0.2697, training acc = 0.92
Batch [200/704] training loss = 0.5108, training acc = 0.83
Batch [400/704] training loss = 0.5568, training acc = 0.86
Batch [600/704] training loss = 0.5928, training acc = 0.80
Valid Test with nat
Test accuracy: 82.00% (4100/5000), Test loss:0.5445
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance_m0.005_warmup0.1.pth
Test on test set:
Test accuracy: 82.72% (8272/10000), Test loss:0.5381
Epoch [6/100], Passed time:[124.153/744.916]
learning rate: 0.07
Batch [0/704] training loss = 0.3571, training acc = 0.91
Batch [200/704] training loss = 0.4040, training acc = 0.89
Batch [400/704] training loss = 0.4347, training acc = 0.80
Batch [600/704] training loss = 0.5187, training acc = 0.84
Valid Test with nat
Test accuracy: 84.18% (4209/5000), Test loss:0.4779
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance_m0.005_warmup0.1.pth
Test on test set:
Test accuracy: 83.11% (8311/10000), Test loss:0.5124
Epoch [7/100], Passed time:[124.739/873.172]
learning rate: 0.08000000000000002
Batch [0/704] training loss = 0.3813, training acc = 0.83
Batch [200/704] training loss = 0.3295, training acc = 0.86
Batch [400/704] training loss = 0.6113, training acc = 0.77
Batch [600/704] training loss = 0.5872, training acc = 0.83
Valid Test with nat
Test accuracy: 79.80% (3990/5000), Test loss:0.6260
Epoch [8/100], Passed time:[123.712/989.696]
learning rate: 0.09000000000000001
Batch [0/704] training loss = 0.4481, training acc = 0.86
Batch [200/704] training loss = 0.5563, training acc = 0.86
Batch [400/704] training loss = 0.3036, training acc = 0.88
Batch [600/704] training loss = 0.4076, training acc = 0.86
Valid Test with nat
Test accuracy: 81.42% (4071/5000), Test loss:0.5791
Epoch [9/100], Passed time:[123.925/1115.326]
learning rate: 0.1
Batch [0/704] training loss = 0.3514, training acc = 0.92
Batch [200/704] training loss = 0.3585, training acc = 0.91
Batch [400/704] training loss = 0.4705, training acc = 0.86
Batch [600/704] training loss = 0.5435, training acc = 0.81
Valid Test with nat
Test accuracy: 82.76% (4138/5000), Test loss:0.5355
Epoch [10/100], Passed time:[123.722/1237.223]
learning rate: 0.1
Batch [0/704] training loss = 0.4813, training acc = 0.86
Batch [200/704] training loss = 0.5110, training acc = 0.86
Batch [400/704] training loss = 0.4263, training acc = 0.86
Batch [600/704] training loss = 0.4487, training acc = 0.88
Valid Test with nat
Test accuracy: 81.86% (4093/5000), Test loss:0.5540
Epoch [11/100], Passed time:[123.415/1357.561]
learning rate: 0.1
Batch [0/704] training loss = 0.3720, training acc = 0.88
Batch [200/704] training loss = 0.2642, training acc = 0.92
Batch [400/704] training loss = 0.4825, training acc = 0.81
Batch [600/704] training loss = 0.3249, training acc = 0.86
Valid Test with nat
Test accuracy: 81.40% (4070/5000), Test loss:0.5724
Epoch [12/100], Passed time:[123.466/1481.595]
learning rate: 0.1
Batch [0/704] training loss = 0.3018, training acc = 0.92
Batch [200/704] training loss = 0.5238, training acc = 0.83
Batch [400/704] training loss = 0.3875, training acc = 0.84
Batch [600/704] training loss = 0.4353, training acc = 0.84
Valid Test with nat
Test accuracy: 83.14% (4157/5000), Test loss:0.5630
Epoch [13/100], Passed time:[123.329/1603.273]
learning rate: 0.1
Batch [0/704] training loss = 0.3755, training acc = 0.89
Batch [200/704] training loss = 0.2735, training acc = 0.91
Batch [400/704] training loss = 0.4015, training acc = 0.84
Batch [600/704] training loss = 0.4042, training acc = 0.84
Valid Test with nat
Test accuracy: 84.96% (4248/5000), Test loss:0.4648
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance_m0.005_warmup0.1.pth
Test on test set:
Test accuracy: 84.77% (8477/10000), Test loss:0.4605
Epoch [14/100], Passed time:[123.679/1731.500]
learning rate: 0.1
Batch [0/704] training loss = 0.2677, training acc = 0.92
Batch [200/704] training loss = 0.4455, training acc = 0.88
Batch [400/704] training loss = 0.5851, training acc = 0.83
Batch [600/704] training loss = 0.2720, training acc = 0.92
Valid Test with nat
Test accuracy: 85.26% (4263/5000), Test loss:0.4656
Epoch [15/100], Passed time:[123.616/1854.234]
learning rate: 0.1
Batch [0/704] training loss = 0.1903, training acc = 0.95
Batch [200/704] training loss = 0.3469, training acc = 0.86
Batch [400/704] training loss = 0.3335, training acc = 0.92
Batch [600/704] training loss = 0.4743, training acc = 0.84
Valid Test with nat
Test accuracy: 84.42% (4221/5000), Test loss:0.4695
Epoch [16/100], Passed time:[123.686/1978.975]
learning rate: 0.1
Batch [0/704] training loss = 0.2832, training acc = 0.89
Batch [200/704] training loss = 0.4805, training acc = 0.84
Batch [400/704] training loss = 0.4526, training acc = 0.83
Batch [600/704] training loss = 0.2771, training acc = 0.94
Valid Test with nat
Test accuracy: 82.62% (4131/5000), Test loss:0.5460
Epoch [17/100], Passed time:[123.756/2103.860]
learning rate: 0.1
Batch [0/704] training loss = 0.4806, training acc = 0.88
Batch [200/704] training loss = 0.3493, training acc = 0.83
Batch [400/704] training loss = 0.4675, training acc = 0.91
Batch [600/704] training loss = 0.3159, training acc = 0.88
Valid Test with nat
Test accuracy: 84.52% (4226/5000), Test loss:0.4811
Epoch [18/100], Passed time:[123.651/2225.725]
learning rate: 0.1
Batch [0/704] training loss = 0.3796, training acc = 0.84
Batch [200/704] training loss = 0.2594, training acc = 0.92
Batch [400/704] training loss = 0.3741, training acc = 0.89
Batch [600/704] training loss = 0.3907, training acc = 0.83
Valid Test with nat
Test accuracy: 84.74% (4237/5000), Test loss:0.4821
Epoch [19/100], Passed time:[123.646/2349.279]
learning rate: 0.1
Batch [0/704] training loss = 0.4753, training acc = 0.84
Batch [200/704] training loss = 0.4574, training acc = 0.84
Batch [400/704] training loss = 0.4466, training acc = 0.86
Batch [600/704] training loss = 0.5106, training acc = 0.86
Valid Test with nat
Test accuracy: 85.22% (4261/5000), Test loss:0.4558
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance_m0.005_warmup0.1.pth
Test on test set:
Test accuracy: 85.32% (8532/10000), Test loss:0.4447
Epoch [20/100], Passed time:[123.647/2472.945]
learning rate: 0.1
Batch [0/704] training loss = 0.3723, training acc = 0.86
Batch [200/704] training loss = 0.3825, training acc = 0.89
Batch [400/704] training loss = 0.5006, training acc = 0.83
Batch [600/704] training loss = 0.4611, training acc = 0.86
Valid Test with nat
Test accuracy: 85.72% (4286/5000), Test loss:0.4589
Epoch [21/100], Passed time:[123.734/2598.404]
learning rate: 0.1
Batch [0/704] training loss = 0.4215, training acc = 0.89
Batch [200/704] training loss = 0.5957, training acc = 0.83
Batch [400/704] training loss = 0.1689, training acc = 0.95
Batch [600/704] training loss = 0.2708, training acc = 0.92
Valid Test with nat
Test accuracy: 85.56% (4278/5000), Test loss:0.4492
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance_m0.005_warmup0.1.pth
Test on test set:
Test accuracy: 86.08% (8608/10000), Test loss:0.4235
Epoch [22/100], Passed time:[122.540/2695.875]
learning rate: 0.1
Batch [0/704] training loss = 0.2612, training acc = 0.91
Batch [200/704] training loss = 0.4072, training acc = 0.89
Batch [400/704] training loss = 0.2471, training acc = 0.94
Batch [600/704] training loss = 0.2791, training acc = 0.95
Valid Test with nat
Test accuracy: 83.66% (4183/5000), Test loss:0.5158
Epoch [23/100], Passed time:[121.242/2788.570]
learning rate: 0.1
Batch [0/704] training loss = 0.2824, training acc = 0.88
Batch [200/704] training loss = 0.2962, training acc = 0.91
Batch [400/704] training loss = 0.3473, training acc = 0.89
Batch [600/704] training loss = 0.2321, training acc = 0.91
Valid Test with nat
Test accuracy: 84.28% (4214/5000), Test loss:0.5017
Epoch [24/100], Passed time:[119.959/2879.008]
learning rate: 0.1
Batch [0/704] training loss = 0.4076, training acc = 0.83
Batch [200/704] training loss = 0.2201, training acc = 0.92
Batch [400/704] training loss = 0.2715, training acc = 0.92
Batch [600/704] training loss = 0.3641, training acc = 0.89
Valid Test with nat
Test accuracy: 85.12% (4256/5000), Test loss:0.4543
Epoch [25/100], Passed time:[118.817/2970.416]
learning rate: 0.1
Batch [0/704] training loss = 0.2329, training acc = 0.94
Batch [200/704] training loss = 0.4526, training acc = 0.88
Batch [400/704] training loss = 0.6154, training acc = 0.81
Batch [600/704] training loss = 0.3120, training acc = 0.86
Valid Test with nat
Test accuracy: 84.98% (4249/5000), Test loss:0.4786
Epoch [26/100], Passed time:[117.805/3062.934]
learning rate: 0.1
Batch [0/704] training loss = 0.1563, training acc = 0.95
Batch [200/704] training loss = 0.3346, training acc = 0.88
Batch [400/704] training loss = 0.3385, training acc = 0.89
Batch [600/704] training loss = 0.5437, training acc = 0.78
Valid Test with nat
Test accuracy: 84.62% (4231/5000), Test loss:0.4885
Epoch [27/100], Passed time:[115.583/3120.744]
learning rate: 0.1
Batch [0/704] training loss = 0.4968, training acc = 0.86
Batch [200/704] training loss = 0.2224, training acc = 0.95
Batch [400/704] training loss = 0.3582, training acc = 0.84
Batch [600/704] training loss = 0.5942, training acc = 0.83
Valid Test with nat
Test accuracy: 83.58% (4179/5000), Test loss:0.5279
Epoch [28/100], Passed time:[113.823/3187.058]
learning rate: 0.1
Batch [0/704] training loss = 0.2964, training acc = 0.92
Batch [200/704] training loss = 0.4409, training acc = 0.86
Batch [400/704] training loss = 0.2470, training acc = 0.91
Batch [600/704] training loss = 0.1656, training acc = 0.95
Valid Test with nat
Test accuracy: 84.58% (4229/5000), Test loss:0.4641
Epoch [29/100], Passed time:[112.501/3262.543]
learning rate: 0.1
Batch [0/704] training loss = 0.3286, training acc = 0.86
Batch [200/704] training loss = 0.3927, training acc = 0.78
Batch [400/704] training loss = 0.2888, training acc = 0.89
Batch [600/704] training loss = 0.4946, training acc = 0.80
Valid Test with nat
Test accuracy: 86.56% (4328/5000), Test loss:0.4046
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance_m0.005_warmup0.1.pth
Test on test set:
Test accuracy: 85.90% (8590/10000), Test loss:0.4135
Epoch [30/100], Passed time:[111.303/3339.084]
learning rate: 0.1
Batch [0/704] training loss = 0.3966, training acc = 0.86
Batch [200/704] training loss = 0.2098, training acc = 0.92
Batch [400/704] training loss = 0.2631, training acc = 0.91
Batch [600/704] training loss = 0.3666, training acc = 0.88
Valid Test with nat
Test accuracy: 85.14% (4257/5000), Test loss:0.4554
Epoch [31/100], Passed time:[110.142/3414.412]
learning rate: 0.1
Batch [0/704] training loss = 0.3622, training acc = 0.86
Batch [200/704] training loss = 0.3245, training acc = 0.89
Batch [400/704] training loss = 0.3893, training acc = 0.88
Batch [600/704] training loss = 0.5160, training acc = 0.77
Valid Test with nat
Test accuracy: 84.24% (4212/5000), Test loss:0.5327
Epoch [32/100], Passed time:[109.084/3490.675]
learning rate: 0.1
Batch [0/704] training loss = 0.1470, training acc = 0.97
Batch [200/704] training loss = 0.2907, training acc = 0.91
Batch [400/704] training loss = 0.4924, training acc = 0.81
Batch [600/704] training loss = 0.4478, training acc = 0.89
Valid Test with nat
Test accuracy: 85.32% (4266/5000), Test loss:0.4516
Epoch [33/100], Passed time:[108.065/3566.143]
learning rate: 0.1
Batch [0/704] training loss = 0.3254, training acc = 0.88
Batch [200/704] training loss = 0.4020, training acc = 0.89
Batch [400/704] training loss = 0.3160, training acc = 0.89
Batch [600/704] training loss = 0.3002, training acc = 0.88
Valid Test with nat
Test accuracy: 86.54% (4327/5000), Test loss:0.4314
Epoch [34/100], Passed time:[107.092/3641.115]
learning rate: 0.1
Batch [0/704] training loss = 0.2297, training acc = 0.94
Batch [200/704] training loss = 0.3075, training acc = 0.88
Batch [400/704] training loss = 0.5151, training acc = 0.84
Batch [600/704] training loss = 0.5686, training acc = 0.84
Valid Test with nat
Test accuracy: 86.14% (4307/5000), Test loss:0.4263
Epoch [35/100], Passed time:[106.183/3716.402]
learning rate: 0.1
Batch [0/704] training loss = 0.2012, training acc = 0.94
Batch [200/704] training loss = 0.2473, training acc = 0.88
Batch [400/704] training loss = 0.3563, training acc = 0.91
Batch [600/704] training loss = 0.2130, training acc = 0.98
Valid Test with nat
Test accuracy: 84.98% (4249/5000), Test loss:0.4918
Epoch [36/100], Passed time:[105.328/3791.824]
learning rate: 0.1
Batch [0/704] training loss = 0.3205, training acc = 0.92
Batch [200/704] training loss = 0.3495, training acc = 0.88
Batch [400/704] training loss = 0.2941, training acc = 0.91
Batch [600/704] training loss = 0.3153, training acc = 0.89
Valid Test with nat
Test accuracy: 85.94% (4297/5000), Test loss:0.4384
Epoch [37/100], Passed time:[104.493/3866.232]
learning rate: 0.1
Batch [0/704] training loss = 0.5376, training acc = 0.81
Batch [200/704] training loss = 0.5805, training acc = 0.83
Batch [400/704] training loss = 0.4329, training acc = 0.88
Batch [600/704] training loss = 0.4121, training acc = 0.88
Valid Test with nat
Test accuracy: 84.14% (4207/5000), Test loss:0.4790
Epoch [38/100], Passed time:[103.731/3941.771]
learning rate: 0.1
Batch [0/704] training loss = 0.3195, training acc = 0.95
Batch [200/704] training loss = 0.4398, training acc = 0.84
Batch [400/704] training loss = 0.2135, training acc = 0.92
Batch [600/704] training loss = 0.4310, training acc = 0.88
Valid Test with nat
Test accuracy: 85.50% (4275/5000), Test loss:0.4657
Epoch [39/100], Passed time:[103.059/4019.300]
learning rate: 0.1
Batch [0/704] training loss = 0.4494, training acc = 0.83
Batch [200/704] training loss = 0.3325, training acc = 0.89
Batch [400/704] training loss = 0.5577, training acc = 0.83
Batch [600/704] training loss = 0.2841, training acc = 0.89
Valid Test with nat
Test accuracy: 87.96% (4398/5000), Test loss:0.3759
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance_m0.005_warmup0.1.pth
Test on test set:
Test accuracy: 87.78% (8778/10000), Test loss:0.3783
Epoch [40/100], Passed time:[102.416/4096.642]
learning rate: 0.1
Batch [0/704] training loss = 0.0776, training acc = 0.98
Batch [200/704] training loss = 0.2729, training acc = 0.92
Batch [400/704] training loss = 0.3551, training acc = 0.89
Batch [600/704] training loss = 0.2564, training acc = 0.92
Valid Test with nat
Test accuracy: 84.96% (4248/5000), Test loss:0.4578
Epoch [41/100], Passed time:[101.548/4163.478]
learning rate: 0.1
Batch [0/704] training loss = 0.1992, training acc = 0.92
Batch [200/704] training loss = 0.1911, training acc = 0.91
Batch [400/704] training loss = 0.3490, training acc = 0.88
Batch [600/704] training loss = 0.3739, training acc = 0.88
Valid Test with nat
Test accuracy: 85.76% (4288/5000), Test loss:0.4358
Epoch [42/100], Passed time:[100.881/4236.995]
learning rate: 0.1
Batch [0/704] training loss = 0.1897, training acc = 0.92
Batch [200/704] training loss = 0.1836, training acc = 0.95
Batch [400/704] training loss = 0.3511, training acc = 0.88
Batch [600/704] training loss = 0.2741, training acc = 0.94
Valid Test with nat
Test accuracy: 84.80% (4240/5000), Test loss:0.4826
Epoch [43/100], Passed time:[100.300/4312.916]
learning rate: 0.1
Batch [0/704] training loss = 0.3945, training acc = 0.86
Batch [200/704] training loss = 0.2219, training acc = 0.94
Batch [400/704] training loss = 0.3163, training acc = 0.91
Batch [600/704] training loss = 0.1372, training acc = 0.97
Valid Test with nat
Test accuracy: 85.42% (4271/5000), Test loss:0.4562
Epoch [44/100], Passed time:[99.695/4386.589]
learning rate: 0.1
Batch [0/704] training loss = 0.2141, training acc = 0.94
Batch [200/704] training loss = 0.2300, training acc = 0.91
Batch [400/704] training loss = 0.4730, training acc = 0.88
Batch [600/704] training loss = 0.4144, training acc = 0.88
Valid Test with nat
Test accuracy: 83.12% (4156/5000), Test loss:0.5570
Epoch [45/100], Passed time:[99.163/4462.341]
learning rate: 0.1
Batch [0/704] training loss = 0.2619, training acc = 0.91
Batch [200/704] training loss = 0.4502, training acc = 0.83
Batch [400/704] training loss = 0.1972, training acc = 0.97
Batch [600/704] training loss = 0.5048, training acc = 0.86
Valid Test with nat
Test accuracy: 85.72% (4286/5000), Test loss:0.4632
Epoch [46/100], Passed time:[98.627/4536.862]
learning rate: 0.1
Batch [0/704] training loss = 0.2788, training acc = 0.91
Batch [200/704] training loss = 0.4190, training acc = 0.86
Batch [400/704] training loss = 0.6154, training acc = 0.83
Batch [600/704] training loss = 0.3639, training acc = 0.88
Valid Test with nat
Test accuracy: 84.60% (4230/5000), Test loss:0.5167
Epoch [47/100], Passed time:[98.151/4613.075]
learning rate: 0.1
Batch [0/704] training loss = 0.0995, training acc = 0.97
Batch [200/704] training loss = 0.3836, training acc = 0.91
Batch [400/704] training loss = 0.3331, training acc = 0.86
Batch [600/704] training loss = 0.3252, training acc = 0.88
Valid Test with nat
Test accuracy: 87.14% (4357/5000), Test loss:0.4131
Epoch [48/100], Passed time:[97.689/4689.092]
learning rate: 0.1
Batch [0/704] training loss = 0.1804, training acc = 0.94
Batch [200/704] training loss = 0.1535, training acc = 0.95
Batch [400/704] training loss = 0.3483, training acc = 0.86
Batch [600/704] training loss = 0.2517, training acc = 0.94
Valid Test with nat
Test accuracy: 84.02% (4201/5000), Test loss:0.4858
Epoch [49/100], Passed time:[97.246/4765.053]
learning rate: 0.1
Batch [0/704] training loss = 0.2845, training acc = 0.91
Batch [200/704] training loss = 0.3204, training acc = 0.92
Batch [400/704] training loss = 0.3719, training acc = 0.86
Batch [600/704] training loss = 0.2235, training acc = 0.94
Valid Test with nat
Test accuracy: 86.40% (4320/5000), Test loss:0.4410
Epoch [50/100], Passed time:[96.765/4838.269]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.5269, training acc = 0.83
Batch [200/704] training loss = 0.2507, training acc = 0.91
Batch [400/704] training loss = 0.1270, training acc = 0.97
Batch [600/704] training loss = 0.1959, training acc = 0.92
Valid Test with nat
Test accuracy: 91.02% (4551/5000), Test loss:0.2767
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance_m0.005_warmup0.1.pth
Test on test set:
Test accuracy: 90.48% (9048/10000), Test loss:0.2911
Epoch [51/100], Passed time:[96.392/4916.006]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.1906, training acc = 0.92
Batch [200/704] training loss = 0.1958, training acc = 0.95
Batch [400/704] training loss = 0.1447, training acc = 0.94
Batch [600/704] training loss = 0.1045, training acc = 0.97
Valid Test with nat
Test accuracy: 91.60% (4580/5000), Test loss:0.2575
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance_m0.005_warmup0.1.pth
Test on test set:
Test accuracy: 91.24% (9124/10000), Test loss:0.2699
Epoch [52/100], Passed time:[96.049/4994.537]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.2178, training acc = 0.94
Batch [200/704] training loss = 0.1780, training acc = 0.94
Batch [400/704] training loss = 0.1946, training acc = 0.94
Batch [600/704] training loss = 0.1030, training acc = 0.97
Valid Test with nat
Test accuracy: 91.32% (4566/5000), Test loss:0.2689
Epoch [53/100], Passed time:[95.653/5069.601]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.2625, training acc = 0.92
Batch [200/704] training loss = 0.1804, training acc = 0.95
Batch [400/704] training loss = 0.1858, training acc = 0.91
Batch [600/704] training loss = 0.0860, training acc = 0.97
Valid Test with nat
Test accuracy: 91.88% (4594/5000), Test loss:0.2616
Epoch [54/100], Passed time:[95.267/5144.393]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0626, training acc = 0.98
Batch [200/704] training loss = 0.2274, training acc = 0.94
Batch [400/704] training loss = 0.1341, training acc = 0.95
Batch [600/704] training loss = 0.3273, training acc = 0.88
Valid Test with nat
Test accuracy: 91.96% (4598/5000), Test loss:0.2682
Epoch [55/100], Passed time:[94.868/5217.746]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0794, training acc = 0.98
Batch [200/704] training loss = 0.1889, training acc = 0.91
Batch [400/704] training loss = 0.0397, training acc = 1.00
Batch [600/704] training loss = 0.0816, training acc = 0.97
Valid Test with nat
Test accuracy: 91.80% (4590/5000), Test loss:0.2694
Epoch [56/100], Passed time:[94.513/5292.737]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.2694, training acc = 0.94
Batch [200/704] training loss = 0.0304, training acc = 1.00
Batch [400/704] training loss = 0.1981, training acc = 0.94
Batch [600/704] training loss = 0.0918, training acc = 0.97
Valid Test with nat
Test accuracy: 91.84% (4592/5000), Test loss:0.2705
Epoch [57/100], Passed time:[94.208/5369.834]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.1659, training acc = 0.92
Batch [200/704] training loss = 0.2135, training acc = 0.89
Batch [400/704] training loss = 0.2023, training acc = 0.89
Batch [600/704] training loss = 0.0840, training acc = 0.98
Valid Test with nat
Test accuracy: 91.78% (4589/5000), Test loss:0.2703
Epoch [58/100], Passed time:[93.894/5445.867]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.2266, training acc = 0.94
Batch [200/704] training loss = 0.0662, training acc = 0.98
Batch [400/704] training loss = 0.2142, training acc = 0.95
Batch [600/704] training loss = 0.2687, training acc = 0.94
Valid Test with nat
Test accuracy: 92.00% (4600/5000), Test loss:0.2710
Epoch [59/100], Passed time:[93.552/5519.563]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.2046, training acc = 0.91
Batch [200/704] training loss = 0.0330, training acc = 0.98
Batch [400/704] training loss = 0.1062, training acc = 0.95
Batch [600/704] training loss = 0.1321, training acc = 0.92
Valid Test with nat
Test accuracy: 91.90% (4595/5000), Test loss:0.2682
Epoch [60/100], Passed time:[93.241/5594.447]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.1046, training acc = 0.95
Batch [200/704] training loss = 0.0583, training acc = 0.95
Batch [400/704] training loss = 0.0646, training acc = 0.97
Batch [600/704] training loss = 0.0409, training acc = 0.98
Valid Test with nat
Test accuracy: 91.74% (4587/5000), Test loss:0.2674
Epoch [61/100], Passed time:[92.981/5671.865]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0524, training acc = 0.98
Batch [200/704] training loss = 0.1936, training acc = 0.95
Batch [400/704] training loss = 0.0346, training acc = 1.00
Batch [600/704] training loss = 0.1117, training acc = 0.95
Valid Test with nat
Test accuracy: 91.88% (4594/5000), Test loss:0.2890
Epoch [62/100], Passed time:[92.689/5746.749]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0775, training acc = 0.98
Batch [200/704] training loss = 0.0341, training acc = 0.98
Batch [400/704] training loss = 0.1190, training acc = 0.95
Batch [600/704] training loss = 0.0964, training acc = 0.98
Valid Test with nat
Test accuracy: 91.96% (4598/5000), Test loss:0.2781
Epoch [63/100], Passed time:[92.439/5823.669]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.1783, training acc = 0.92
Batch [200/704] training loss = 0.1572, training acc = 0.95
Batch [400/704] training loss = 0.1021, training acc = 0.98
Batch [600/704] training loss = 0.0693, training acc = 0.97
Valid Test with nat
Test accuracy: 91.86% (4593/5000), Test loss:0.2895
Epoch [64/100], Passed time:[92.191/5900.199]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.1121, training acc = 0.98
Batch [200/704] training loss = 0.1081, training acc = 0.95
Batch [400/704] training loss = 0.0314, training acc = 1.00
Batch [600/704] training loss = 0.0832, training acc = 0.97
Valid Test with nat
Test accuracy: 92.00% (4600/5000), Test loss:0.2835
Epoch [65/100], Passed time:[91.927/5975.286]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.1151, training acc = 0.95
Batch [200/704] training loss = 0.0919, training acc = 0.95
Batch [400/704] training loss = 0.0404, training acc = 1.00
Batch [600/704] training loss = 0.2296, training acc = 0.92
Valid Test with nat
Test accuracy: 92.08% (4604/5000), Test loss:0.2771
Epoch [66/100], Passed time:[91.725/6053.821]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0411, training acc = 0.97
Batch [200/704] training loss = 0.0391, training acc = 1.00
Batch [400/704] training loss = 0.0281, training acc = 1.00
Batch [600/704] training loss = 0.1099, training acc = 0.97
Valid Test with nat
Test accuracy: 92.16% (4608/5000), Test loss:0.2899
Epoch [67/100], Passed time:[91.478/6128.998]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.1879, training acc = 0.94
Batch [200/704] training loss = 0.0993, training acc = 0.97
Batch [400/704] training loss = 0.0436, training acc = 0.97
Batch [600/704] training loss = 0.0872, training acc = 0.97
Valid Test with nat
Test accuracy: 92.14% (4607/5000), Test loss:0.2910
Epoch [68/100], Passed time:[91.248/6204.861]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0295, training acc = 1.00
Batch [200/704] training loss = 0.0908, training acc = 0.97
Batch [400/704] training loss = 0.1184, training acc = 0.95
Batch [600/704] training loss = 0.1065, training acc = 0.97
Valid Test with nat
Test accuracy: 91.64% (4582/5000), Test loss:0.2936
Epoch [69/100], Passed time:[91.039/6281.658]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.1702, training acc = 0.94
Batch [200/704] training loss = 0.0186, training acc = 1.00
Batch [400/704] training loss = 0.1406, training acc = 0.95
Batch [600/704] training loss = 0.1478, training acc = 0.97
Valid Test with nat
Test accuracy: 92.22% (4611/5000), Test loss:0.2845
Epoch [70/100], Passed time:[90.789/6355.224]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0319, training acc = 1.00
Batch [200/704] training loss = 0.1484, training acc = 0.95
Batch [400/704] training loss = 0.1612, training acc = 0.97
Batch [600/704] training loss = 0.1164, training acc = 0.95
Valid Test with nat
Test accuracy: 91.82% (4591/5000), Test loss:0.2958
Epoch [71/100], Passed time:[90.573/6430.677]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0584, training acc = 0.98
Batch [200/704] training loss = 0.0274, training acc = 1.00
Batch [400/704] training loss = 0.0678, training acc = 0.98
Batch [600/704] training loss = 0.0592, training acc = 0.98
Valid Test with nat
Test accuracy: 91.76% (4588/5000), Test loss:0.2945
Epoch [72/100], Passed time:[90.390/6508.058]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.1218, training acc = 0.94
Batch [200/704] training loss = 0.1612, training acc = 0.97
Batch [400/704] training loss = 0.0804, training acc = 0.97
Batch [600/704] training loss = 0.0875, training acc = 0.95
Valid Test with nat
Test accuracy: 91.88% (4594/5000), Test loss:0.2847
Epoch [73/100], Passed time:[90.170/6582.444]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0776, training acc = 0.97
Batch [200/704] training loss = 0.0445, training acc = 0.98
Batch [400/704] training loss = 0.1733, training acc = 0.95
Batch [600/704] training loss = 0.0786, training acc = 0.95
Valid Test with nat
Test accuracy: 91.96% (4598/5000), Test loss:0.3012
Epoch [74/100], Passed time:[89.982/6658.654]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0767, training acc = 0.97
Batch [200/704] training loss = 0.1023, training acc = 0.95
Batch [400/704] training loss = 0.0523, training acc = 0.98
Batch [600/704] training loss = 0.0096, training acc = 1.00
Valid Test with nat
Test accuracy: 92.00% (4600/5000), Test loss:0.2971
Epoch [75/100], Passed time:[89.804/6735.334]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0318, training acc = 0.98
Batch [200/704] training loss = 0.0686, training acc = 0.98
Batch [400/704] training loss = 0.1164, training acc = 0.97
Batch [600/704] training loss = 0.0347, training acc = 0.98
Valid Test with nat
Test accuracy: 92.22% (4611/5000), Test loss:0.2803
Epoch [76/100], Passed time:[89.614/6810.656]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0259, training acc = 0.98
Batch [200/704] training loss = 0.0931, training acc = 0.95
Batch [400/704] training loss = 0.0605, training acc = 0.97
Batch [600/704] training loss = 0.0640, training acc = 0.97
Valid Test with nat
Test accuracy: 92.30% (4615/5000), Test loss:0.2879
Epoch [77/100], Passed time:[89.425/6885.757]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0703, training acc = 0.98
Batch [200/704] training loss = 0.0230, training acc = 0.98
Batch [400/704] training loss = 0.0125, training acc = 1.00
Batch [600/704] training loss = 0.0294, training acc = 0.98
Valid Test with nat
Test accuracy: 92.38% (4619/5000), Test loss:0.2818
Epoch [78/100], Passed time:[89.261/6962.384]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0554, training acc = 0.97
Batch [200/704] training loss = 0.0547, training acc = 0.97
Batch [400/704] training loss = 0.0317, training acc = 0.98
Batch [600/704] training loss = 0.0447, training acc = 0.98
Valid Test with nat
Test accuracy: 92.44% (4622/5000), Test loss:0.2855
Epoch [79/100], Passed time:[89.077/7037.048]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0174, training acc = 1.00
Batch [200/704] training loss = 0.0194, training acc = 1.00
Batch [400/704] training loss = 0.0265, training acc = 0.98
Batch [600/704] training loss = 0.0394, training acc = 0.97
Valid Test with nat
Test accuracy: 92.38% (4619/5000), Test loss:0.2906
Epoch [80/100], Passed time:[88.890/7111.173]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0519, training acc = 0.97
Batch [200/704] training loss = 0.0310, training acc = 1.00
Batch [400/704] training loss = 0.0623, training acc = 0.97
Batch [600/704] training loss = 0.0796, training acc = 0.97
Valid Test with nat
Test accuracy: 92.42% (4621/5000), Test loss:0.2964
Epoch [81/100], Passed time:[88.719/7186.249]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0314, training acc = 0.98
Batch [200/704] training loss = 0.0435, training acc = 0.98
Batch [400/704] training loss = 0.0508, training acc = 0.98
Batch [600/704] training loss = 0.0170, training acc = 1.00
Valid Test with nat
Test accuracy: 92.34% (4617/5000), Test loss:0.3017
Epoch [82/100], Passed time:[88.544/7260.633]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0318, training acc = 0.98
Batch [200/704] training loss = 0.1676, training acc = 0.92
Batch [400/704] training loss = 0.0202, training acc = 1.00
Batch [600/704] training loss = 0.0742, training acc = 0.95
Valid Test with nat
Test accuracy: 92.42% (4621/5000), Test loss:0.2816
Epoch [83/100], Passed time:[88.370/7334.732]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0112, training acc = 1.00
Batch [200/704] training loss = 0.0486, training acc = 0.98
Batch [400/704] training loss = 0.0170, training acc = 1.00
Batch [600/704] training loss = 0.0354, training acc = 0.98
Valid Test with nat
Test accuracy: 92.38% (4619/5000), Test loss:0.2965
Epoch [84/100], Passed time:[88.239/7412.116]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0180, training acc = 1.00
Batch [200/704] training loss = 0.0136, training acc = 1.00
Batch [400/704] training loss = 0.0168, training acc = 1.00
Batch [600/704] training loss = 0.0697, training acc = 0.97
Valid Test with nat
Test accuracy: 92.42% (4621/5000), Test loss:0.2875
Epoch [85/100], Passed time:[88.071/7486.043]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0759, training acc = 0.97
Batch [200/704] training loss = 0.0247, training acc = 0.98
Batch [400/704] training loss = 0.0151, training acc = 1.00
Batch [600/704] training loss = 0.1421, training acc = 0.97
Valid Test with nat
Test accuracy: 92.44% (4622/5000), Test loss:0.2844
Epoch [86/100], Passed time:[87.918/7560.937]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0637, training acc = 0.97
Batch [200/704] training loss = 0.0509, training acc = 0.98
Batch [400/704] training loss = 0.1154, training acc = 0.95
Batch [600/704] training loss = 0.1023, training acc = 0.98
Valid Test with nat
Test accuracy: 92.16% (4608/5000), Test loss:0.2957
Epoch [87/100], Passed time:[87.781/7636.984]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0530, training acc = 0.98
Batch [200/704] training loss = 0.0182, training acc = 1.00
Batch [400/704] training loss = 0.0152, training acc = 1.00
Batch [600/704] training loss = 0.0059, training acc = 1.00
Valid Test with nat
Test accuracy: 92.30% (4615/5000), Test loss:0.2853
Epoch [88/100], Passed time:[87.634/7711.773]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.1077, training acc = 0.98
Batch [200/704] training loss = 0.0360, training acc = 0.98
Batch [400/704] training loss = 0.0143, training acc = 1.00
Batch [600/704] training loss = 0.0112, training acc = 1.00
Valid Test with nat
Test accuracy: 92.42% (4621/5000), Test loss:0.2886
Epoch [89/100], Passed time:[87.529/7790.078]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0174, training acc = 1.00
Batch [200/704] training loss = 0.1247, training acc = 0.95
Batch [400/704] training loss = 0.0560, training acc = 0.98
Batch [600/704] training loss = 0.0491, training acc = 0.98
Valid Test with nat
Test accuracy: 92.62% (4631/5000), Test loss:0.2830
Epoch [90/100], Passed time:[87.390/7865.113]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0066, training acc = 1.00
Batch [200/704] training loss = 0.0522, training acc = 0.98
Batch [400/704] training loss = 0.0510, training acc = 0.97
Batch [600/704] training loss = 0.0562, training acc = 0.98
Valid Test with nat
Test accuracy: 92.44% (4622/5000), Test loss:0.2860
Epoch [91/100], Passed time:[87.270/7941.555]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0565, training acc = 0.98
Batch [200/704] training loss = 0.0902, training acc = 0.97
Batch [400/704] training loss = 0.0318, training acc = 0.98
Batch [600/704] training loss = 0.0501, training acc = 0.98
Valid Test with nat
Test accuracy: 92.44% (4622/5000), Test loss:0.2898
Epoch [92/100], Passed time:[87.152/8017.950]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0155, training acc = 1.00
Batch [200/704] training loss = 0.0052, training acc = 1.00
Batch [400/704] training loss = 0.0114, training acc = 1.00
Batch [600/704] training loss = 0.0726, training acc = 0.98
Valid Test with nat
Test accuracy: 92.42% (4621/5000), Test loss:0.3022
Epoch [93/100], Passed time:[87.034/8094.173]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0410, training acc = 0.97
Batch [200/704] training loss = 0.0693, training acc = 0.97
Batch [400/704] training loss = 0.0725, training acc = 0.97
Batch [600/704] training loss = 0.0145, training acc = 1.00
Valid Test with nat
Test accuracy: 92.36% (4618/5000), Test loss:0.2893
Epoch [94/100], Passed time:[86.939/8172.238]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0151, training acc = 1.00
Batch [200/704] training loss = 0.0415, training acc = 0.98
Batch [400/704] training loss = 0.0941, training acc = 0.97
Batch [600/704] training loss = 0.1014, training acc = 0.97
Valid Test with nat
Test accuracy: 92.32% (4616/5000), Test loss:0.2949
Epoch [95/100], Passed time:[86.810/8246.953]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0467, training acc = 0.97
Batch [200/704] training loss = 0.0513, training acc = 0.98
Batch [400/704] training loss = 0.1105, training acc = 0.97
Batch [600/704] training loss = 0.0971, training acc = 0.98
Valid Test with nat
Test accuracy: 92.36% (4618/5000), Test loss:0.2908
Epoch [96/100], Passed time:[86.693/8322.566]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0169, training acc = 1.00
Batch [200/704] training loss = 0.0594, training acc = 0.97
Batch [400/704] training loss = 0.0345, training acc = 0.98
Batch [600/704] training loss = 0.0113, training acc = 1.00
Valid Test with nat
Test accuracy: 92.22% (4611/5000), Test loss:0.2911
Epoch [97/100], Passed time:[86.572/8397.523]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.1146, training acc = 0.97
Batch [200/704] training loss = 0.0104, training acc = 1.00
Batch [400/704] training loss = 0.0134, training acc = 1.00
Batch [600/704] training loss = 0.0141, training acc = 1.00
Valid Test with nat
Test accuracy: 92.36% (4618/5000), Test loss:0.2991
Epoch [98/100], Passed time:[86.456/8472.707]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0409, training acc = 0.98
Batch [200/704] training loss = 0.0265, training acc = 1.00
Batch [400/704] training loss = 0.1116, training acc = 0.97
Batch [600/704] training loss = 0.0208, training acc = 1.00
Valid Test with nat
Test accuracy: 92.26% (4613/5000), Test loss:0.2947
Epoch [99/100], Passed time:[86.356/8549.267]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0332, training acc = 0.98
Batch [200/704] training loss = 0.0253, training acc = 1.00
Batch [400/704] training loss = 0.0546, training acc = 0.97
Batch [600/704] training loss = 0.0092, training acc = 1.00
Valid Test with nat
Test accuracy: 92.50% (4625/5000), Test loss:0.2945
Training done, model saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance_m0.005_warmup0.1.pth
Test on test set:
Test accuracy: 92.16% (9216/10000), Test loss:0.3076
