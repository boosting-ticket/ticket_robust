model_type : vgg16
init_type : pure
finetune_method : nat
enhance_method : nat
gpu : 7
model_name : init_enhance80_m0.01_warmup0.1
model_width : 8
n_pruning_steps : 1
max_pruning_ratio : 80
train_epochs : 80
enhance_epochs : 80
prune_method : unstructured
dataset : cifar
noise_sd : 1.0
trades_beta : 6.0
seed : 7
warmup : True
parallel : False
create_init : False
init_step : 1400
train_method : nat
early_stop : 100
norm : True
optm : sgd
batch_size : 64
test_batch_size : 100
learning_rate : 0.1
enhance_learning_rate : 0.1
schedule_length : 10
weight_decay : 0.0001
epsilon : 0.03137254901960784
attack_iter : 10
eps_step : 0.00784313725490196
targeted : False
clip_min : 0
clip_max : 1.0
starting_epsilon : 1e-05
interval_weight : 0.1
ft_interval_weight : 50
verbose : 200
resume : 0
model_path : ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance80_m0.01_warmup0.1.pth
last_model_path : ./trained_models_new/
mask_path : ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/pruned_lr0.01_mask_r80.npy
mask_name : pruned_lr0.01_mask_r80
log_path : ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance80_m0.01_warmup0.1.log
init_path : ./trained_models_new/cifar/vgg16/init/pure_vgg16_init.pth
results_path : None
n_classes : 10
eval : False
init : True
transfer : False
CUDA enabled.
Enhance training config:
Enhance training method: nat
model will be saved in: ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance80_m0.01_warmup0.1.pth
Init model is: ./trained_models_new/cifar/vgg16/init/pure_vgg16_init.pth
Init mask used from: ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/pruned_lr0.01_mask_r80.npy
Log will be saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance80_m0.01_warmup0.1.log
Random seed is: 7

model loading from ./trained_models_new/cifar/vgg16/init/pure_vgg16_init.pth
Epoch [0/80]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 2.2271, training acc = 0.23
Batch [200/704] training loss = 0.8493, training acc = 0.72
Batch [400/704] training loss = 0.7813, training acc = 0.72
Batch [600/704] training loss = 0.3680, training acc = 0.92
Valid Test with nat
Test accuracy: 79.62% (3981/5000), Test loss:0.6161
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance80_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 79.33% (7933/10000), Test loss:0.6168
Epoch [1/80], Passed time:[76.025/76.025]
learning rate: 0.020000000000000004
Batch [0/704] training loss = 0.4874, training acc = 0.86
Batch [200/704] training loss = 0.5099, training acc = 0.83
Batch [400/704] training loss = 0.4325, training acc = 0.84
Batch [600/704] training loss = 0.4452, training acc = 0.84
Valid Test with nat
Test accuracy: 79.42% (3971/5000), Test loss:0.6335
Epoch [2/80], Passed time:[72.290/144.580]
learning rate: 0.030000000000000006
Batch [0/704] training loss = 0.5694, training acc = 0.83
Batch [200/704] training loss = 0.3927, training acc = 0.86
Batch [400/704] training loss = 0.3893, training acc = 0.84
Batch [600/704] training loss = 0.4414, training acc = 0.88
Valid Test with nat
Test accuracy: 78.62% (3931/5000), Test loss:0.6804
Epoch [3/80], Passed time:[71.795/215.384]
learning rate: 0.04000000000000001
Batch [0/704] training loss = 0.4459, training acc = 0.83
Batch [200/704] training loss = 0.3750, training acc = 0.88
Batch [400/704] training loss = 0.8838, training acc = 0.69
Batch [600/704] training loss = 0.4948, training acc = 0.83
Valid Test with nat
Test accuracy: 83.68% (4184/5000), Test loss:0.5022
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance80_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 83.92% (8392/10000), Test loss:0.4721
Epoch [4/80], Passed time:[72.350/289.399]
learning rate: 0.05
Batch [0/704] training loss = 0.4503, training acc = 0.83
Batch [200/704] training loss = 0.2520, training acc = 0.92
Batch [400/704] training loss = 0.2720, training acc = 0.89
Batch [600/704] training loss = 0.2813, training acc = 0.89
Valid Test with nat
Test accuracy: 84.42% (4221/5000), Test loss:0.4750
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance80_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 84.42% (8442/10000), Test loss:0.4702
Epoch [5/80], Passed time:[72.931/364.657]
learning rate: 0.06000000000000001
Batch [0/704] training loss = 0.3000, training acc = 0.91
Batch [200/704] training loss = 0.5319, training acc = 0.78
Batch [400/704] training loss = 0.3214, training acc = 0.86
Batch [600/704] training loss = 0.2513, training acc = 0.92
Valid Test with nat
Test accuracy: 80.60% (4030/5000), Test loss:0.6083
Epoch [6/80], Passed time:[72.136/432.816]
learning rate: 0.07
Batch [0/704] training loss = 0.1907, training acc = 0.92
Batch [200/704] training loss = 0.2668, training acc = 0.91
Batch [400/704] training loss = 0.3971, training acc = 0.86
Batch [600/704] training loss = 0.3318, training acc = 0.86
Valid Test with nat
Test accuracy: 82.26% (4113/5000), Test loss:0.5726
Epoch [7/80], Passed time:[71.425/499.977]
learning rate: 0.08000000000000002
Batch [0/704] training loss = 0.2235, training acc = 0.92
Batch [200/704] training loss = 0.5682, training acc = 0.75
Batch [400/704] training loss = 0.5117, training acc = 0.84
Batch [600/704] training loss = 0.2506, training acc = 0.91
Valid Test with nat
Test accuracy: 84.26% (4213/5000), Test loss:0.4954
Epoch [8/80], Passed time:[71.175/569.403]
learning rate: 0.09000000000000001
Batch [0/704] training loss = 0.5287, training acc = 0.81
Batch [200/704] training loss = 0.2179, training acc = 0.94
Batch [400/704] training loss = 0.4479, training acc = 0.83
Batch [600/704] training loss = 0.3521, training acc = 0.89
Valid Test with nat
Test accuracy: 83.54% (4177/5000), Test loss:0.5172
Epoch [9/80], Passed time:[71.065/639.583]
learning rate: 0.1
Batch [0/704] training loss = 0.5034, training acc = 0.89
Batch [200/704] training loss = 0.3683, training acc = 0.88
Batch [400/704] training loss = 0.3197, training acc = 0.89
Batch [600/704] training loss = 0.3669, training acc = 0.83
Valid Test with nat
Test accuracy: 82.38% (4119/5000), Test loss:0.5645
Epoch [10/80], Passed time:[71.216/712.160]
learning rate: 0.1
Batch [0/704] training loss = 0.5210, training acc = 0.80
Batch [200/704] training loss = 0.3047, training acc = 0.91
Batch [400/704] training loss = 0.3240, training acc = 0.94
Batch [600/704] training loss = 0.2878, training acc = 0.89
Valid Test with nat
Test accuracy: 85.02% (4251/5000), Test loss:0.4567
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance80_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 84.51% (8451/10000), Test loss:0.4858
Epoch [11/80], Passed time:[71.158/782.737]
learning rate: 0.1
Batch [0/704] training loss = 0.2688, training acc = 0.92
Batch [200/704] training loss = 0.4227, training acc = 0.89
Batch [400/704] training loss = 0.4579, training acc = 0.88
Batch [600/704] training loss = 0.3656, training acc = 0.88
Valid Test with nat
Test accuracy: 83.06% (4153/5000), Test loss:0.5225
Epoch [12/80], Passed time:[71.124/853.485]
learning rate: 0.1
Batch [0/704] training loss = 0.3320, training acc = 0.89
Batch [200/704] training loss = 0.5178, training acc = 0.83
Batch [400/704] training loss = 0.4693, training acc = 0.83
Batch [600/704] training loss = 0.4565, training acc = 0.81
Valid Test with nat
Test accuracy: 84.70% (4235/5000), Test loss:0.5161
Epoch [13/80], Passed time:[70.957/922.440]
learning rate: 0.1
Batch [0/704] training loss = 0.3405, training acc = 0.91
Batch [200/704] training loss = 0.3879, training acc = 0.88
Batch [400/704] training loss = 0.4398, training acc = 0.84
Batch [600/704] training loss = 0.2934, training acc = 0.86
Valid Test with nat
Test accuracy: 85.54% (4277/5000), Test loss:0.4376
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance80_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 85.46% (8546/10000), Test loss:0.4529
Epoch [14/80], Passed time:[70.970/993.584]
learning rate: 0.1
Batch [0/704] training loss = 0.2188, training acc = 0.91
Batch [200/704] training loss = 0.3151, training acc = 0.89
Batch [400/704] training loss = 0.4191, training acc = 0.84
Batch [600/704] training loss = 0.3577, training acc = 0.89
Valid Test with nat
Test accuracy: 84.88% (4244/5000), Test loss:0.5012
Epoch [15/80], Passed time:[70.706/1060.592]
learning rate: 0.1
Batch [0/704] training loss = 0.2731, training acc = 0.89
Batch [200/704] training loss = 0.2688, training acc = 0.91
Batch [400/704] training loss = 0.2783, training acc = 0.91
Batch [600/704] training loss = 0.4511, training acc = 0.81
Valid Test with nat
Test accuracy: 84.00% (4200/5000), Test loss:0.5195
Epoch [16/80], Passed time:[70.603/1129.650]
learning rate: 0.1
Batch [0/704] training loss = 0.3597, training acc = 0.91
Batch [200/704] training loss = 0.4944, training acc = 0.80
Batch [400/704] training loss = 0.3901, training acc = 0.86
Batch [600/704] training loss = 0.2683, training acc = 0.88
Valid Test with nat
Test accuracy: 82.92% (4146/5000), Test loss:0.5362
Epoch [17/80], Passed time:[70.481/1198.179]
learning rate: 0.1
Batch [0/704] training loss = 0.4573, training acc = 0.86
Batch [200/704] training loss = 0.2085, training acc = 0.94
Batch [400/704] training loss = 0.4862, training acc = 0.89
Batch [600/704] training loss = 0.4413, training acc = 0.81
Valid Test with nat
Test accuracy: 85.90% (4295/5000), Test loss:0.4368
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance80_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 85.93% (8593/10000), Test loss:0.4249
Epoch [18/80], Passed time:[70.580/1270.448]
learning rate: 0.1
Batch [0/704] training loss = 0.1646, training acc = 0.97
Batch [200/704] training loss = 0.3741, training acc = 0.88
Batch [400/704] training loss = 0.5028, training acc = 0.92
Batch [600/704] training loss = 0.3283, training acc = 0.89
Valid Test with nat
Test accuracy: 84.70% (4235/5000), Test loss:0.5152
Epoch [19/80], Passed time:[70.537/1340.210]
learning rate: 0.1
Batch [0/704] training loss = 0.3172, training acc = 0.86
Batch [200/704] training loss = 0.2921, training acc = 0.89
Batch [400/704] training loss = 0.2263, training acc = 0.92
Batch [600/704] training loss = 0.4058, training acc = 0.91
Valid Test with nat
Test accuracy: 84.32% (4216/5000), Test loss:0.5318
Epoch [20/80], Passed time:[70.586/1411.716]
learning rate: 0.1
Batch [0/704] training loss = 0.4509, training acc = 0.81
Batch [200/704] training loss = 0.2501, training acc = 0.92
Batch [400/704] training loss = 0.3932, training acc = 0.88
Batch [600/704] training loss = 0.3500, training acc = 0.92
Valid Test with nat
Test accuracy: 85.18% (4259/5000), Test loss:0.4686
Epoch [21/80], Passed time:[70.706/1484.831]
learning rate: 0.1
Batch [0/704] training loss = 0.3623, training acc = 0.91
Batch [200/704] training loss = 0.4924, training acc = 0.84
Batch [400/704] training loss = 0.2970, training acc = 0.91
Batch [600/704] training loss = 0.3173, training acc = 0.89
Valid Test with nat
Test accuracy: 84.60% (4230/5000), Test loss:0.4798
Epoch [22/80], Passed time:[70.574/1552.621]
learning rate: 0.1
Batch [0/704] training loss = 0.1366, training acc = 0.94
Batch [200/704] training loss = 0.3300, training acc = 0.89
Batch [400/704] training loss = 0.3309, training acc = 0.92
Batch [600/704] training loss = 0.3159, training acc = 0.92
Valid Test with nat
Test accuracy: 85.30% (4265/5000), Test loss:0.4642
Epoch [23/80], Passed time:[70.544/1622.501]
learning rate: 0.1
Batch [0/704] training loss = 0.3947, training acc = 0.86
Batch [200/704] training loss = 0.3784, training acc = 0.89
Batch [400/704] training loss = 0.3174, training acc = 0.86
Batch [600/704] training loss = 0.2914, training acc = 0.94
Valid Test with nat
Test accuracy: 82.16% (4108/5000), Test loss:0.5943
Epoch [24/80], Passed time:[70.437/1690.498]
learning rate: 0.1
Batch [0/704] training loss = 0.3042, training acc = 0.92
Batch [200/704] training loss = 0.3873, training acc = 0.86
Batch [400/704] training loss = 0.3393, training acc = 0.86
Batch [600/704] training loss = 0.4443, training acc = 0.84
Valid Test with nat
Test accuracy: 87.80% (4390/5000), Test loss:0.3868
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance80_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 87.11% (8711/10000), Test loss:0.3877
Epoch [25/80], Passed time:[70.482/1762.062]
learning rate: 0.1
Batch [0/704] training loss = 0.2305, training acc = 0.89
Batch [200/704] training loss = 0.1656, training acc = 0.92
Batch [400/704] training loss = 0.6332, training acc = 0.81
Batch [600/704] training loss = 0.2354, training acc = 0.94
Valid Test with nat
Test accuracy: 87.10% (4355/5000), Test loss:0.3941
Epoch [26/80], Passed time:[70.501/1833.039]
learning rate: 0.1
Batch [0/704] training loss = 0.2038, training acc = 0.92
Batch [200/704] training loss = 0.4021, training acc = 0.91
Batch [400/704] training loss = 0.3343, training acc = 0.92
Batch [600/704] training loss = 0.3765, training acc = 0.84
Valid Test with nat
Test accuracy: 85.14% (4257/5000), Test loss:0.4621
Epoch [27/80], Passed time:[70.504/1903.605]
learning rate: 0.1
Batch [0/704] training loss = 0.5213, training acc = 0.80
Batch [200/704] training loss = 0.2360, training acc = 0.91
Batch [400/704] training loss = 0.2704, training acc = 0.89
Batch [600/704] training loss = 0.5609, training acc = 0.84
Valid Test with nat
Test accuracy: 85.36% (4268/5000), Test loss:0.4629
Epoch [28/80], Passed time:[70.561/1975.712]
learning rate: 0.1
Batch [0/704] training loss = 0.3558, training acc = 0.89
Batch [200/704] training loss = 0.3584, training acc = 0.91
Batch [400/704] training loss = 0.3492, training acc = 0.89
Batch [600/704] training loss = 0.1440, training acc = 0.95
Valid Test with nat
Test accuracy: 87.30% (4365/5000), Test loss:0.3843
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance80_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 88.05% (8805/10000), Test loss:0.3775
Epoch [29/80], Passed time:[70.629/2048.237]
learning rate: 0.1
Batch [0/704] training loss = 0.3081, training acc = 0.91
Batch [200/704] training loss = 0.3945, training acc = 0.86
Batch [400/704] training loss = 0.4443, training acc = 0.81
Batch [600/704] training loss = 0.3362, training acc = 0.91
Valid Test with nat
Test accuracy: 86.44% (4322/5000), Test loss:0.4327
Epoch [30/80], Passed time:[70.613/2118.390]
learning rate: 0.1
Batch [0/704] training loss = 0.2906, training acc = 0.92
Batch [200/704] training loss = 0.2004, training acc = 0.94
Batch [400/704] training loss = 0.2854, training acc = 0.88
Batch [600/704] training loss = 0.2856, training acc = 0.88
Valid Test with nat
Test accuracy: 85.12% (4256/5000), Test loss:0.4643
Epoch [31/80], Passed time:[70.619/2189.193]
learning rate: 0.1
Batch [0/704] training loss = 0.4649, training acc = 0.83
Batch [200/704] training loss = 0.2942, training acc = 0.91
Batch [400/704] training loss = 0.2745, training acc = 0.92
Batch [600/704] training loss = 0.4247, training acc = 0.84
Valid Test with nat
Test accuracy: 85.42% (4271/5000), Test loss:0.4800
Epoch [32/80], Passed time:[70.401/2252.824]
learning rate: 0.1
Batch [0/704] training loss = 0.2758, training acc = 0.92
Batch [200/704] training loss = 0.4133, training acc = 0.86
Batch [400/704] training loss = 0.3161, training acc = 0.89
Batch [600/704] training loss = 0.4572, training acc = 0.84
Valid Test with nat
Test accuracy: 82.68% (4134/5000), Test loss:0.5500
Epoch [33/80], Passed time:[70.382/2322.594]
learning rate: 0.1
Batch [0/704] training loss = 0.2745, training acc = 0.88
Batch [200/704] training loss = 0.3009, training acc = 0.89
Batch [400/704] training loss = 0.2006, training acc = 0.91
Batch [600/704] training loss = 0.2666, training acc = 0.91
Valid Test with nat
Test accuracy: 85.78% (4289/5000), Test loss:0.4494
Epoch [34/80], Passed time:[70.389/2393.243]
learning rate: 0.1
Batch [0/704] training loss = 0.3119, training acc = 0.92
Batch [200/704] training loss = 0.3658, training acc = 0.88
Batch [400/704] training loss = 0.4288, training acc = 0.86
Batch [600/704] training loss = 0.2949, training acc = 0.89
Valid Test with nat
Test accuracy: 85.96% (4298/5000), Test loss:0.4513
Epoch [35/80], Passed time:[70.410/2464.353]
learning rate: 0.1
Batch [0/704] training loss = 0.3442, training acc = 0.88
Batch [200/704] training loss = 0.2516, training acc = 0.89
Batch [400/704] training loss = 0.2689, training acc = 0.92
Batch [600/704] training loss = 0.2200, training acc = 0.92
Valid Test with nat
Test accuracy: 87.02% (4351/5000), Test loss:0.4168
Epoch [36/80], Passed time:[70.403/2534.491]
learning rate: 0.1
Batch [0/704] training loss = 0.3354, training acc = 0.88
Batch [200/704] training loss = 0.2992, training acc = 0.92
Batch [400/704] training loss = 0.3121, training acc = 0.89
Batch [600/704] training loss = 0.2926, training acc = 0.86
Valid Test with nat
Test accuracy: 85.08% (4254/5000), Test loss:0.4612
Epoch [37/80], Passed time:[70.504/2608.664]
learning rate: 0.1
Batch [0/704] training loss = 0.4931, training acc = 0.83
Batch [200/704] training loss = 0.4677, training acc = 0.88
Batch [400/704] training loss = 0.2166, training acc = 0.92
Batch [600/704] training loss = 0.4790, training acc = 0.86
Valid Test with nat
Test accuracy: 85.00% (4250/5000), Test loss:0.4743
Epoch [38/80], Passed time:[70.383/2674.555]
learning rate: 0.1
Batch [0/704] training loss = 0.2579, training acc = 0.92
Batch [200/704] training loss = 0.2768, training acc = 0.86
Batch [400/704] training loss = 0.2957, training acc = 0.92
Batch [600/704] training loss = 0.3927, training acc = 0.89
Valid Test with nat
Test accuracy: 85.64% (4282/5000), Test loss:0.4795
Epoch [39/80], Passed time:[70.499/2749.480]
learning rate: 0.1
Batch [0/704] training loss = 0.5118, training acc = 0.86
Batch [200/704] training loss = 0.3713, training acc = 0.92
Batch [400/704] training loss = 0.2858, training acc = 0.92
Batch [600/704] training loss = 0.1919, training acc = 0.94
Valid Test with nat
Test accuracy: 87.52% (4376/5000), Test loss:0.3916
Epoch [40/80], Passed time:[70.473/2818.938]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.1043, training acc = 0.97
Batch [200/704] training loss = 0.1289, training acc = 0.95
Batch [400/704] training loss = 0.1668, training acc = 0.95
Batch [600/704] training loss = 0.2508, training acc = 0.92
Valid Test with nat
Test accuracy: 91.34% (4567/5000), Test loss:0.2922
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance80_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 91.14% (9114/10000), Test loss:0.2931
Epoch [41/80], Passed time:[70.542/2892.202]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0802, training acc = 0.97
Batch [200/704] training loss = 0.0750, training acc = 0.97
Batch [400/704] training loss = 0.2852, training acc = 0.91
Batch [600/704] training loss = 0.2471, training acc = 0.91
Valid Test with nat
Test accuracy: 91.38% (4569/5000), Test loss:0.2836
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance80_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 91.51% (9151/10000), Test loss:0.2795
Epoch [42/80], Passed time:[70.646/2967.120]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.2036, training acc = 0.92
Batch [200/704] training loss = 0.0746, training acc = 0.97
Batch [400/704] training loss = 0.1578, training acc = 0.95
Batch [600/704] training loss = 0.1430, training acc = 0.95
Valid Test with nat
Test accuracy: 91.30% (4565/5000), Test loss:0.2810
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance80_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 91.49% (9149/10000), Test loss:0.2748
Epoch [43/80], Passed time:[70.760/3042.688]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0431, training acc = 0.98
Batch [200/704] training loss = 0.1018, training acc = 0.98
Batch [400/704] training loss = 0.1312, training acc = 0.95
Batch [600/704] training loss = 0.1579, training acc = 0.97
Valid Test with nat
Test accuracy: 91.28% (4564/5000), Test loss:0.2856
Epoch [44/80], Passed time:[70.762/3113.521]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0489, training acc = 0.98
Batch [200/704] training loss = 0.1748, training acc = 0.97
Batch [400/704] training loss = 0.1641, training acc = 0.92
Batch [600/704] training loss = 0.1958, training acc = 0.95
Valid Test with nat
Test accuracy: 91.54% (4577/5000), Test loss:0.2781
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance80_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 91.51% (9151/10000), Test loss:0.2814
Epoch [45/80], Passed time:[70.823/3187.031]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.1150, training acc = 0.92
Batch [200/704] training loss = 0.0551, training acc = 0.98
Batch [400/704] training loss = 0.0963, training acc = 0.97
Batch [600/704] training loss = 0.1104, training acc = 0.97
Valid Test with nat
Test accuracy: 91.74% (4587/5000), Test loss:0.2788
Epoch [46/80], Passed time:[70.795/3256.591]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0942, training acc = 0.97
Batch [200/704] training loss = 0.1029, training acc = 0.97
Batch [400/704] training loss = 0.0515, training acc = 0.98
Batch [600/704] training loss = 0.1557, training acc = 0.94
Valid Test with nat
Test accuracy: 91.76% (4588/5000), Test loss:0.2847
Epoch [47/80], Passed time:[70.802/3327.714]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.2431, training acc = 0.91
Batch [200/704] training loss = 0.0602, training acc = 0.98
Batch [400/704] training loss = 0.1052, training acc = 0.97
Batch [600/704] training loss = 0.0571, training acc = 0.97
Valid Test with nat
Test accuracy: 91.80% (4590/5000), Test loss:0.2983
Epoch [48/80], Passed time:[70.775/3397.194]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.1015, training acc = 0.97
Batch [200/704] training loss = 0.0942, training acc = 0.98
Batch [400/704] training loss = 0.0843, training acc = 0.97
Batch [600/704] training loss = 0.0802, training acc = 0.98
Valid Test with nat
Test accuracy: 91.54% (4577/5000), Test loss:0.2835
Epoch [49/80], Passed time:[70.728/3465.659]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.1361, training acc = 0.94
Batch [200/704] training loss = 0.0172, training acc = 1.00
Batch [400/704] training loss = 0.1002, training acc = 0.95
Batch [600/704] training loss = 0.0711, training acc = 0.97
Valid Test with nat
Test accuracy: 91.58% (4579/5000), Test loss:0.2894
Epoch [50/80], Passed time:[70.683/3534.145]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0898, training acc = 0.98
Batch [200/704] training loss = 0.0328, training acc = 1.00
Batch [400/704] training loss = 0.0732, training acc = 0.97
Batch [600/704] training loss = 0.0575, training acc = 0.98
Valid Test with nat
Test accuracy: 91.82% (4591/5000), Test loss:0.2926
Epoch [51/80], Passed time:[70.644/3602.838]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0122, training acc = 1.00
Batch [200/704] training loss = 0.0748, training acc = 0.97
Batch [400/704] training loss = 0.1078, training acc = 0.98
Batch [600/704] training loss = 0.1376, training acc = 0.95
Valid Test with nat
Test accuracy: 91.84% (4592/5000), Test loss:0.2948
Epoch [52/80], Passed time:[70.607/3671.552]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.1270, training acc = 0.92
Batch [200/704] training loss = 0.1056, training acc = 0.95
Batch [400/704] training loss = 0.0484, training acc = 0.98
Batch [600/704] training loss = 0.0501, training acc = 0.98
Valid Test with nat
Test accuracy: 91.68% (4584/5000), Test loss:0.3020
Epoch [53/80], Passed time:[70.580/3740.764]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0871, training acc = 0.97
Batch [200/704] training loss = 0.0844, training acc = 0.98
Batch [400/704] training loss = 0.2511, training acc = 0.94
Batch [600/704] training loss = 0.0641, training acc = 0.97
Valid Test with nat
Test accuracy: 91.94% (4597/5000), Test loss:0.3050
Epoch [54/80], Passed time:[70.526/3808.412]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0556, training acc = 0.95
Batch [200/704] training loss = 0.0425, training acc = 0.98
Batch [400/704] training loss = 0.0438, training acc = 0.98
Batch [600/704] training loss = 0.0572, training acc = 0.98
Valid Test with nat
Test accuracy: 91.82% (4591/5000), Test loss:0.2967
Epoch [55/80], Passed time:[70.511/3878.086]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0357, training acc = 1.00
Batch [200/704] training loss = 0.0409, training acc = 1.00
Batch [400/704] training loss = 0.1616, training acc = 0.94
Batch [600/704] training loss = 0.1122, training acc = 0.98
Valid Test with nat
Test accuracy: 91.90% (4595/5000), Test loss:0.2964
Epoch [56/80], Passed time:[70.508/3948.424]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0464, training acc = 0.98
Batch [200/704] training loss = 0.0789, training acc = 0.98
Batch [400/704] training loss = 0.2028, training acc = 0.92
Batch [600/704] training loss = 0.0842, training acc = 0.95
Valid Test with nat
Test accuracy: 91.80% (4590/5000), Test loss:0.3102
Epoch [57/80], Passed time:[70.532/4020.340]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0804, training acc = 0.98
Batch [200/704] training loss = 0.2232, training acc = 0.94
Batch [400/704] training loss = 0.1214, training acc = 0.97
Batch [600/704] training loss = 0.1810, training acc = 0.94
Valid Test with nat
Test accuracy: 91.92% (4596/5000), Test loss:0.3015
Epoch [58/80], Passed time:[70.496/4088.768]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0916, training acc = 0.97
Batch [200/704] training loss = 0.0151, training acc = 1.00
Batch [400/704] training loss = 0.1122, training acc = 0.95
Batch [600/704] training loss = 0.0397, training acc = 0.98
Valid Test with nat
Test accuracy: 91.86% (4593/5000), Test loss:0.3023
Epoch [59/80], Passed time:[70.496/4159.246]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0634, training acc = 0.97
Batch [200/704] training loss = 0.0487, training acc = 0.98
Batch [400/704] training loss = 0.0709, training acc = 0.98
Batch [600/704] training loss = 0.0297, training acc = 0.98
Valid Test with nat
Test accuracy: 91.78% (4589/5000), Test loss:0.3165
Epoch [60/80], Passed time:[70.486/4229.183]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.1201, training acc = 0.97
Batch [200/704] training loss = 0.0242, training acc = 1.00
Batch [400/704] training loss = 0.2062, training acc = 0.91
Batch [600/704] training loss = 0.0355, training acc = 0.98
Valid Test with nat
Test accuracy: 92.14% (4607/5000), Test loss:0.3025
Epoch [61/80], Passed time:[70.469/4298.616]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0866, training acc = 0.95
Batch [200/704] training loss = 0.0539, training acc = 0.97
Batch [400/704] training loss = 0.0326, training acc = 0.98
Batch [600/704] training loss = 0.0952, training acc = 0.98
Valid Test with nat
Test accuracy: 92.10% (4605/5000), Test loss:0.2991
Epoch [62/80], Passed time:[70.396/4364.532]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0345, training acc = 0.98
Batch [200/704] training loss = 0.0539, training acc = 0.98
Batch [400/704] training loss = 0.0941, training acc = 0.95
Batch [600/704] training loss = 0.0396, training acc = 1.00
Valid Test with nat
Test accuracy: 92.14% (4607/5000), Test loss:0.2904
Epoch [63/80], Passed time:[70.377/4433.738]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0623, training acc = 0.98
Batch [200/704] training loss = 0.0158, training acc = 1.00
Batch [400/704] training loss = 0.0427, training acc = 0.98
Batch [600/704] training loss = 0.0338, training acc = 0.98
Valid Test with nat
Test accuracy: 92.06% (4603/5000), Test loss:0.2979
Epoch [64/80], Passed time:[70.358/4502.913]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0384, training acc = 0.98
Batch [200/704] training loss = 0.0867, training acc = 0.95
Batch [400/704] training loss = 0.0249, training acc = 1.00
Batch [600/704] training loss = 0.0453, training acc = 0.98
Valid Test with nat
Test accuracy: 92.12% (4606/5000), Test loss:0.3009
Epoch [65/80], Passed time:[70.331/4571.507]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0180, training acc = 1.00
Batch [200/704] training loss = 0.0065, training acc = 1.00
Batch [400/704] training loss = 0.0572, training acc = 0.98
Batch [600/704] training loss = 0.0098, training acc = 1.00
Valid Test with nat
Test accuracy: 92.00% (4600/5000), Test loss:0.3036
Epoch [66/80], Passed time:[70.283/4638.691]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0444, training acc = 0.98
Batch [200/704] training loss = 0.0522, training acc = 0.98
Batch [400/704] training loss = 0.0409, training acc = 0.98
Batch [600/704] training loss = 0.1160, training acc = 0.97
Valid Test with nat
Test accuracy: 92.04% (4602/5000), Test loss:0.3012
Epoch [67/80], Passed time:[70.286/4709.194]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0304, training acc = 0.98
Batch [200/704] training loss = 0.0446, training acc = 0.98
Batch [400/704] training loss = 0.0480, training acc = 0.98
Batch [600/704] training loss = 0.0765, training acc = 0.98
Valid Test with nat
Test accuracy: 92.02% (4601/5000), Test loss:0.3007
Epoch [68/80], Passed time:[70.286/4779.436]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0234, training acc = 1.00
Batch [200/704] training loss = 0.0302, training acc = 1.00
Batch [400/704] training loss = 0.0301, training acc = 1.00
Batch [600/704] training loss = 0.0279, training acc = 0.98
Valid Test with nat
Test accuracy: 92.14% (4607/5000), Test loss:0.2985
Epoch [69/80], Passed time:[70.252/4847.404]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0489, training acc = 0.98
Batch [200/704] training loss = 0.0556, training acc = 0.98
Batch [400/704] training loss = 0.0317, training acc = 1.00
Batch [600/704] training loss = 0.0194, training acc = 1.00
Valid Test with nat
Test accuracy: 92.06% (4603/5000), Test loss:0.2996
Epoch [70/80], Passed time:[70.241/4916.891]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.1161, training acc = 0.94
Batch [200/704] training loss = 0.0073, training acc = 1.00
Batch [400/704] training loss = 0.0149, training acc = 1.00
Batch [600/704] training loss = 0.0689, training acc = 0.97
Valid Test with nat
Test accuracy: 92.18% (4609/5000), Test loss:0.3162
Epoch [71/80], Passed time:[70.255/4988.129]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0194, training acc = 1.00
Batch [200/704] training loss = 0.0390, training acc = 0.98
Batch [400/704] training loss = 0.0543, training acc = 0.98
Batch [600/704] training loss = 0.0161, training acc = 1.00
Valid Test with nat
Test accuracy: 92.14% (4607/5000), Test loss:0.3131
Epoch [72/80], Passed time:[70.255/5058.331]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0114, training acc = 1.00
Batch [200/704] training loss = 0.0313, training acc = 0.98
Batch [400/704] training loss = 0.1613, training acc = 0.97
Batch [600/704] training loss = 0.0228, training acc = 1.00
Valid Test with nat
Test accuracy: 92.08% (4604/5000), Test loss:0.3051
Epoch [73/80], Passed time:[70.282/5130.621]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0123, training acc = 1.00
Batch [200/704] training loss = 0.0760, training acc = 0.97
Batch [400/704] training loss = 0.0448, training acc = 0.98
Batch [600/704] training loss = 0.0109, training acc = 1.00
Valid Test with nat
Test accuracy: 92.18% (4609/5000), Test loss:0.3079
Epoch [74/80], Passed time:[70.271/5200.044]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0242, training acc = 0.98
Batch [200/704] training loss = 0.0340, training acc = 1.00
Batch [400/704] training loss = 0.0050, training acc = 1.00
Batch [600/704] training loss = 0.0253, training acc = 0.98
Valid Test with nat
Test accuracy: 92.28% (4614/5000), Test loss:0.3016
Epoch [75/80], Passed time:[70.227/5267.007]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.1033, training acc = 0.95
Batch [200/704] training loss = 0.0095, training acc = 1.00
Batch [400/704] training loss = 0.0806, training acc = 0.98
Batch [600/704] training loss = 0.0119, training acc = 1.00
Valid Test with nat
Test accuracy: 92.12% (4606/5000), Test loss:0.3044
Epoch [76/80], Passed time:[70.265/5340.167]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0504, training acc = 0.98
Batch [200/704] training loss = 0.0946, training acc = 0.95
Batch [400/704] training loss = 0.0520, training acc = 0.98
Batch [600/704] training loss = 0.0071, training acc = 1.00
Valid Test with nat
Test accuracy: 92.08% (4604/5000), Test loss:0.2997
Epoch [77/80], Passed time:[70.264/5410.311]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0416, training acc = 0.98
Batch [200/704] training loss = 0.1204, training acc = 0.95
Batch [400/704] training loss = 0.0323, training acc = 0.98
Batch [600/704] training loss = 0.0154, training acc = 1.00
Valid Test with nat
Test accuracy: 92.00% (4600/5000), Test loss:0.3056
Epoch [78/80], Passed time:[70.240/5478.719]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0916, training acc = 0.95
Batch [200/704] training loss = 0.0156, training acc = 1.00
Batch [400/704] training loss = 0.0023, training acc = 1.00
Batch [600/704] training loss = 0.0265, training acc = 1.00
Valid Test with nat
Test accuracy: 92.18% (4609/5000), Test loss:0.2988
Epoch [79/80], Passed time:[70.248/5549.567]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0342, training acc = 0.98
Batch [200/704] training loss = 0.0693, training acc = 0.98
Batch [400/704] training loss = 0.0548, training acc = 0.97
Batch [600/704] training loss = 0.0121, training acc = 1.00
Valid Test with nat
Test accuracy: 92.22% (4611/5000), Test loss:0.3055
Training done, model saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance80_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 92.24% (9224/10000), Test loss:0.3104
