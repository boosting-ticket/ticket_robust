n_pruning_steps : 1
parallel : False
gpu : 2
starting_epsilon : 1e-05
clip_max : 1.0
n_classes : 10
warmup : True
transfer : False
eps_step : 0.00784313725490196
weight_decay : 0.0001
mask_path : ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/pruned_lr0.01_mask_r80.npy
optm : sgd
init_step : 1400
model_type : vgg16
interval_weight : 0.1
finetune_method : nat
create_init : False
early_stop : 100
seed : 7
test_batch_size : 100
results_path : None
train_epochs : 90
batch_size : 64
init_path : ./trained_models_new/cifar/vgg16/init/pure_vgg16_init.pth
prune_method : unstructured
verbose : 200
last_model_path : ./trained_models_new/
ft_interval_weight : 50
attack_iter : 10
init : True
mask_name : pruned_lr0.01_mask_r80
model_width : 8
schedule_length : 10
init_type : pure
enhance_epochs : 90
trades_beta : 6.0
eval : False
clip_min : 0
noise_sd : 1.0
model_name : init_enhance90_m0.01_warmup0.1
learning_rate : 0.1
resume : 0
max_pruning_ratio : 80
norm : True
targeted : False
enhance_learning_rate : 0.1
model_path : ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance90_m0.01_warmup0.1.pth
train_method : nat
enhance_method : nat
log_path : ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance90_m0.01_warmup0.1.log
epsilon : 0.03137254901960784
dataset : cifar
CUDA enabled.
Enhance training config:
Enhance training method: nat
model will be saved in: ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance90_m0.01_warmup0.1.pth
Init model is: ./trained_models_new/cifar/vgg16/init/pure_vgg16_init.pth
Init mask used from: ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/pruned_lr0.01_mask_r80.npy
Log will be saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance90_m0.01_warmup0.1.log
Random seed is: 7

model loading from ./trained_models_new/cifar/vgg16/init/pure_vgg16_init.pth
Epoch [0/90]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 2.2271, training acc = 0.23
Batch [200/704] training loss = 0.9553, training acc = 0.66
Batch [400/704] training loss = 0.8331, training acc = 0.70
Batch [600/704] training loss = 0.3060, training acc = 0.94
Valid Test with nat
Test accuracy: 79.94% (3997/5000), Test loss:0.5991
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance90_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 80.33% (8033/10000), Test loss:0.5886
Epoch [1/90], Passed time:[313.228/313.228]
learning rate: 0.020000000000000004
Batch [0/704] training loss = 0.4073, training acc = 0.86
Batch [200/704] training loss = 0.5949, training acc = 0.75
Batch [400/704] training loss = 0.5607, training acc = 0.78
Batch [600/704] training loss = 0.5633, training acc = 0.78
Valid Test with nat
Test accuracy: 77.66% (3883/5000), Test loss:0.6918
Epoch [2/90], Passed time:[303.931/607.863]
learning rate: 0.030000000000000006
Batch [0/704] training loss = 0.4878, training acc = 0.83
Batch [200/704] training loss = 0.4325, training acc = 0.84
Batch [400/704] training loss = 0.3157, training acc = 0.84
Batch [600/704] training loss = 0.5360, training acc = 0.84
Valid Test with nat
Test accuracy: 80.96% (4048/5000), Test loss:0.5901
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance90_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 79.16% (7916/10000), Test loss:0.6575
Epoch [3/90], Passed time:[304.047/912.140]
learning rate: 0.04000000000000001
Batch [0/704] training loss = 0.3370, training acc = 0.84
Batch [200/704] training loss = 0.4318, training acc = 0.83
Batch [400/704] training loss = 0.5345, training acc = 0.83
Batch [600/704] training loss = 0.6824, training acc = 0.81
Valid Test with nat
Test accuracy: 84.16% (4208/5000), Test loss:0.4827
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance90_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 84.50% (8450/10000), Test loss:0.4599
Epoch [4/90], Passed time:[304.568/1218.273]
learning rate: 0.05
Batch [0/704] training loss = 0.2985, training acc = 0.94
Batch [200/704] training loss = 0.5483, training acc = 0.75
Batch [400/704] training loss = 0.3359, training acc = 0.84
Batch [600/704] training loss = 0.4462, training acc = 0.86
Valid Test with nat
Test accuracy: 83.66% (4183/5000), Test loss:0.4987
Epoch [5/90], Passed time:[303.011/1515.054]
learning rate: 0.06000000000000001
Batch [0/704] training loss = 0.2234, training acc = 0.95
Batch [200/704] training loss = 0.5410, training acc = 0.81
Batch [400/704] training loss = 0.3423, training acc = 0.84
Batch [600/704] training loss = 0.2586, training acc = 0.95
Valid Test with nat
Test accuracy: 82.90% (4145/5000), Test loss:0.5276
Epoch [6/90], Passed time:[301.412/1808.470]
learning rate: 0.07
Batch [0/704] training loss = 0.1665, training acc = 0.95
Batch [200/704] training loss = 0.2556, training acc = 0.92
Batch [400/704] training loss = 0.4243, training acc = 0.86
Batch [600/704] training loss = 0.4671, training acc = 0.83
Valid Test with nat
Test accuracy: 84.76% (4238/5000), Test loss:0.4515
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance90_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 85.02% (8502/10000), Test loss:0.4536
Epoch [7/90], Passed time:[302.563/2117.940]
learning rate: 0.08000000000000002
Batch [0/704] training loss = 0.3481, training acc = 0.88
Batch [200/704] training loss = 0.3007, training acc = 0.88
Batch [400/704] training loss = 0.6019, training acc = 0.80
Batch [600/704] training loss = 0.4748, training acc = 0.81
Valid Test with nat
Test accuracy: 81.42% (4071/5000), Test loss:0.5899
Epoch [8/90], Passed time:[301.325/2410.599]
learning rate: 0.09000000000000001
Batch [0/704] training loss = 0.3738, training acc = 0.91
Batch [200/704] training loss = 0.5958, training acc = 0.83
Batch [400/704] training loss = 0.4385, training acc = 0.83
Batch [600/704] training loss = 0.3600, training acc = 0.88
Valid Test with nat
Test accuracy: 82.22% (4111/5000), Test loss:0.5652
Epoch [9/90], Passed time:[300.717/2706.452]
learning rate: 0.1
Batch [0/704] training loss = 0.4626, training acc = 0.84
Batch [200/704] training loss = 0.3973, training acc = 0.86
Batch [400/704] training loss = 0.4452, training acc = 0.88
Batch [600/704] training loss = 0.3651, training acc = 0.89
Valid Test with nat
Test accuracy: 81.40% (4070/5000), Test loss:0.5743
Epoch [10/90], Passed time:[300.338/3003.379]
learning rate: 0.1
Batch [0/704] training loss = 0.5456, training acc = 0.86
Batch [200/704] training loss = 0.5026, training acc = 0.80
Batch [400/704] training loss = 0.4369, training acc = 0.88
Batch [600/704] training loss = 0.4156, training acc = 0.92
Valid Test with nat
Test accuracy: 82.68% (4134/5000), Test loss:0.5417
Epoch [11/90], Passed time:[300.579/3306.374]
learning rate: 0.1
Batch [0/704] training loss = 0.3199, training acc = 0.89
Batch [200/704] training loss = 0.4138, training acc = 0.84
Batch [400/704] training loss = 0.4145, training acc = 0.84
Batch [600/704] training loss = 0.3147, training acc = 0.91
Valid Test with nat
Test accuracy: 85.70% (4285/5000), Test loss:0.4566
Epoch [12/90], Passed time:[298.122/3577.459]
learning rate: 0.1
Batch [0/704] training loss = 0.2776, training acc = 0.91
Batch [200/704] training loss = 0.4185, training acc = 0.86
Batch [400/704] training loss = 0.3261, training acc = 0.88
Batch [600/704] training loss = 0.4920, training acc = 0.84
Valid Test with nat
Test accuracy: 84.12% (4206/5000), Test loss:0.5349
Epoch [13/90], Passed time:[295.394/3840.127]
learning rate: 0.1
Batch [0/704] training loss = 0.4155, training acc = 0.89
Batch [200/704] training loss = 0.3711, training acc = 0.88
Batch [400/704] training loss = 0.3977, training acc = 0.89
Batch [600/704] training loss = 0.3109, training acc = 0.88
Valid Test with nat
Test accuracy: 85.58% (4279/5000), Test loss:0.4552
Epoch [14/90], Passed time:[293.236/4105.303]
learning rate: 0.1
Batch [0/704] training loss = 0.3372, training acc = 0.86
Batch [200/704] training loss = 0.3069, training acc = 0.91
Batch [400/704] training loss = 0.3846, training acc = 0.88
Batch [600/704] training loss = 0.6095, training acc = 0.84
Valid Test with nat
Test accuracy: 84.98% (4249/5000), Test loss:0.4899
Epoch [15/90], Passed time:[290.291/4354.367]
learning rate: 0.1
Batch [0/704] training loss = 0.2489, training acc = 0.89
Batch [200/704] training loss = 0.4674, training acc = 0.86
Batch [400/704] training loss = 0.1589, training acc = 0.94
Batch [600/704] training loss = 0.2818, training acc = 0.94
Valid Test with nat
Test accuracy: 86.36% (4318/5000), Test loss:0.4242
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance90_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 86.53% (8653/10000), Test loss:0.4245
Epoch [16/90], Passed time:[288.130/4610.077]
learning rate: 0.1
Batch [0/704] training loss = 0.2156, training acc = 0.91
Batch [200/704] training loss = 0.5315, training acc = 0.81
Batch [400/704] training loss = 0.2115, training acc = 0.92
Batch [600/704] training loss = 0.2263, training acc = 0.92
Valid Test with nat
Test accuracy: 82.54% (4127/5000), Test loss:0.5357
Epoch [17/90], Passed time:[286.084/4863.429]
learning rate: 0.1
Batch [0/704] training loss = 0.4115, training acc = 0.86
Batch [200/704] training loss = 0.3853, training acc = 0.83
Batch [400/704] training loss = 0.5169, training acc = 0.86
Batch [600/704] training loss = 0.4083, training acc = 0.83
Valid Test with nat
Test accuracy: 82.88% (4144/5000), Test loss:0.5598
Epoch [18/90], Passed time:[283.545/5103.812]
learning rate: 0.1
Batch [0/704] training loss = 0.4584, training acc = 0.86
Batch [200/704] training loss = 0.2392, training acc = 0.91
Batch [400/704] training loss = 0.2477, training acc = 0.94
Batch [600/704] training loss = 0.3294, training acc = 0.91
Valid Test with nat
Test accuracy: 86.12% (4306/5000), Test loss:0.4572
Epoch [19/90], Passed time:[281.374/5346.113]
learning rate: 0.1
Batch [0/704] training loss = 0.3866, training acc = 0.89
Batch [200/704] training loss = 0.4443, training acc = 0.81
Batch [400/704] training loss = 0.4681, training acc = 0.83
Batch [600/704] training loss = 0.3100, training acc = 0.86
Valid Test with nat
Test accuracy: 85.10% (4255/5000), Test loss:0.4431
Epoch [20/90], Passed time:[279.173/5583.468]
learning rate: 0.1
Batch [0/704] training loss = 0.3332, training acc = 0.88
Batch [200/704] training loss = 0.2151, training acc = 0.94
Batch [400/704] training loss = 0.2500, training acc = 0.91
Batch [600/704] training loss = 0.1452, training acc = 0.97
Valid Test with nat
Test accuracy: 85.06% (4253/5000), Test loss:0.4677
Epoch [21/90], Passed time:[277.169/5820.544]
learning rate: 0.1
Batch [0/704] training loss = 0.2338, training acc = 0.94
Batch [200/704] training loss = 0.2954, training acc = 0.92
Batch [400/704] training loss = 0.6386, training acc = 0.78
Batch [600/704] training loss = 0.3996, training acc = 0.88
Valid Test with nat
Test accuracy: 86.32% (4316/5000), Test loss:0.4364
Epoch [22/90], Passed time:[274.832/6046.314]
learning rate: 0.1
Batch [0/704] training loss = 0.1695, training acc = 0.91
Batch [200/704] training loss = 0.2985, training acc = 0.91
Batch [400/704] training loss = 0.3827, training acc = 0.86
Batch [600/704] training loss = 0.3609, training acc = 0.86
Valid Test with nat
Test accuracy: 85.30% (4265/5000), Test loss:0.4673
Epoch [23/90], Passed time:[272.971/6278.337]
learning rate: 0.1
Batch [0/704] training loss = 0.3598, training acc = 0.86
Batch [200/704] training loss = 0.2311, training acc = 0.92
Batch [400/704] training loss = 0.3505, training acc = 0.88
Batch [600/704] training loss = 0.2754, training acc = 0.91
Valid Test with nat
Test accuracy: 85.58% (4279/5000), Test loss:0.4424
Epoch [24/90], Passed time:[271.509/6516.216]
learning rate: 0.1
Batch [0/704] training loss = 0.2893, training acc = 0.92
Batch [200/704] training loss = 0.5219, training acc = 0.78
Batch [400/704] training loss = 0.2473, training acc = 0.94
Batch [600/704] training loss = 0.4202, training acc = 0.84
Valid Test with nat
Test accuracy: 86.28% (4314/5000), Test loss:0.4472
Epoch [25/90], Passed time:[269.584/6739.603]
learning rate: 0.1
Batch [0/704] training loss = 0.1804, training acc = 0.94
Batch [200/704] training loss = 0.1982, training acc = 0.94
Batch [400/704] training loss = 0.2287, training acc = 0.89
Batch [600/704] training loss = 0.3552, training acc = 0.86
Valid Test with nat
Test accuracy: 84.60% (4230/5000), Test loss:0.5027
Epoch [26/90], Passed time:[268.436/6979.326]
learning rate: 0.1
Batch [0/704] training loss = 0.4074, training acc = 0.89
Batch [200/704] training loss = 0.3385, training acc = 0.86
Batch [400/704] training loss = 0.4826, training acc = 0.91
Batch [600/704] training loss = 0.3342, training acc = 0.88
Valid Test with nat
Test accuracy: 85.62% (4281/5000), Test loss:0.4590
Epoch [27/90], Passed time:[267.582/7224.719]
learning rate: 0.1
Batch [0/704] training loss = 0.2108, training acc = 0.92
Batch [200/704] training loss = 0.1787, training acc = 0.95
Batch [400/704] training loss = 0.4021, training acc = 0.88
Batch [600/704] training loss = 0.2709, training acc = 0.91
Valid Test with nat
Test accuracy: 85.24% (4262/5000), Test loss:0.4822
Epoch [28/90], Passed time:[266.519/7462.520]
learning rate: 0.1
Batch [0/704] training loss = 0.4277, training acc = 0.83
Batch [200/704] training loss = 0.3435, training acc = 0.89
Batch [400/704] training loss = 0.1402, training acc = 0.94
Batch [600/704] training loss = 0.3235, training acc = 0.91
Valid Test with nat
Test accuracy: 86.40% (4320/5000), Test loss:0.4380
Epoch [29/90], Passed time:[265.629/7703.236]
learning rate: 0.1
Batch [0/704] training loss = 0.1648, training acc = 0.98
Batch [200/704] training loss = 0.2783, training acc = 0.88
Batch [400/704] training loss = 0.3174, training acc = 0.91
Batch [600/704] training loss = 0.2500, training acc = 0.91
Valid Test with nat
Test accuracy: 86.38% (4319/5000), Test loss:0.4358
Epoch [30/90], Passed time:[264.734/7942.015]
learning rate: 0.1
Batch [0/704] training loss = 0.2528, training acc = 0.92
Batch [200/704] training loss = 0.2957, training acc = 0.91
Batch [400/704] training loss = 0.3504, training acc = 0.91
Batch [600/704] training loss = 0.2892, training acc = 0.92
Valid Test with nat
Test accuracy: 83.88% (4194/5000), Test loss:0.5315
Epoch [31/90], Passed time:[263.752/8176.303]
learning rate: 0.1
Batch [0/704] training loss = 0.6076, training acc = 0.84
Batch [200/704] training loss = 0.2577, training acc = 0.89
Batch [400/704] training loss = 0.2493, training acc = 0.91
Batch [600/704] training loss = 0.2856, training acc = 0.91
Valid Test with nat
Test accuracy: 85.10% (4255/5000), Test loss:0.4766
Epoch [32/90], Passed time:[262.683/8405.864]
learning rate: 0.1
Batch [0/704] training loss = 0.3338, training acc = 0.89
Batch [200/704] training loss = 0.1579, training acc = 0.97
Batch [400/704] training loss = 0.0857, training acc = 0.98
Batch [600/704] training loss = 0.3881, training acc = 0.88
Valid Test with nat
Test accuracy: 84.22% (4211/5000), Test loss:0.4907
Epoch [33/90], Passed time:[260.965/8611.840]
learning rate: 0.1
Batch [0/704] training loss = 0.2788, training acc = 0.89
Batch [200/704] training loss = 0.5845, training acc = 0.83
Batch [400/704] training loss = 0.2840, training acc = 0.94
Batch [600/704] training loss = 0.1990, training acc = 0.95
Valid Test with nat
Test accuracy: 86.90% (4345/5000), Test loss:0.3944
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance90_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 85.75% (8575/10000), Test loss:0.4331
Epoch [34/90], Passed time:[259.470/8821.986]
learning rate: 0.1
Batch [0/704] training loss = 0.3370, training acc = 0.88
Batch [200/704] training loss = 0.3819, training acc = 0.88
Batch [400/704] training loss = 0.2287, training acc = 0.91
Batch [600/704] training loss = 0.2531, training acc = 0.92
Valid Test with nat
Test accuracy: 87.30% (4365/5000), Test loss:0.4196
Epoch [35/90], Passed time:[257.699/9019.477]
learning rate: 0.1
Batch [0/704] training loss = 0.2888, training acc = 0.86
Batch [200/704] training loss = 0.1569, training acc = 0.94
Batch [400/704] training loss = 0.3636, training acc = 0.89
Batch [600/704] training loss = 0.2327, training acc = 0.94
Valid Test with nat
Test accuracy: 85.54% (4277/5000), Test loss:0.4610
Epoch [36/90], Passed time:[255.936/9213.688]
learning rate: 0.1
Batch [0/704] training loss = 0.2180, training acc = 0.94
Batch [200/704] training loss = 0.4425, training acc = 0.86
Batch [400/704] training loss = 0.3045, training acc = 0.91
Batch [600/704] training loss = 0.3538, training acc = 0.89
Valid Test with nat
Test accuracy: 85.48% (4274/5000), Test loss:0.4742
Epoch [37/90], Passed time:[254.205/9405.602]
learning rate: 0.1
Batch [0/704] training loss = 0.1863, training acc = 0.92
Batch [200/704] training loss = 0.2294, training acc = 0.92
Batch [400/704] training loss = 0.4418, training acc = 0.91
Batch [600/704] training loss = 0.3171, training acc = 0.92
Valid Test with nat
Test accuracy: 84.56% (4228/5000), Test loss:0.4817
Epoch [38/90], Passed time:[252.601/9598.833]
learning rate: 0.1
Batch [0/704] training loss = 0.1945, training acc = 0.92
Batch [200/704] training loss = 0.2213, training acc = 0.94
Batch [400/704] training loss = 0.1777, training acc = 0.92
Batch [600/704] training loss = 0.4731, training acc = 0.84
Valid Test with nat
Test accuracy: 85.90% (4295/5000), Test loss:0.4510
Epoch [39/90], Passed time:[250.372/9764.492]
learning rate: 0.1
Batch [0/704] training loss = 0.2260, training acc = 0.92
Batch [200/704] training loss = 0.2956, training acc = 0.89
Batch [400/704] training loss = 0.2497, training acc = 0.89
Batch [600/704] training loss = 0.2157, training acc = 0.95
Valid Test with nat
Test accuracy: 83.24% (4162/5000), Test loss:0.5158
Epoch [40/90], Passed time:[248.164/9926.566]
learning rate: 0.1
Batch [0/704] training loss = 0.1830, training acc = 0.94
Batch [200/704] training loss = 0.2660, training acc = 0.94
Batch [400/704] training loss = 0.1392, training acc = 0.97
Batch [600/704] training loss = 0.3526, training acc = 0.89
Valid Test with nat
Test accuracy: 86.36% (4318/5000), Test loss:0.4168
Epoch [41/90], Passed time:[246.155/10092.370]
learning rate: 0.1
Batch [0/704] training loss = 0.2595, training acc = 0.91
Batch [200/704] training loss = 0.2572, training acc = 0.94
Batch [400/704] training loss = 0.3112, training acc = 0.89
Batch [600/704] training loss = 0.3273, training acc = 0.86
Valid Test with nat
Test accuracy: 86.18% (4309/5000), Test loss:0.4374
Epoch [42/90], Passed time:[244.195/10256.185]
learning rate: 0.1
Batch [0/704] training loss = 0.2562, training acc = 0.91
Batch [200/704] training loss = 0.2641, training acc = 0.88
Batch [400/704] training loss = 0.4273, training acc = 0.84
Batch [600/704] training loss = 0.2918, training acc = 0.91
Valid Test with nat
Test accuracy: 87.24% (4362/5000), Test loss:0.4116
Epoch [43/90], Passed time:[242.465/10425.998]
learning rate: 0.1
Batch [0/704] training loss = 0.2161, training acc = 0.94
Batch [200/704] training loss = 0.3617, training acc = 0.84
Batch [400/704] training loss = 0.2831, training acc = 0.91
Batch [600/704] training loss = 0.1694, training acc = 0.95
Valid Test with nat
Test accuracy: 83.64% (4182/5000), Test loss:0.5218
Epoch [44/90], Passed time:[240.706/10591.070]
learning rate: 0.1
Batch [0/704] training loss = 0.2131, training acc = 0.92
Batch [200/704] training loss = 0.3918, training acc = 0.86
Batch [400/704] training loss = 0.5560, training acc = 0.83
Batch [600/704] training loss = 0.3799, training acc = 0.89
Valid Test with nat
Test accuracy: 88.20% (4410/5000), Test loss:0.3703
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance90_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 87.20% (8720/10000), Test loss:0.3949
Epoch [45/90], Passed time:[239.094/10759.215]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.3243, training acc = 0.91
Batch [200/704] training loss = 0.2356, training acc = 0.95
Batch [400/704] training loss = 0.1266, training acc = 0.95
Batch [600/704] training loss = 0.2894, training acc = 0.91
Valid Test with nat
Test accuracy: 91.60% (4580/5000), Test loss:0.2785
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance90_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 90.95% (9095/10000), Test loss:0.2886
Epoch [46/90], Passed time:[237.655/10932.124]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.1905, training acc = 0.91
Batch [200/704] training loss = 0.1560, training acc = 0.94
Batch [400/704] training loss = 0.1049, training acc = 0.97
Batch [600/704] training loss = 0.1253, training acc = 0.98
Valid Test with nat
Test accuracy: 91.84% (4592/5000), Test loss:0.2662
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance90_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 91.20% (9120/10000), Test loss:0.2873
Epoch [47/90], Passed time:[236.238/11103.165]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0468, training acc = 0.98
Batch [200/704] training loss = 0.2553, training acc = 0.88
Batch [400/704] training loss = 0.0803, training acc = 0.98
Batch [600/704] training loss = 0.1436, training acc = 0.94
Valid Test with nat
Test accuracy: 91.86% (4593/5000), Test loss:0.2670
Epoch [48/90], Passed time:[234.871/11273.813]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0621, training acc = 0.98
Batch [200/704] training loss = 0.0826, training acc = 0.97
Batch [400/704] training loss = 0.1025, training acc = 0.94
Batch [600/704] training loss = 0.0683, training acc = 0.98
Valid Test with nat
Test accuracy: 91.86% (4593/5000), Test loss:0.2721
Epoch [49/90], Passed time:[233.487/11440.858]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0741, training acc = 0.98
Batch [200/704] training loss = 0.1000, training acc = 0.97
Batch [400/704] training loss = 0.0844, training acc = 0.95
Batch [600/704] training loss = 0.1409, training acc = 0.97
Valid Test with nat
Test accuracy: 91.84% (4592/5000), Test loss:0.2755
Epoch [50/90], Passed time:[232.249/11612.473]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.2547, training acc = 0.92
Batch [200/704] training loss = 0.0424, training acc = 1.00
Batch [400/704] training loss = 0.1067, training acc = 0.97
Batch [600/704] training loss = 0.0823, training acc = 0.97
Valid Test with nat
Test accuracy: 92.36% (4618/5000), Test loss:0.2681
Epoch [51/90], Passed time:[230.971/11779.511]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.1796, training acc = 0.95
Batch [200/704] training loss = 0.0988, training acc = 0.97
Batch [400/704] training loss = 0.0152, training acc = 1.00
Batch [600/704] training loss = 0.2139, training acc = 0.94
Valid Test with nat
Test accuracy: 92.18% (4609/5000), Test loss:0.2701
Epoch [52/90], Passed time:[229.690/11943.886]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0653, training acc = 0.97
Batch [200/704] training loss = 0.0368, training acc = 0.98
Batch [400/704] training loss = 0.0600, training acc = 0.97
Batch [600/704] training loss = 0.0776, training acc = 0.98
Valid Test with nat
Test accuracy: 92.08% (4604/5000), Test loss:0.2786
Epoch [53/90], Passed time:[228.402/12105.280]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0320, training acc = 1.00
Batch [200/704] training loss = 0.0963, training acc = 0.95
Batch [400/704] training loss = 0.1205, training acc = 0.97
Batch [600/704] training loss = 0.0877, training acc = 0.98
Valid Test with nat
Test accuracy: 91.90% (4595/5000), Test loss:0.2862
Epoch [54/90], Passed time:[227.135/12265.271]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.1386, training acc = 0.95
Batch [200/704] training loss = 0.0715, training acc = 0.97
Batch [400/704] training loss = 0.0772, training acc = 0.98
Batch [600/704] training loss = 0.2185, training acc = 0.94
Valid Test with nat
Test accuracy: 91.96% (4598/5000), Test loss:0.2943
Epoch [55/90], Passed time:[225.840/12421.218]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.1196, training acc = 0.97
Batch [200/704] training loss = 0.0473, training acc = 0.98
Batch [400/704] training loss = 0.1121, training acc = 0.94
Batch [600/704] training loss = 0.0654, training acc = 0.97
Valid Test with nat
Test accuracy: 92.06% (4603/5000), Test loss:0.2842
Epoch [56/90], Passed time:[224.395/12566.123]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0568, training acc = 0.97
Batch [200/704] training loss = 0.0337, training acc = 1.00
Batch [400/704] training loss = 0.0358, training acc = 0.98
Batch [600/704] training loss = 0.1040, training acc = 0.97
Valid Test with nat
Test accuracy: 92.08% (4604/5000), Test loss:0.2874
Epoch [57/90], Passed time:[222.531/12684.276]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0487, training acc = 0.98
Batch [200/704] training loss = 0.0236, training acc = 1.00
Batch [400/704] training loss = 0.0446, training acc = 0.97
Batch [600/704] training loss = 0.0118, training acc = 1.00
Valid Test with nat
Test accuracy: 92.04% (4602/5000), Test loss:0.2888
Epoch [58/90], Passed time:[220.688/12799.919]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0517, training acc = 0.97
Batch [200/704] training loss = 0.0341, training acc = 1.00
Batch [400/704] training loss = 0.0597, training acc = 0.98
Batch [600/704] training loss = 0.0476, training acc = 0.97
Valid Test with nat
Test accuracy: 91.94% (4597/5000), Test loss:0.2971
Epoch [59/90], Passed time:[218.841/12911.616]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0406, training acc = 0.98
Batch [200/704] training loss = 0.0300, training acc = 0.98
Batch [400/704] training loss = 0.0267, training acc = 1.00
Batch [600/704] training loss = 0.0448, training acc = 0.98
Valid Test with nat
Test accuracy: 92.34% (4617/5000), Test loss:0.3008
Epoch [60/90], Passed time:[217.121/13027.241]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0613, training acc = 0.98
Batch [200/704] training loss = 0.0524, training acc = 0.98
Batch [400/704] training loss = 0.1574, training acc = 0.97
Batch [600/704] training loss = 0.0366, training acc = 0.98
Valid Test with nat
Test accuracy: 91.92% (4596/5000), Test loss:0.3070
Epoch [61/90], Passed time:[215.407/13139.845]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0956, training acc = 0.95
Batch [200/704] training loss = 0.0064, training acc = 1.00
Batch [400/704] training loss = 0.0118, training acc = 1.00
Batch [600/704] training loss = 0.0276, training acc = 0.98
Valid Test with nat
Test accuracy: 92.04% (4602/5000), Test loss:0.3112
Epoch [62/90], Passed time:[213.752/13252.646]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0866, training acc = 0.97
Batch [200/704] training loss = 0.0186, training acc = 1.00
Batch [400/704] training loss = 0.0683, training acc = 0.98
Batch [600/704] training loss = 0.0875, training acc = 0.95
Valid Test with nat
Test accuracy: 92.08% (4604/5000), Test loss:0.2982
Epoch [63/90], Passed time:[212.238/13370.969]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0103, training acc = 1.00
Batch [200/704] training loss = 0.1504, training acc = 0.95
Batch [400/704] training loss = 0.0726, training acc = 0.98
Batch [600/704] training loss = 0.0397, training acc = 0.98
Valid Test with nat
Test accuracy: 92.12% (4606/5000), Test loss:0.3020
Epoch [64/90], Passed time:[210.729/13486.651]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.1480, training acc = 0.95
Batch [200/704] training loss = 0.0334, training acc = 0.98
Batch [400/704] training loss = 0.0346, training acc = 0.98
Batch [600/704] training loss = 0.0757, training acc = 0.97
Valid Test with nat
Test accuracy: 92.00% (4600/5000), Test loss:0.3095
Epoch [65/90], Passed time:[209.300/13604.524]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.1062, training acc = 0.97
Batch [200/704] training loss = 0.1241, training acc = 0.97
Batch [400/704] training loss = 0.0853, training acc = 0.95
Batch [600/704] training loss = 0.0285, training acc = 0.98
Valid Test with nat
Test accuracy: 91.88% (4594/5000), Test loss:0.3049
Epoch [66/90], Passed time:[207.906/13721.806]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0639, training acc = 0.97
Batch [200/704] training loss = 0.1121, training acc = 0.97
Batch [400/704] training loss = 0.0647, training acc = 0.97
Batch [600/704] training loss = 0.0675, training acc = 0.97
Valid Test with nat
Test accuracy: 91.92% (4596/5000), Test loss:0.3202
Epoch [67/90], Passed time:[206.490/13834.838]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.1254, training acc = 0.97
Batch [200/704] training loss = 0.0117, training acc = 1.00
Batch [400/704] training loss = 0.0549, training acc = 0.97
Batch [600/704] training loss = 0.1283, training acc = 0.97
Valid Test with nat
Test accuracy: 91.90% (4595/5000), Test loss:0.3140
Epoch [68/90], Passed time:[204.680/13918.255]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0917, training acc = 0.97
Batch [200/704] training loss = 0.0918, training acc = 0.95
Batch [400/704] training loss = 0.0121, training acc = 1.00
Batch [600/704] training loss = 0.0655, training acc = 0.98
Valid Test with nat
Test accuracy: 92.26% (4613/5000), Test loss:0.2971
Epoch [69/90], Passed time:[202.696/13986.015]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0695, training acc = 0.98
Batch [200/704] training loss = 0.0196, training acc = 0.98
Batch [400/704] training loss = 0.0099, training acc = 1.00
Batch [600/704] training loss = 0.0198, training acc = 1.00
Valid Test with nat
Test accuracy: 92.34% (4617/5000), Test loss:0.2924
Epoch [70/90], Passed time:[200.726/14050.812]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0112, training acc = 1.00
Batch [200/704] training loss = 0.0082, training acc = 1.00
Batch [400/704] training loss = 0.0619, training acc = 0.97
Batch [600/704] training loss = 0.0107, training acc = 1.00
Valid Test with nat
Test accuracy: 92.28% (4614/5000), Test loss:0.2966
Epoch [71/90], Passed time:[198.806/14115.207]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0071, training acc = 1.00
Batch [200/704] training loss = 0.0145, training acc = 1.00
Batch [400/704] training loss = 0.0438, training acc = 0.98
Batch [600/704] training loss = 0.1375, training acc = 0.94
Valid Test with nat
Test accuracy: 92.34% (4617/5000), Test loss:0.2962
Epoch [72/90], Passed time:[196.938/14179.508]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0367, training acc = 0.98
Batch [200/704] training loss = 0.0555, training acc = 0.98
Batch [400/704] training loss = 0.0385, training acc = 0.98
Batch [600/704] training loss = 0.0159, training acc = 1.00
Valid Test with nat
Test accuracy: 92.48% (4624/5000), Test loss:0.3035
Epoch [73/90], Passed time:[195.118/14243.596]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0374, training acc = 0.98
Batch [200/704] training loss = 0.0016, training acc = 1.00
Batch [400/704] training loss = 0.0279, training acc = 0.98
Batch [600/704] training loss = 0.0392, training acc = 0.98
Valid Test with nat
Test accuracy: 92.46% (4623/5000), Test loss:0.2969
Epoch [74/90], Passed time:[193.101/14289.480]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0319, training acc = 0.98
Batch [200/704] training loss = 0.0906, training acc = 0.97
Batch [400/704] training loss = 0.0405, training acc = 0.98
Batch [600/704] training loss = 0.0281, training acc = 0.98
Valid Test with nat
Test accuracy: 92.42% (4621/5000), Test loss:0.2989
Epoch [75/90], Passed time:[190.996/14324.722]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0239, training acc = 1.00
Batch [200/704] training loss = 0.0958, training acc = 0.95
Batch [400/704] training loss = 0.0090, training acc = 1.00
Batch [600/704] training loss = 0.0622, training acc = 0.97
Valid Test with nat
Test accuracy: 92.32% (4616/5000), Test loss:0.2991
Epoch [76/90], Passed time:[188.851/14352.641]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0440, training acc = 0.98
Batch [200/704] training loss = 0.0039, training acc = 1.00
Batch [400/704] training loss = 0.0670, training acc = 0.97
Batch [600/704] training loss = 0.0479, training acc = 0.98
Valid Test with nat
Test accuracy: 92.38% (4619/5000), Test loss:0.2979
Epoch [77/90], Passed time:[186.761/14380.592]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0039, training acc = 1.00
Batch [200/704] training loss = 0.0416, training acc = 1.00
Batch [400/704] training loss = 0.0540, training acc = 0.98
Batch [600/704] training loss = 0.0408, training acc = 0.98
Valid Test with nat
Test accuracy: 92.50% (4625/5000), Test loss:0.2992
Epoch [78/90], Passed time:[184.722/14408.346]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0157, training acc = 1.00
Batch [200/704] training loss = 0.0352, training acc = 0.98
Batch [400/704] training loss = 0.0833, training acc = 0.95
Batch [600/704] training loss = 0.0881, training acc = 0.98
Valid Test with nat
Test accuracy: 92.60% (4630/5000), Test loss:0.3051
Epoch [79/90], Passed time:[182.738/14436.302]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0337, training acc = 0.98
Batch [200/704] training loss = 0.0214, training acc = 0.98
Batch [400/704] training loss = 0.0267, training acc = 1.00
Batch [600/704] training loss = 0.0105, training acc = 1.00
Valid Test with nat
Test accuracy: 92.52% (4626/5000), Test loss:0.2983
Epoch [80/90], Passed time:[180.804/14464.317]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0171, training acc = 1.00
Batch [200/704] training loss = 0.0366, training acc = 0.98
Batch [400/704] training loss = 0.0392, training acc = 0.98
Batch [600/704] training loss = 0.0363, training acc = 0.98
Valid Test with nat
Test accuracy: 92.30% (4615/5000), Test loss:0.3089
Epoch [81/90], Passed time:[178.914/14492.015]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0150, training acc = 1.00
Batch [200/704] training loss = 0.0360, training acc = 0.98
Batch [400/704] training loss = 0.1004, training acc = 0.98
Batch [600/704] training loss = 0.0044, training acc = 1.00
Valid Test with nat
Test accuracy: 92.48% (4624/5000), Test loss:0.3059
Epoch [82/90], Passed time:[177.068/14519.551]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0419, training acc = 0.98
Batch [200/704] training loss = 0.0306, training acc = 0.98
Batch [400/704] training loss = 0.0289, training acc = 1.00
Batch [600/704] training loss = 0.0092, training acc = 1.00
Valid Test with nat
Test accuracy: 92.66% (4633/5000), Test loss:0.3012
Epoch [83/90], Passed time:[175.270/14547.442]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0453, training acc = 0.98
Batch [200/704] training loss = 0.0140, training acc = 1.00
Batch [400/704] training loss = 0.0275, training acc = 0.98
Batch [600/704] training loss = 0.0571, training acc = 0.97
Valid Test with nat
Test accuracy: 92.48% (4624/5000), Test loss:0.3069
Epoch [84/90], Passed time:[173.515/14575.238]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0518, training acc = 0.98
Batch [200/704] training loss = 0.0738, training acc = 0.97
Batch [400/704] training loss = 0.0654, training acc = 0.97
Batch [600/704] training loss = 0.0305, training acc = 0.98
Valid Test with nat
Test accuracy: 92.42% (4621/5000), Test loss:0.3054
Epoch [85/90], Passed time:[171.802/14603.134]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0208, training acc = 0.98
Batch [200/704] training loss = 0.0799, training acc = 0.98
Batch [400/704] training loss = 0.0193, training acc = 1.00
Batch [600/704] training loss = 0.0120, training acc = 1.00
Valid Test with nat
Test accuracy: 92.54% (4627/5000), Test loss:0.3028
Epoch [86/90], Passed time:[170.129/14631.098]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0568, training acc = 0.97
Batch [200/704] training loss = 0.0567, training acc = 0.98
Batch [400/704] training loss = 0.0164, training acc = 1.00
Batch [600/704] training loss = 0.0542, training acc = 0.98
Valid Test with nat
Test accuracy: 92.48% (4624/5000), Test loss:0.3093
Epoch [87/90], Passed time:[168.495/14659.104]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0223, training acc = 1.00
Batch [200/704] training loss = 0.0141, training acc = 1.00
Batch [400/704] training loss = 0.0507, training acc = 0.97
Batch [600/704] training loss = 0.0767, training acc = 0.97
Valid Test with nat
Test accuracy: 92.40% (4620/5000), Test loss:0.3164
Epoch [88/90], Passed time:[166.896/14686.845]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0294, training acc = 1.00
Batch [200/704] training loss = 0.0166, training acc = 1.00
Batch [400/704] training loss = 0.0038, training acc = 1.00
Batch [600/704] training loss = 0.0352, training acc = 0.98
Valid Test with nat
Test accuracy: 92.58% (4629/5000), Test loss:0.3015
Epoch [89/90], Passed time:[165.334/14714.747]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0122, training acc = 1.00
Batch [200/704] training loss = 0.0045, training acc = 1.00
Batch [400/704] training loss = 0.0463, training acc = 0.97
Batch [600/704] training loss = 0.0043, training acc = 1.00
Valid Test with nat
Test accuracy: 92.66% (4633/5000), Test loss:0.3089
Training done, model saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance90_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 92.04% (9204/10000), Test loss:0.3220
