model_type : vgg16
init_type : pure
finetune_method : nat
enhance_method : nat
gpu : 6
model_name : init_enhance20_m0.05_warmup0.1
model_width : 8
n_pruning_steps : 1
max_pruning_ratio : 80
train_epochs : 20
enhance_epochs : 20
prune_method : unstructured
dataset : cifar
noise_sd : 1.0
trades_beta : 6.0
seed : 7
warmup : True
parallel : False
create_init : False
init_step : 1400
train_method : nat
early_stop : 100
norm : True
optm : sgd
batch_size : 64
test_batch_size : 100
learning_rate : 0.1
enhance_learning_rate : 0.1
schedule_length : 10
weight_decay : 0.0001
epsilon : 0.03137254901960784
attack_iter : 10
eps_step : 0.00784313725490196
targeted : False
clip_min : 0
clip_max : 1.0
starting_epsilon : 1e-05
interval_weight : 0.1
ft_interval_weight : 50
verbose : 200
resume : 0
model_path : ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance20_m0.05_warmup0.1.pth
last_model_path : ./trained_models_new/
mask_path : ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/pruned_lr0.05_mask_r80.npy
mask_name : pruned_lr0.05_mask_r80
log_path : ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance20_m0.05_warmup0.1.log
init_path : ./trained_models_new/cifar/vgg16/init/pure_vgg16_init.pth
results_path : None
n_classes : 10
eval : False
init : True
transfer : False
CUDA enabled.
Enhance training config:
Enhance training method: nat
model will be saved in: ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance20_m0.05_warmup0.1.pth
Init model is: ./trained_models_new/cifar/vgg16/init/pure_vgg16_init.pth
Init mask used from: ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/pruned_lr0.05_mask_r80.npy
Log will be saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance20_m0.05_warmup0.1.log
Random seed is: 7

model loading from ./trained_models_new/cifar/vgg16/init/pure_vgg16_init.pth
Epoch [0/20]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 2.2821, training acc = 0.14
Batch [200/704] training loss = 1.4947, training acc = 0.47
Batch [400/704] training loss = 1.3564, training acc = 0.53
Batch [600/704] training loss = 0.9888, training acc = 0.66
Valid Test with nat
Test accuracy: 51.10% (2555/5000), Test loss:1.3887
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance20_m0.05_warmup0.1.pth
Test on test set:
Test accuracy: 48.43% (4843/10000), Test loss:1.4757
Epoch [1/20], Passed time:[58.743/58.743]
learning rate: 0.020000000000000004
Batch [0/704] training loss = 1.0812, training acc = 0.59
Batch [200/704] training loss = 1.0550, training acc = 0.66
Batch [400/704] training loss = 0.9008, training acc = 0.64
Batch [600/704] training loss = 1.0711, training acc = 0.69
Valid Test with nat
Test accuracy: 70.76% (3538/5000), Test loss:0.8395
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance20_m0.05_warmup0.1.pth
Test on test set:
Test accuracy: 71.15% (7115/10000), Test loss:0.8405
Epoch [2/20], Passed time:[59.141/118.283]
learning rate: 0.030000000000000006
Batch [0/704] training loss = 0.6545, training acc = 0.73
Batch [200/704] training loss = 0.7029, training acc = 0.75
Batch [400/704] training loss = 0.8943, training acc = 0.66
Batch [600/704] training loss = 0.7438, training acc = 0.78
Valid Test with nat
Test accuracy: 72.68% (3634/5000), Test loss:0.8355
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance20_m0.05_warmup0.1.pth
Test on test set:
Test accuracy: 71.46% (7146/10000), Test loss:0.8529
Epoch [3/20], Passed time:[61.468/184.405]
learning rate: 0.04000000000000001
Batch [0/704] training loss = 0.7311, training acc = 0.72
Batch [200/704] training loss = 0.8911, training acc = 0.70
Batch [400/704] training loss = 0.8777, training acc = 0.66
Batch [600/704] training loss = 0.7798, training acc = 0.72
Valid Test with nat
Test accuracy: 68.72% (3436/5000), Test loss:1.0101
Epoch [4/20], Passed time:[65.536/262.143]
learning rate: 0.05
Batch [0/704] training loss = 0.6461, training acc = 0.80
Batch [200/704] training loss = 0.7551, training acc = 0.70
Batch [400/704] training loss = 0.7488, training acc = 0.73
Batch [600/704] training loss = 0.5458, training acc = 0.80
Valid Test with nat
Test accuracy: 73.50% (3675/5000), Test loss:0.8056
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance20_m0.05_warmup0.1.pth
Test on test set:
Test accuracy: 72.42% (7242/10000), Test loss:0.8364
Epoch [5/20], Passed time:[71.011/355.054]
learning rate: 0.06000000000000001
Batch [0/704] training loss = 0.8252, training acc = 0.70
Batch [200/704] training loss = 0.3669, training acc = 0.92
Batch [400/704] training loss = 0.6847, training acc = 0.73
Batch [600/704] training loss = 0.6530, training acc = 0.77
Valid Test with nat
Test accuracy: 75.64% (3782/5000), Test loss:0.7284
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance20_m0.05_warmup0.1.pth
Test on test set:
Test accuracy: 74.22% (7422/10000), Test loss:0.7730
Epoch [6/20], Passed time:[75.326/451.959]
learning rate: 0.07
Batch [0/704] training loss = 0.6838, training acc = 0.83
Batch [200/704] training loss = 0.5340, training acc = 0.83
Batch [400/704] training loss = 0.8695, training acc = 0.73
Batch [600/704] training loss = 0.3837, training acc = 0.89
Valid Test with nat
Test accuracy: 76.34% (3817/5000), Test loss:0.7253
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance20_m0.05_warmup0.1.pth
Test on test set:
Test accuracy: 75.76% (7576/10000), Test loss:0.7270
Epoch [7/20], Passed time:[78.331/548.316]
learning rate: 0.08000000000000002
Batch [0/704] training loss = 0.6683, training acc = 0.80
Batch [200/704] training loss = 0.5056, training acc = 0.83
Batch [400/704] training loss = 0.3777, training acc = 0.92
Batch [600/704] training loss = 0.6059, training acc = 0.77
Valid Test with nat
Test accuracy: 75.50% (3775/5000), Test loss:0.7329
Epoch [8/20], Passed time:[79.792/638.337]
learning rate: 0.09000000000000001
Batch [0/704] training loss = 0.5346, training acc = 0.78
Batch [200/704] training loss = 0.6717, training acc = 0.73
Batch [400/704] training loss = 0.4247, training acc = 0.86
Batch [600/704] training loss = 0.5068, training acc = 0.77
Valid Test with nat
Test accuracy: 81.02% (4051/5000), Test loss:0.5812
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance20_m0.05_warmup0.1.pth
Test on test set:
Test accuracy: 80.73% (8073/10000), Test loss:0.5773
Epoch [9/20], Passed time:[80.857/727.712]
learning rate: 0.1
Batch [0/704] training loss = 0.6109, training acc = 0.84
Batch [200/704] training loss = 0.6688, training acc = 0.75
Batch [400/704] training loss = 0.5168, training acc = 0.81
Batch [600/704] training loss = 0.5358, training acc = 0.84
Valid Test with nat
Test accuracy: 74.06% (3703/5000), Test loss:0.8364
Epoch [10/20], Passed time:[81.401/814.012]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.3913, training acc = 0.88
Batch [200/704] training loss = 0.3966, training acc = 0.84
Batch [400/704] training loss = 0.3539, training acc = 0.88
Batch [600/704] training loss = 0.2919, training acc = 0.88
Valid Test with nat
Test accuracy: 87.16% (4358/5000), Test loss:0.3832
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance20_m0.05_warmup0.1.pth
Test on test set:
Test accuracy: 86.64% (8664/10000), Test loss:0.3959
Epoch [11/20], Passed time:[82.021/902.232]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.2626, training acc = 0.89
Batch [200/704] training loss = 0.3316, training acc = 0.91
Batch [400/704] training loss = 0.3192, training acc = 0.89
Batch [600/704] training loss = 0.3326, training acc = 0.88
Valid Test with nat
Test accuracy: 87.64% (4382/5000), Test loss:0.3978
Epoch [12/20], Passed time:[81.721/980.648]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.2356, training acc = 0.92
Batch [200/704] training loss = 0.4171, training acc = 0.88
Batch [400/704] training loss = 0.2320, training acc = 0.91
Batch [600/704] training loss = 0.3724, training acc = 0.86
Valid Test with nat
Test accuracy: 88.18% (4409/5000), Test loss:0.3621
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance20_m0.05_warmup0.1.pth
Test on test set:
Test accuracy: 87.63% (8763/10000), Test loss:0.3652
Epoch [13/20], Passed time:[82.456/1071.931]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.2441, training acc = 0.94
Batch [200/704] training loss = 0.3691, training acc = 0.84
Batch [400/704] training loss = 0.3619, training acc = 0.89
Batch [600/704] training loss = 0.1491, training acc = 0.95
Valid Test with nat
Test accuracy: 88.40% (4420/5000), Test loss:0.3616
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance20_m0.05_warmup0.1.pth
Test on test set:
Test accuracy: 87.80% (8780/10000), Test loss:0.3692
Epoch [14/20], Passed time:[82.688/1157.639]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.2424, training acc = 0.91
Batch [200/704] training loss = 0.1661, training acc = 0.97
Batch [400/704] training loss = 0.5006, training acc = 0.80
Batch [600/704] training loss = 0.4404, training acc = 0.84
Valid Test with nat
Test accuracy: 88.28% (4414/5000), Test loss:0.3555
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance20_m0.05_warmup0.1.pth
Test on test set:
Test accuracy: 87.90% (8790/10000), Test loss:0.3567
Epoch [15/20], Passed time:[82.746/1241.196]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.4504, training acc = 0.91
Batch [200/704] training loss = 0.3256, training acc = 0.89
Batch [400/704] training loss = 0.2602, training acc = 0.88
Batch [600/704] training loss = 0.2397, training acc = 0.88
Valid Test with nat
Test accuracy: 88.86% (4443/5000), Test loss:0.3539
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance20_m0.05_warmup0.1.pth
Test on test set:
Test accuracy: 88.03% (8803/10000), Test loss:0.3534
Epoch [16/20], Passed time:[82.574/1321.190]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.2085, training acc = 0.91
Batch [200/704] training loss = 0.1482, training acc = 0.97
Batch [400/704] training loss = 0.5253, training acc = 0.81
Batch [600/704] training loss = 0.3510, training acc = 0.89
Valid Test with nat
Test accuracy: 89.10% (4455/5000), Test loss:0.3437
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance20_m0.05_warmup0.1.pth
Test on test set:
Test accuracy: 88.22% (8822/10000), Test loss:0.3470
Epoch [17/20], Passed time:[83.348/1416.910]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.2703, training acc = 0.88
Batch [200/704] training loss = 0.2767, training acc = 0.91
Batch [400/704] training loss = 0.1634, training acc = 0.92
Batch [600/704] training loss = 0.2377, training acc = 0.92
Valid Test with nat
Test accuracy: 89.08% (4454/5000), Test loss:0.3451
Epoch [18/20], Passed time:[83.301/1499.423]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.3598, training acc = 0.88
Batch [200/704] training loss = 0.2946, training acc = 0.91
Batch [400/704] training loss = 0.2178, training acc = 0.91
Batch [600/704] training loss = 0.1270, training acc = 0.97
Valid Test with nat
Test accuracy: 89.02% (4451/5000), Test loss:0.3398
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance20_m0.05_warmup0.1.pth
Test on test set:
Test accuracy: 88.05% (8805/10000), Test loss:0.3517
Epoch [19/20], Passed time:[83.971/1595.451]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.3321, training acc = 0.86
Batch [200/704] training loss = 0.3391, training acc = 0.91
Batch [400/704] training loss = 0.2176, training acc = 0.92
Batch [600/704] training loss = 0.1754, training acc = 0.95
Valid Test with nat
Test accuracy: 89.08% (4454/5000), Test loss:0.3402
Training done, model saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance20_m0.05_warmup0.1.pth
Test on test set:
Test accuracy: 88.29% (8829/10000), Test loss:0.3492
