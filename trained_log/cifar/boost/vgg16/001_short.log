model_type : vgg16
init_type : pure
finetune_method : nat
enhance_method : nat
gpu : 5
model_name : short_enhance_001_mask_warmup
model_width : 8
n_pruning_steps : 1
max_pruning_ratio : 80
train_epochs : 50
enhance_epochs : 50
prune_method : unstructured
dataset : cifar
noise_sd : 1.0
trades_beta : 6.0
seed : 7
warmup : True
create_init : False
init_step : 1400
train_method : nat
early_stop : 50
norm : True
optm : sgd
batch_size : 64
test_batch_size : 100
learning_rate : 0.1
enhance_learning_rate : None
schedule_length : 10
weight_decay : 0.0001
epsilon : 0.03137254901960784
attack_iter : 10
eps_step : 0.00784313725490196
targeted : False
clip_min : 0
clip_max : 1.0
starting_epsilon : 1e-05
interval_weight : 0.1
ft_interval_weight : 50
verbose : 200
resume : 0
model_path : ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100/init_pure/short_enhance_001_mask_warmup.pth
mask_path : ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100/init_pure/pruned_001_mask_r80.npy
mask_name : pruned_001_mask_r80
log_path : ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100/init_pure/short_enhance_001_mask_warmup.log
init_path : ./trained_models_new/cifar/vgg16/init/pure_vgg16_init.pth
results_path : None
n_classes : 10
eval : False
init : True
CUDA enabled.
Enhance training config:
Enhance training method: nat
model will be saved in: ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100/init_pure/short_enhance_001_mask_warmup.pth
Init model is: ./trained_models_new/cifar/vgg16/init/pure_vgg16_init.pth
Init mask used from: ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100/init_pure/pruned_001_mask_r80.npy
Log will be saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100/init_pure/short_enhance_001_mask_warmup.log
Random seed is: 7

model loading from ./trained_models_new/cifar/vgg16/init/pure_vgg16_init.pth
Epoch [0/50]
learning rate: 0.01
Batch [0/704] training loss = 2.2368, training acc = 0.27
Batch [200/704] training loss = 1.0849, training acc = 0.66
Batch [400/704] training loss = 0.8304, training acc = 0.75
Batch [600/704] training loss = 0.3317, training acc = 0.94
Valid Test with nat
Test accuracy: 79.74% (3987/5000), Test loss:0.6243
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100/init_pure/short_enhance_001_mask_warmup.pth
Test on test set:
Test accuracy: 79.00% (7900/10000), Test loss:0.6328
Epoch [1/50], Passed time:[78.012/78.012]
learning rate: 0.02
Batch [0/704] training loss = 0.4406, training acc = 0.84
Batch [200/704] training loss = 0.6712, training acc = 0.81
Batch [400/704] training loss = 0.4918, training acc = 0.83
Batch [600/704] training loss = 0.4750, training acc = 0.83
Valid Test with nat
Test accuracy: 82.30% (4115/5000), Test loss:0.5502
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100/init_pure/short_enhance_001_mask_warmup.pth
Test on test set:
Test accuracy: 80.40% (8040/10000), Test loss:0.6003
Epoch [2/50], Passed time:[75.157/150.315]
learning rate: 0.03
Batch [0/704] training loss = 0.3508, training acc = 0.89
Batch [200/704] training loss = 0.3793, training acc = 0.89
Batch [400/704] training loss = 0.5343, training acc = 0.83
Batch [600/704] training loss = 0.4233, training acc = 0.84
Valid Test with nat
Test accuracy: 83.74% (4187/5000), Test loss:0.4822
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100/init_pure/short_enhance_001_mask_warmup.pth
Test on test set:
Test accuracy: 83.09% (8309/10000), Test loss:0.5240
Epoch [3/50], Passed time:[75.330/225.989]
learning rate: 0.04
Batch [0/704] training loss = 0.2814, training acc = 0.91
Batch [200/704] training loss = 0.6027, training acc = 0.77
Batch [400/704] training loss = 0.4404, training acc = 0.83
Batch [600/704] training loss = 0.5976, training acc = 0.80
Valid Test with nat
Test accuracy: 77.80% (3890/5000), Test loss:0.7098
Epoch [4/50], Passed time:[75.101/300.403]
learning rate: 0.05
Batch [0/704] training loss = 0.3112, training acc = 0.88
Batch [200/704] training loss = 0.5757, training acc = 0.80
Batch [400/704] training loss = 0.5428, training acc = 0.84
Batch [600/704] training loss = 0.3956, training acc = 0.91
Valid Test with nat
Test accuracy: 83.20% (4160/5000), Test loss:0.5192
Epoch [5/50], Passed time:[73.951/369.755]
learning rate: 0.060000000000000005
Batch [0/704] training loss = 0.3244, training acc = 0.88
Batch [200/704] training loss = 0.5876, training acc = 0.77
Batch [400/704] training loss = 0.3225, training acc = 0.86
Batch [600/704] training loss = 0.2993, training acc = 0.89
Valid Test with nat
Test accuracy: 80.56% (4028/5000), Test loss:0.6366
Epoch [6/50], Passed time:[73.676/442.058]
learning rate: 0.06999999999999999
Batch [0/704] training loss = 0.2875, training acc = 0.92
Batch [200/704] training loss = 0.3637, training acc = 0.91
Batch [400/704] training loss = 0.3584, training acc = 0.83
Batch [600/704] training loss = 0.4577, training acc = 0.84
Valid Test with nat
Test accuracy: 85.22% (4261/5000), Test loss:0.4667
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100/init_pure/short_enhance_001_mask_warmup.pth
Test on test set:
Test accuracy: 84.24% (8424/10000), Test loss:0.4882
Epoch [7/50], Passed time:[75.232/526.624]
learning rate: 0.08
Batch [0/704] training loss = 0.3343, training acc = 0.84
Batch [200/704] training loss = 0.3947, training acc = 0.86
Batch [400/704] training loss = 0.6474, training acc = 0.80
Batch [600/704] training loss = 0.5289, training acc = 0.84
Valid Test with nat
Test accuracy: 82.88% (4144/5000), Test loss:0.5253
Epoch [8/50], Passed time:[75.419/603.352]
learning rate: 0.09
Batch [0/704] training loss = 0.3023, training acc = 0.92
Batch [200/704] training loss = 0.5402, training acc = 0.84
Batch [400/704] training loss = 0.2995, training acc = 0.88
Batch [600/704] training loss = 0.2512, training acc = 0.94
Valid Test with nat
Test accuracy: 78.36% (3918/5000), Test loss:0.6930
Epoch [9/50], Passed time:[75.692/681.228]
learning rate: 0.09999999999999999
Batch [0/704] training loss = 0.3003, training acc = 0.89
Batch [200/704] training loss = 0.4511, training acc = 0.88
Batch [400/704] training loss = 0.4648, training acc = 0.91
Batch [600/704] training loss = 0.3297, training acc = 0.91
Valid Test with nat
Test accuracy: 83.30% (4165/5000), Test loss:0.5365
Epoch [10/50], Passed time:[75.736/757.355]
learning rate: 0.09999999999999999
Batch [0/704] training loss = 0.3884, training acc = 0.84
Batch [200/704] training loss = 0.5569, training acc = 0.80
Batch [400/704] training loss = 0.2678, training acc = 0.92
Batch [600/704] training loss = 0.4483, training acc = 0.86
Valid Test with nat
Test accuracy: 84.22% (4211/5000), Test loss:0.4933
Epoch [11/50], Passed time:[75.885/834.739]
learning rate: 0.09999999999999999
Batch [0/704] training loss = 0.2717, training acc = 0.89
Batch [200/704] training loss = 0.4350, training acc = 0.81
Batch [400/704] training loss = 0.3245, training acc = 0.92
Batch [600/704] training loss = 0.2286, training acc = 0.94
Valid Test with nat
Test accuracy: 81.68% (4084/5000), Test loss:0.5868
Epoch [12/50], Passed time:[76.042/912.499]
learning rate: 0.09999999999999999
Batch [0/704] training loss = 0.2095, training acc = 0.91
Batch [200/704] training loss = 0.3625, training acc = 0.89
Batch [400/704] training loss = 0.3837, training acc = 0.84
Batch [600/704] training loss = 0.4067, training acc = 0.88
Valid Test with nat
Test accuracy: 85.36% (4268/5000), Test loss:0.4532
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100/init_pure/short_enhance_001_mask_warmup.pth
Test on test set:
Test accuracy: 86.28% (8628/10000), Test loss:0.4267
Epoch [13/50], Passed time:[76.596/995.753]
learning rate: 0.09999999999999999
Batch [0/704] training loss = 0.3742, training acc = 0.89
Batch [200/704] training loss = 0.2628, training acc = 0.94
Batch [400/704] training loss = 0.2600, training acc = 0.94
Batch [600/704] training loss = 0.3069, training acc = 0.91
Valid Test with nat
Test accuracy: 86.46% (4323/5000), Test loss:0.4262
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100/init_pure/short_enhance_001_mask_warmup.pth
Test on test set:
Test accuracy: 86.31% (8631/10000), Test loss:0.4272
Epoch [14/50], Passed time:[77.119/1079.667]
learning rate: 0.09999999999999999
Batch [0/704] training loss = 0.2626, training acc = 0.92
Batch [200/704] training loss = 0.4492, training acc = 0.89
Batch [400/704] training loss = 0.4313, training acc = 0.81
Batch [600/704] training loss = 0.3183, training acc = 0.89
Valid Test with nat
Test accuracy: 85.56% (4278/5000), Test loss:0.4508
Epoch [15/50], Passed time:[77.197/1157.949]
learning rate: 0.09999999999999999
Batch [0/704] training loss = 0.3211, training acc = 0.94
Batch [200/704] training loss = 0.2235, training acc = 0.95
Batch [400/704] training loss = 0.5524, training acc = 0.84
Batch [600/704] training loss = 0.2058, training acc = 0.94
Valid Test with nat
Test accuracy: 86.24% (4312/5000), Test loss:0.4330
Epoch [16/50], Passed time:[77.240/1235.840]
learning rate: 0.09999999999999999
Batch [0/704] training loss = 0.2989, training acc = 0.92
Batch [200/704] training loss = 0.2755, training acc = 0.92
Batch [400/704] training loss = 0.4195, training acc = 0.86
Batch [600/704] training loss = 0.4798, training acc = 0.77
Valid Test with nat
Test accuracy: 86.62% (4331/5000), Test loss:0.4103
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100/init_pure/short_enhance_001_mask_warmup.pth
Test on test set:
Test accuracy: 85.74% (8574/10000), Test loss:0.4314
Epoch [17/50], Passed time:[77.365/1315.212]
learning rate: 0.09999999999999999
Batch [0/704] training loss = 0.3541, training acc = 0.89
Batch [200/704] training loss = 0.2722, training acc = 0.92
Batch [400/704] training loss = 0.1957, training acc = 0.94
Batch [600/704] training loss = 0.3061, training acc = 0.91
Valid Test with nat
Test accuracy: 86.42% (4321/5000), Test loss:0.4271
Epoch [18/50], Passed time:[77.421/1393.570]
learning rate: 0.09999999999999999
Batch [0/704] training loss = 0.2154, training acc = 0.94
Batch [200/704] training loss = 0.2302, training acc = 0.92
Batch [400/704] training loss = 0.2936, training acc = 0.92
Batch [600/704] training loss = 0.2831, training acc = 0.94
Valid Test with nat
Test accuracy: 81.74% (4087/5000), Test loss:0.5908
Epoch [19/50], Passed time:[77.375/1470.131]
learning rate: 0.09999999999999999
Batch [0/704] training loss = 0.3989, training acc = 0.89
Batch [200/704] training loss = 0.2335, training acc = 0.92
Batch [400/704] training loss = 0.1828, training acc = 0.95
Batch [600/704] training loss = 0.4047, training acc = 0.88
Valid Test with nat
Test accuracy: 82.96% (4148/5000), Test loss:0.5552
Epoch [20/50], Passed time:[77.319/1546.388]
learning rate: 0.09999999999999999
Batch [0/704] training loss = 0.3019, training acc = 0.92
Batch [200/704] training loss = 0.3114, training acc = 0.91
Batch [400/704] training loss = 0.3666, training acc = 0.88
Batch [600/704] training loss = 0.3101, training acc = 0.86
Valid Test with nat
Test accuracy: 85.74% (4287/5000), Test loss:0.4458
Epoch [21/50], Passed time:[77.259/1622.445]
learning rate: 0.09999999999999999
Batch [0/704] training loss = 0.2605, training acc = 0.91
Batch [200/704] training loss = 0.1950, training acc = 0.92
Batch [400/704] training loss = 0.3011, training acc = 0.91
Batch [600/704] training loss = 0.2579, training acc = 0.92
Valid Test with nat
Test accuracy: 86.46% (4323/5000), Test loss:0.4637
Epoch [22/50], Passed time:[77.537/1705.803]
learning rate: 0.09999999999999999
Batch [0/704] training loss = 0.2278, training acc = 0.92
Batch [200/704] training loss = 0.3859, training acc = 0.91
Batch [400/704] training loss = 0.2386, training acc = 0.94
Batch [600/704] training loss = 0.2797, training acc = 0.89
Valid Test with nat
Test accuracy: 85.52% (4276/5000), Test loss:0.4608
Epoch [23/50], Passed time:[77.487/1782.192]
learning rate: 0.09999999999999999
Batch [0/704] training loss = 0.2824, training acc = 0.91
Batch [200/704] training loss = 0.1549, training acc = 0.97
Batch [400/704] training loss = 0.2972, training acc = 0.94
Batch [600/704] training loss = 0.2368, training acc = 0.92
Valid Test with nat
Test accuracy: 84.22% (4211/5000), Test loss:0.4897
Epoch [24/50], Passed time:[77.448/1858.759]
learning rate: 0.09999999999999999
Batch [0/704] training loss = 0.3134, training acc = 0.89
Batch [200/704] training loss = 0.2888, training acc = 0.91
Batch [400/704] training loss = 0.2831, training acc = 0.92
Batch [600/704] training loss = 0.2082, training acc = 0.91
Valid Test with nat
Test accuracy: 84.82% (4241/5000), Test loss:0.4676
Epoch [25/50], Passed time:[77.552/1938.806]
learning rate: 0.01
Batch [0/704] training loss = 0.3346, training acc = 0.88
Batch [200/704] training loss = 0.2116, training acc = 0.92
Batch [400/704] training loss = 0.3239, training acc = 0.89
Batch [600/704] training loss = 0.2015, training acc = 0.94
Valid Test with nat
Test accuracy: 91.04% (4552/5000), Test loss:0.2801
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100/init_pure/short_enhance_001_mask_warmup.pth
Test on test set:
Test accuracy: 91.18% (9118/10000), Test loss:0.2730
Epoch [26/50], Passed time:[77.828/2023.519]
learning rate: 0.01
Batch [0/704] training loss = 0.1439, training acc = 0.97
Batch [200/704] training loss = 0.2889, training acc = 0.89
Batch [400/704] training loss = 0.1917, training acc = 0.97
Batch [600/704] training loss = 0.1432, training acc = 0.95
Valid Test with nat
Test accuracy: 91.50% (4575/5000), Test loss:0.2676
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100/init_pure/short_enhance_001_mask_warmup.pth
Test on test set:
Test accuracy: 91.51% (9151/10000), Test loss:0.2648
Epoch [27/50], Passed time:[77.934/2104.208]
learning rate: 0.01
Batch [0/704] training loss = 0.1203, training acc = 0.97
Batch [200/704] training loss = 0.1839, training acc = 0.91
Batch [400/704] training loss = 0.1076, training acc = 0.95
Batch [600/704] training loss = 0.1463, training acc = 0.95
Valid Test with nat
Test accuracy: 91.46% (4573/5000), Test loss:0.2672
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100/init_pure/short_enhance_001_mask_warmup.pth
Test on test set:
Test accuracy: 91.55% (9155/10000), Test loss:0.2657
Epoch [28/50], Passed time:[78.268/2191.499]
learning rate: 0.01
Batch [0/704] training loss = 0.1361, training acc = 0.97
Batch [200/704] training loss = 0.1186, training acc = 0.95
Batch [400/704] training loss = 0.0847, training acc = 0.98
Batch [600/704] training loss = 0.2575, training acc = 0.92
Valid Test with nat
Test accuracy: 91.66% (4583/5000), Test loss:0.2714
Epoch [29/50], Passed time:[78.277/2270.019]
learning rate: 0.01
Batch [0/704] training loss = 0.0822, training acc = 0.97
Batch [200/704] training loss = 0.1190, training acc = 0.95
Batch [400/704] training loss = 0.1117, training acc = 0.95
Batch [600/704] training loss = 0.1343, training acc = 0.94
Valid Test with nat
Test accuracy: 91.60% (4580/5000), Test loss:0.2804
Epoch [30/50], Passed time:[78.232/2346.966]
learning rate: 0.01
Batch [0/704] training loss = 0.0581, training acc = 0.97
Batch [200/704] training loss = 0.0830, training acc = 0.97
Batch [400/704] training loss = 0.0602, training acc = 0.97
Batch [600/704] training loss = 0.1021, training acc = 0.98
Valid Test with nat
Test accuracy: 91.80% (4590/5000), Test loss:0.2799
Epoch [31/50], Passed time:[78.130/2422.037]
learning rate: 0.01
Batch [0/704] training loss = 0.0840, training acc = 0.97
Batch [200/704] training loss = 0.0768, training acc = 0.98
Batch [400/704] training loss = 0.1103, training acc = 0.94
Batch [600/704] training loss = 0.0286, training acc = 1.00
Valid Test with nat
Test accuracy: 91.66% (4583/5000), Test loss:0.2695
Epoch [32/50], Passed time:[78.222/2503.115]
learning rate: 0.01
Batch [0/704] training loss = 0.0618, training acc = 0.98
Batch [200/704] training loss = 0.0919, training acc = 0.97
Batch [400/704] training loss = 0.1160, training acc = 0.94
Batch [600/704] training loss = 0.2607, training acc = 0.94
Valid Test with nat
Test accuracy: 91.50% (4575/5000), Test loss:0.2817
Epoch [33/50], Passed time:[78.281/2583.281]
learning rate: 0.01
Batch [0/704] training loss = 0.1146, training acc = 0.95
Batch [200/704] training loss = 0.1309, training acc = 0.97
Batch [400/704] training loss = 0.0985, training acc = 0.97
Batch [600/704] training loss = 0.0462, training acc = 1.00
Valid Test with nat
Test accuracy: 91.16% (4558/5000), Test loss:0.2993
Epoch [34/50], Passed time:[78.435/2666.786]
learning rate: 0.01
Batch [0/704] training loss = 0.0571, training acc = 0.97
Batch [200/704] training loss = 0.1111, training acc = 0.94
Batch [400/704] training loss = 0.1338, training acc = 0.95
Batch [600/704] training loss = 0.2447, training acc = 0.92
Valid Test with nat
Test accuracy: 91.86% (4593/5000), Test loss:0.2816
Epoch [35/50], Passed time:[78.501/2747.532]
learning rate: 0.01
Batch [0/704] training loss = 0.0395, training acc = 0.98
Batch [200/704] training loss = 0.0326, training acc = 0.98
Batch [400/704] training loss = 0.0298, training acc = 0.98
Batch [600/704] training loss = 0.0985, training acc = 0.98
Valid Test with nat
Test accuracy: 92.14% (4607/5000), Test loss:0.2769
Epoch [36/50], Passed time:[78.548/2827.733]
learning rate: 0.01
Batch [0/704] training loss = 0.0954, training acc = 0.97
Batch [200/704] training loss = 0.0664, training acc = 0.97
Batch [400/704] training loss = 0.0647, training acc = 0.98
Batch [600/704] training loss = 0.0999, training acc = 0.97
Valid Test with nat
Test accuracy: 91.58% (4579/5000), Test loss:0.2957
Epoch [37/50], Passed time:[78.629/2909.259]
learning rate: 0.01
Batch [0/704] training loss = 0.0261, training acc = 1.00
Batch [200/704] training loss = 0.1396, training acc = 0.92
Batch [400/704] training loss = 0.1963, training acc = 0.95
Batch [600/704] training loss = 0.0660, training acc = 0.97
Valid Test with nat
Test accuracy: 91.70% (4585/5000), Test loss:0.2810
Epoch [38/50], Passed time:[78.524/2983.910]
learning rate: 0.001
Batch [0/704] training loss = 0.0394, training acc = 1.00
Batch [200/704] training loss = 0.0641, training acc = 0.98
Batch [400/704] training loss = 0.0397, training acc = 0.98
Batch [600/704] training loss = 0.0346, training acc = 0.98
Valid Test with nat
Test accuracy: 92.10% (4605/5000), Test loss:0.2767
Epoch [39/50], Passed time:[78.499/3061.469]
learning rate: 0.001
Batch [0/704] training loss = 0.0836, training acc = 0.97
Batch [200/704] training loss = 0.1246, training acc = 0.97
Batch [400/704] training loss = 0.1037, training acc = 0.97
Batch [600/704] training loss = 0.1204, training acc = 0.97
Valid Test with nat
Test accuracy: 92.24% (4612/5000), Test loss:0.2729
Epoch [40/50], Passed time:[78.480/3139.201]
learning rate: 0.001
Batch [0/704] training loss = 0.1027, training acc = 0.94
Batch [200/704] training loss = 0.1831, training acc = 0.95
Batch [400/704] training loss = 0.0609, training acc = 0.97
Batch [600/704] training loss = 0.1587, training acc = 0.92
Valid Test with nat
Test accuracy: 92.42% (4621/5000), Test loss:0.2716
Epoch [41/50], Passed time:[78.441/3216.068]
learning rate: 0.001
Batch [0/704] training loss = 0.0484, training acc = 0.98
Batch [200/704] training loss = 0.0723, training acc = 0.98
Batch [400/704] training loss = 0.0498, training acc = 0.98
Batch [600/704] training loss = 0.0205, training acc = 1.00
Valid Test with nat
Test accuracy: 92.30% (4615/5000), Test loss:0.2793
Epoch [42/50], Passed time:[78.473/3295.881]
learning rate: 0.001
Batch [0/704] training loss = 0.1405, training acc = 0.95
Batch [200/704] training loss = 0.0360, training acc = 0.98
Batch [400/704] training loss = 0.0337, training acc = 1.00
Batch [600/704] training loss = 0.0562, training acc = 0.95
Valid Test with nat
Test accuracy: 92.34% (4617/5000), Test loss:0.2714
Epoch [43/50], Passed time:[78.500/3375.510]
learning rate: 0.001
Batch [0/704] training loss = 0.0637, training acc = 0.98
Batch [200/704] training loss = 0.0552, training acc = 0.97
Batch [400/704] training loss = 0.0323, training acc = 0.98
Batch [600/704] training loss = 0.0275, training acc = 0.98
Valid Test with nat
Test accuracy: 92.06% (4603/5000), Test loss:0.2746
Epoch [44/50], Passed time:[78.491/3453.586]
learning rate: 0.001
Batch [0/704] training loss = 0.0287, training acc = 1.00
Batch [200/704] training loss = 0.0378, training acc = 0.98
Batch [400/704] training loss = 0.0680, training acc = 0.97
Batch [600/704] training loss = 0.1311, training acc = 0.94
Valid Test with nat
Test accuracy: 92.06% (4603/5000), Test loss:0.2787
Epoch [45/50], Passed time:[78.477/3531.476]
learning rate: 0.001
Batch [0/704] training loss = 0.0218, training acc = 1.00
Batch [200/704] training loss = 0.2482, training acc = 0.94
Batch [400/704] training loss = 0.0100, training acc = 1.00
Batch [600/704] training loss = 0.0965, training acc = 0.95
Valid Test with nat
Test accuracy: 92.24% (4612/5000), Test loss:0.2945
Epoch [46/50], Passed time:[78.517/3611.791]
learning rate: 0.001
Batch [0/704] training loss = 0.0453, training acc = 0.97
Batch [200/704] training loss = 0.1078, training acc = 0.97
Batch [400/704] training loss = 0.1337, training acc = 0.95
Batch [600/704] training loss = 0.0135, training acc = 1.00
Valid Test with nat
Test accuracy: 92.26% (4613/5000), Test loss:0.2889
Epoch [47/50], Passed time:[78.539/3691.340]
learning rate: 0.001
Batch [0/704] training loss = 0.0389, training acc = 0.98
Batch [200/704] training loss = 0.0356, training acc = 0.98
Batch [400/704] training loss = 0.0331, training acc = 1.00
Batch [600/704] training loss = 0.0724, training acc = 0.98
Valid Test with nat
Test accuracy: 92.14% (4607/5000), Test loss:0.2756
Epoch [48/50], Passed time:[78.616/3773.584]
learning rate: 0.001
Batch [0/704] training loss = 0.0311, training acc = 1.00
Batch [200/704] training loss = 0.0773, training acc = 0.98
Batch [400/704] training loss = 0.1369, training acc = 0.98
Batch [600/704] training loss = 0.0535, training acc = 0.97
Valid Test with nat
Test accuracy: 92.16% (4608/5000), Test loss:0.2745
Epoch [49/50], Passed time:[78.335/3838.403]
learning rate: 0.001
Batch [0/704] training loss = 0.1404, training acc = 0.95
Batch [200/704] training loss = 0.1902, training acc = 0.97
Batch [400/704] training loss = 0.0338, training acc = 0.98
Batch [600/704] training loss = 0.1118, training acc = 0.95
Valid Test with nat
Test accuracy: 92.22% (4611/5000), Test loss:0.2757
Training done, model saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100/init_pure/short_enhance_001_mask_warmup.pth
Test on test set:
Test accuracy: 92.07% (9207/10000), Test loss:0.2766
