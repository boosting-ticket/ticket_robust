model_type : vgg16
init_type : pure
finetune_method : nat
enhance_method : nat
gpu : 5
model_name : init_enhance_m0.01_warmup0.1
model_width : 8
n_pruning_steps : 1
max_pruning_ratio : 65
train_epochs : 100
enhance_epochs : None
prune_method : unstructured
dataset : cifar
noise_sd : 1.0
trades_beta : 6.0
seed : 7
warmup : True
create_init : False
init_step : 1400
train_method : nat
early_stop : 50
norm : True
optm : sgd
batch_size : 64
test_batch_size : 100
learning_rate : 0.1
enhance_learning_rate : 0.1
schedule_length : 10
weight_decay : 0.0001
epsilon : 0.03137254901960784
attack_iter : 10
eps_step : 0.00784313725490196
targeted : False
clip_min : 0
clip_max : 1.0
starting_epsilon : 1e-05
interval_weight : 0.1
ft_interval_weight : 50
verbose : 200
resume : 0
model_path : ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r65/init_pure/init_enhance_m0.01_warmup0.1.pth
last_model_path : ./trained_models_new/
mask_path : ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r65/init_pure/pruned_lr0.01_mask_r65.npy
mask_name : pruned_lr0.01_mask_r65
log_path : ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r65/init_pure/init_enhance_m0.01_warmup0.1.log
init_path : ./trained_models_new/cifar/vgg16/init/pure_vgg16_init.pth
results_path : None
n_classes : 10
eval : False
init : True
transfer : False
CUDA enabled.
Enhance training config:
Enhance training method: nat
model will be saved in: ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r65/init_pure/init_enhance_m0.01_warmup0.1.pth
Init model is: ./trained_models_new/cifar/vgg16/init/pure_vgg16_init.pth
Init mask used from: ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r65/init_pure/pruned_lr0.01_mask_r65.npy
Log will be saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r65/init_pure/init_enhance_m0.01_warmup0.1.log
Random seed is: 7

model loading from ./trained_models_new/cifar/vgg16/init/pure_vgg16_init.pth
Epoch [0/100]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 2.1880, training acc = 0.20
Batch [200/704] training loss = 1.0264, training acc = 0.69
Batch [400/704] training loss = 0.8373, training acc = 0.72
Batch [600/704] training loss = 0.3575, training acc = 0.89
Valid Test with nat
Test accuracy: 79.96% (3998/5000), Test loss:0.6118
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r65/init_pure/init_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 80.18% (8018/10000), Test loss:0.5945
Epoch [1/100], Passed time:[80.328/80.328]
learning rate: 0.020000000000000004
Batch [0/704] training loss = 0.4394, training acc = 0.83
Batch [200/704] training loss = 0.7443, training acc = 0.78
Batch [400/704] training loss = 0.4980, training acc = 0.83
Batch [600/704] training loss = 0.5479, training acc = 0.80
Valid Test with nat
Test accuracy: 81.82% (4091/5000), Test loss:0.5757
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r65/init_pure/init_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 80.84% (8084/10000), Test loss:0.5636
Epoch [2/100], Passed time:[78.426/156.853]
learning rate: 0.030000000000000006
Batch [0/704] training loss = 0.4134, training acc = 0.88
Batch [200/704] training loss = 0.3307, training acc = 0.88
Batch [400/704] training loss = 0.5595, training acc = 0.75
Batch [600/704] training loss = 0.6436, training acc = 0.75
Valid Test with nat
Test accuracy: 83.92% (4196/5000), Test loss:0.4803
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r65/init_pure/init_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 82.69% (8269/10000), Test loss:0.5229
Epoch [3/100], Passed time:[78.028/234.084]
learning rate: 0.04000000000000001
Batch [0/704] training loss = 0.3458, training acc = 0.84
Batch [200/704] training loss = 0.6130, training acc = 0.78
Batch [400/704] training loss = 0.5730, training acc = 0.83
Batch [600/704] training loss = 0.3882, training acc = 0.88
Valid Test with nat
Test accuracy: 80.80% (4040/5000), Test loss:0.5877
Epoch [4/100], Passed time:[77.307/309.228]
learning rate: 0.05
Batch [0/704] training loss = 0.3417, training acc = 0.88
Batch [200/704] training loss = 0.5599, training acc = 0.80
Batch [400/704] training loss = 0.2863, training acc = 0.89
Batch [600/704] training loss = 0.4448, training acc = 0.88
Valid Test with nat
Test accuracy: 82.52% (4126/5000), Test loss:0.5123
Epoch [5/100], Passed time:[76.566/382.828]
learning rate: 0.06000000000000001
Batch [0/704] training loss = 0.3058, training acc = 0.89
Batch [200/704] training loss = 0.3891, training acc = 0.86
Batch [400/704] training loss = 0.4452, training acc = 0.81
Batch [600/704] training loss = 0.2723, training acc = 0.91
Valid Test with nat
Test accuracy: 78.02% (3901/5000), Test loss:0.7237
Epoch [6/100], Passed time:[76.940/461.638]
learning rate: 0.07
Batch [0/704] training loss = 0.2418, training acc = 0.92
Batch [200/704] training loss = 0.2998, training acc = 0.88
Batch [400/704] training loss = 0.4602, training acc = 0.83
Batch [600/704] training loss = 0.4699, training acc = 0.83
Valid Test with nat
Test accuracy: 84.52% (4226/5000), Test loss:0.5012
Epoch [7/100], Passed time:[75.596/529.174]
learning rate: 0.08000000000000002
Batch [0/704] training loss = 0.1188, training acc = 1.00
Batch [200/704] training loss = 0.4710, training acc = 0.84
Batch [400/704] training loss = 0.4692, training acc = 0.86
Batch [600/704] training loss = 0.1873, training acc = 0.92
Valid Test with nat
Test accuracy: 82.58% (4129/5000), Test loss:0.5481
Epoch [8/100], Passed time:[75.304/602.431]
learning rate: 0.09000000000000001
Batch [0/704] training loss = 0.5094, training acc = 0.80
Batch [200/704] training loss = 0.2917, training acc = 0.94
Batch [400/704] training loss = 0.5785, training acc = 0.80
Batch [600/704] training loss = 0.5462, training acc = 0.81
Valid Test with nat
Test accuracy: 83.38% (4169/5000), Test loss:0.4971
Epoch [9/100], Passed time:[75.010/675.090]
learning rate: 0.1
Batch [0/704] training loss = 0.3967, training acc = 0.91
Batch [200/704] training loss = 0.4384, training acc = 0.80
Batch [400/704] training loss = 0.2577, training acc = 0.92
Batch [600/704] training loss = 0.3320, training acc = 0.84
Valid Test with nat
Test accuracy: 84.70% (4235/5000), Test loss:0.4787
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r65/init_pure/init_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 85.43% (8543/10000), Test loss:0.4497
Epoch [10/100], Passed time:[75.690/756.903]
learning rate: 0.1
Batch [0/704] training loss = 0.3379, training acc = 0.86
Batch [200/704] training loss = 0.5236, training acc = 0.83
Batch [400/704] training loss = 0.3025, training acc = 0.88
Batch [600/704] training loss = 0.3722, training acc = 0.84
Valid Test with nat
Test accuracy: 84.08% (4204/5000), Test loss:0.5075
Epoch [11/100], Passed time:[75.782/833.604]
learning rate: 0.1
Batch [0/704] training loss = 0.3482, training acc = 0.92
Batch [200/704] training loss = 0.4320, training acc = 0.86
Batch [400/704] training loss = 0.4108, training acc = 0.89
Batch [600/704] training loss = 0.1613, training acc = 0.95
Valid Test with nat
Test accuracy: 82.86% (4143/5000), Test loss:0.5551
Epoch [12/100], Passed time:[76.389/916.670]
learning rate: 0.1
Batch [0/704] training loss = 0.3932, training acc = 0.89
Batch [200/704] training loss = 0.3252, training acc = 0.91
Batch [400/704] training loss = 0.2281, training acc = 0.91
Batch [600/704] training loss = 0.4258, training acc = 0.89
Valid Test with nat
Test accuracy: 85.58% (4279/5000), Test loss:0.4674
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r65/init_pure/init_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 84.99% (8499/10000), Test loss:0.4652
Epoch [13/100], Passed time:[76.423/993.494]
learning rate: 0.1
Batch [0/704] training loss = 0.3617, training acc = 0.86
Batch [200/704] training loss = 0.2437, training acc = 0.94
Batch [400/704] training loss = 0.2597, training acc = 0.88
Batch [600/704] training loss = 0.3012, training acc = 0.86
Valid Test with nat
Test accuracy: 86.50% (4325/5000), Test loss:0.4154
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r65/init_pure/init_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 86.79% (8679/10000), Test loss:0.4112
Epoch [14/100], Passed time:[76.960/1077.440]
learning rate: 0.1
Batch [0/704] training loss = 0.2367, training acc = 0.92
Batch [200/704] training loss = 0.4061, training acc = 0.88
Batch [400/704] training loss = 0.3848, training acc = 0.84
Batch [600/704] training loss = 0.2448, training acc = 0.92
Valid Test with nat
Test accuracy: 85.24% (4262/5000), Test loss:0.4729
Epoch [15/100], Passed time:[77.009/1155.134]
learning rate: 0.1
Batch [0/704] training loss = 0.4612, training acc = 0.86
Batch [200/704] training loss = 0.1526, training acc = 0.97
Batch [400/704] training loss = 0.5657, training acc = 0.80
Batch [600/704] training loss = 0.2972, training acc = 0.89
Valid Test with nat
Test accuracy: 86.94% (4347/5000), Test loss:0.4214
Epoch [16/100], Passed time:[77.188/1235.011]
learning rate: 0.1
Batch [0/704] training loss = 0.2942, training acc = 0.89
Batch [200/704] training loss = 0.1945, training acc = 0.94
Batch [400/704] training loss = 0.3594, training acc = 0.86
Batch [600/704] training loss = 0.3601, training acc = 0.88
Valid Test with nat
Test accuracy: 87.68% (4384/5000), Test loss:0.3951
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r65/init_pure/init_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 87.22% (8722/10000), Test loss:0.4013
Epoch [17/100], Passed time:[77.693/1320.782]
learning rate: 0.1
Batch [0/704] training loss = 0.2890, training acc = 0.89
Batch [200/704] training loss = 0.2523, training acc = 0.91
Batch [400/704] training loss = 0.2284, training acc = 0.94
Batch [600/704] training loss = 0.3858, training acc = 0.86
Valid Test with nat
Test accuracy: 87.66% (4383/5000), Test loss:0.3995
Epoch [18/100], Passed time:[77.640/1397.527]
learning rate: 0.1
Batch [0/704] training loss = 0.2914, training acc = 0.95
Batch [200/704] training loss = 0.3924, training acc = 0.83
Batch [400/704] training loss = 0.3523, training acc = 0.89
Batch [600/704] training loss = 0.3742, training acc = 0.89
Valid Test with nat
Test accuracy: 86.00% (4300/5000), Test loss:0.4410
Epoch [19/100], Passed time:[77.458/1471.702]
learning rate: 0.1
Batch [0/704] training loss = 0.3275, training acc = 0.91
Batch [200/704] training loss = 0.2689, training acc = 0.88
Batch [400/704] training loss = 0.2220, training acc = 0.94
Batch [600/704] training loss = 0.4666, training acc = 0.86
Valid Test with nat
Test accuracy: 85.46% (4273/5000), Test loss:0.4449
Epoch [20/100], Passed time:[77.239/1544.788]
learning rate: 0.1
Batch [0/704] training loss = 0.2044, training acc = 0.94
Batch [200/704] training loss = 0.4271, training acc = 0.86
Batch [400/704] training loss = 0.3840, training acc = 0.84
Batch [600/704] training loss = 0.2549, training acc = 0.89
Valid Test with nat
Test accuracy: 84.66% (4233/5000), Test loss:0.5154
Epoch [21/100], Passed time:[77.133/1619.788]
learning rate: 0.1
Batch [0/704] training loss = 0.3366, training acc = 0.88
Batch [200/704] training loss = 0.2392, training acc = 0.91
Batch [400/704] training loss = 0.3709, training acc = 0.89
Batch [600/704] training loss = 0.2916, training acc = 0.94
Valid Test with nat
Test accuracy: 86.00% (4300/5000), Test loss:0.4434
Epoch [22/100], Passed time:[77.080/1695.765]
learning rate: 0.1
Batch [0/704] training loss = 0.1843, training acc = 0.91
Batch [200/704] training loss = 0.3445, training acc = 0.88
Batch [400/704] training loss = 0.2559, training acc = 0.91
Batch [600/704] training loss = 0.2896, training acc = 0.89
Valid Test with nat
Test accuracy: 86.58% (4329/5000), Test loss:0.4254
Epoch [23/100], Passed time:[76.965/1770.186]
learning rate: 0.1
Batch [0/704] training loss = 0.2188, training acc = 0.89
Batch [200/704] training loss = 0.2409, training acc = 0.92
Batch [400/704] training loss = 0.2147, training acc = 0.89
Batch [600/704] training loss = 0.1920, training acc = 0.89
Valid Test with nat
Test accuracy: 85.78% (4289/5000), Test loss:0.4604
Epoch [24/100], Passed time:[76.730/1841.525]
learning rate: 0.1
Batch [0/704] training loss = 0.3372, training acc = 0.86
Batch [200/704] training loss = 0.2633, training acc = 0.91
Batch [400/704] training loss = 0.3033, training acc = 0.91
Batch [600/704] training loss = 0.2171, training acc = 0.94
Valid Test with nat
Test accuracy: 87.22% (4361/5000), Test loss:0.3913
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r65/init_pure/init_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 87.47% (8747/10000), Test loss:0.3893
Epoch [25/100], Passed time:[77.220/1930.503]
learning rate: 0.1
Batch [0/704] training loss = 0.4398, training acc = 0.86
Batch [200/704] training loss = 0.1676, training acc = 0.94
Batch [400/704] training loss = 0.2360, training acc = 0.92
Batch [600/704] training loss = 0.1951, training acc = 0.92
Valid Test with nat
Test accuracy: 87.36% (4368/5000), Test loss:0.3772
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r65/init_pure/init_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 87.45% (8745/10000), Test loss:0.3846
Epoch [26/100], Passed time:[77.422/2012.971]
learning rate: 0.1
Batch [0/704] training loss = 0.1687, training acc = 0.97
Batch [200/704] training loss = 0.3141, training acc = 0.88
Batch [400/704] training loss = 0.2425, training acc = 0.94
Batch [600/704] training loss = 0.3854, training acc = 0.88
Valid Test with nat
Test accuracy: 85.16% (4258/5000), Test loss:0.4691
Epoch [27/100], Passed time:[77.414/2090.184]
learning rate: 0.1
Batch [0/704] training loss = 0.3611, training acc = 0.88
Batch [200/704] training loss = 0.4570, training acc = 0.83
Batch [400/704] training loss = 0.2469, training acc = 0.91
Batch [600/704] training loss = 0.3418, training acc = 0.83
Valid Test with nat
Test accuracy: 86.46% (4323/5000), Test loss:0.4109
Epoch [28/100], Passed time:[77.371/2166.377]
learning rate: 0.1
Batch [0/704] training loss = 0.1766, training acc = 0.94
Batch [200/704] training loss = 0.4182, training acc = 0.88
Batch [400/704] training loss = 0.3412, training acc = 0.88
Batch [600/704] training loss = 0.1711, training acc = 0.92
Valid Test with nat
Test accuracy: 87.94% (4397/5000), Test loss:0.3938
Epoch [29/100], Passed time:[77.400/2244.599]
learning rate: 0.1
Batch [0/704] training loss = 0.2812, training acc = 0.84
Batch [200/704] training loss = 0.2049, training acc = 0.91
Batch [400/704] training loss = 0.4464, training acc = 0.83
Batch [600/704] training loss = 0.3363, training acc = 0.88
Valid Test with nat
Test accuracy: 86.16% (4308/5000), Test loss:0.4566
Epoch [30/100], Passed time:[77.342/2320.272]
learning rate: 0.1
Batch [0/704] training loss = 0.2659, training acc = 0.88
Batch [200/704] training loss = 0.1423, training acc = 0.94
Batch [400/704] training loss = 0.3308, training acc = 0.88
Batch [600/704] training loss = 0.4612, training acc = 0.88
Valid Test with nat
Test accuracy: 86.38% (4319/5000), Test loss:0.4488
Epoch [31/100], Passed time:[77.612/2405.987]
learning rate: 0.1
Batch [0/704] training loss = 0.1477, training acc = 0.95
Batch [200/704] training loss = 0.2255, training acc = 0.91
Batch [400/704] training loss = 0.2153, training acc = 0.91
Batch [600/704] training loss = 0.4279, training acc = 0.83
Valid Test with nat
Test accuracy: 86.82% (4341/5000), Test loss:0.4141
Epoch [32/100], Passed time:[77.663/2485.202]
learning rate: 0.1
Batch [0/704] training loss = 0.2752, training acc = 0.91
Batch [200/704] training loss = 0.3456, training acc = 0.89
Batch [400/704] training loss = 0.2883, training acc = 0.92
Batch [600/704] training loss = 0.3133, training acc = 0.92
Valid Test with nat
Test accuracy: 84.36% (4218/5000), Test loss:0.4899
Epoch [33/100], Passed time:[77.646/2562.327]
learning rate: 0.1
Batch [0/704] training loss = 0.2033, training acc = 0.91
Batch [200/704] training loss = 0.1815, training acc = 0.94
Batch [400/704] training loss = 0.1872, training acc = 0.95
Batch [600/704] training loss = 0.4369, training acc = 0.84
Valid Test with nat
Test accuracy: 87.58% (4379/5000), Test loss:0.3825
Epoch [34/100], Passed time:[77.766/2644.051]
learning rate: 0.1
Batch [0/704] training loss = 0.2335, training acc = 0.91
Batch [200/704] training loss = 0.2781, training acc = 0.94
Batch [400/704] training loss = 0.3844, training acc = 0.88
Batch [600/704] training loss = 0.2098, training acc = 0.91
Valid Test with nat
Test accuracy: 87.00% (4350/5000), Test loss:0.4185
Epoch [35/100], Passed time:[77.833/2724.165]
learning rate: 0.1
Batch [0/704] training loss = 0.6399, training acc = 0.81
Batch [200/704] training loss = 0.2999, training acc = 0.84
Batch [400/704] training loss = 0.1902, training acc = 0.92
Batch [600/704] training loss = 0.3517, training acc = 0.88
Valid Test with nat
Test accuracy: 87.86% (4393/5000), Test loss:0.3692
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r65/init_pure/init_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 87.76% (8776/10000), Test loss:0.3800
Epoch [36/100], Passed time:[78.013/2808.456]
learning rate: 0.1
Batch [0/704] training loss = 0.4183, training acc = 0.86
Batch [200/704] training loss = 0.2314, training acc = 0.91
Batch [400/704] training loss = 0.3987, training acc = 0.86
Batch [600/704] training loss = 0.1844, training acc = 0.94
Valid Test with nat
Test accuracy: 87.96% (4398/5000), Test loss:0.3817
Epoch [37/100], Passed time:[77.984/2885.395]
learning rate: 0.1
Batch [0/704] training loss = 0.1287, training acc = 0.95
Batch [200/704] training loss = 0.3893, training acc = 0.89
Batch [400/704] training loss = 0.2719, training acc = 0.89
Batch [600/704] training loss = 0.5479, training acc = 0.83
Valid Test with nat
Test accuracy: 86.56% (4328/5000), Test loss:0.4385
Epoch [38/100], Passed time:[77.949/2962.047]
learning rate: 0.1
Batch [0/704] training loss = 0.2813, training acc = 0.89
Batch [200/704] training loss = 0.2498, training acc = 0.94
Batch [400/704] training loss = 0.2177, training acc = 0.91
Batch [600/704] training loss = 0.1922, training acc = 0.95
Valid Test with nat
Test accuracy: 86.70% (4335/5000), Test loss:0.4337
Epoch [39/100], Passed time:[77.888/3037.624]
learning rate: 0.1
Batch [0/704] training loss = 0.2185, training acc = 0.92
Batch [200/704] training loss = 0.2680, training acc = 0.92
Batch [400/704] training loss = 0.3616, training acc = 0.88
Batch [600/704] training loss = 0.2576, training acc = 0.91
Valid Test with nat
Test accuracy: 87.60% (4380/5000), Test loss:0.3832
Epoch [40/100], Passed time:[77.950/3117.999]
learning rate: 0.1
Batch [0/704] training loss = 0.2349, training acc = 0.94
Batch [200/704] training loss = 0.2529, training acc = 0.91
Batch [400/704] training loss = 0.4859, training acc = 0.86
Batch [600/704] training loss = 0.4493, training acc = 0.86
Valid Test with nat
Test accuracy: 87.22% (4361/5000), Test loss:0.4092
Epoch [41/100], Passed time:[77.964/3196.508]
learning rate: 0.1
Batch [0/704] training loss = 0.3229, training acc = 0.89
Batch [200/704] training loss = 0.1896, training acc = 0.92
Batch [400/704] training loss = 0.2286, training acc = 0.91
Batch [600/704] training loss = 0.4587, training acc = 0.86
Valid Test with nat
Test accuracy: 86.06% (4303/5000), Test loss:0.4740
Epoch [42/100], Passed time:[77.884/3271.109]
learning rate: 0.1
Batch [0/704] training loss = 0.3511, training acc = 0.92
Batch [200/704] training loss = 0.1830, training acc = 0.95
Batch [400/704] training loss = 0.2748, training acc = 0.91
Batch [600/704] training loss = 0.2897, training acc = 0.86
Valid Test with nat
Test accuracy: 87.26% (4363/5000), Test loss:0.4082
Epoch [43/100], Passed time:[77.865/3348.180]
learning rate: 0.1
Batch [0/704] training loss = 0.1795, training acc = 0.92
Batch [200/704] training loss = 0.3582, training acc = 0.84
Batch [400/704] training loss = 0.2358, training acc = 0.92
Batch [600/704] training loss = 0.2636, training acc = 0.91
Valid Test with nat
Test accuracy: 82.90% (4145/5000), Test loss:0.6150
Epoch [44/100], Passed time:[77.872/3426.383]
learning rate: 0.1
Batch [0/704] training loss = 0.2300, training acc = 0.92
Batch [200/704] training loss = 0.2305, training acc = 0.94
Batch [400/704] training loss = 0.1996, training acc = 0.92
Batch [600/704] training loss = 0.3976, training acc = 0.88
Valid Test with nat
Test accuracy: 86.32% (4316/5000), Test loss:0.4234
Epoch [45/100], Passed time:[77.838/3502.720]
learning rate: 0.1
Batch [0/704] training loss = 0.1699, training acc = 0.94
Batch [200/704] training loss = 0.3866, training acc = 0.86
Batch [400/704] training loss = 0.2257, training acc = 0.91
Batch [600/704] training loss = 0.1437, training acc = 0.95
Valid Test with nat
Test accuracy: 87.20% (4360/5000), Test loss:0.4307
Epoch [46/100], Passed time:[77.943/3585.381]
learning rate: 0.1
Batch [0/704] training loss = 0.2455, training acc = 0.92
Batch [200/704] training loss = 0.2401, training acc = 0.91
Batch [400/704] training loss = 0.4069, training acc = 0.81
Batch [600/704] training loss = 0.3093, training acc = 0.94
Valid Test with nat
Test accuracy: 84.82% (4241/5000), Test loss:0.4862
Epoch [47/100], Passed time:[78.079/3669.715]
learning rate: 0.1
Batch [0/704] training loss = 0.2885, training acc = 0.86
Batch [200/704] training loss = 0.2490, training acc = 0.89
Batch [400/704] training loss = 0.3768, training acc = 0.89
Batch [600/704] training loss = 0.1928, training acc = 0.94
Valid Test with nat
Test accuracy: 86.34% (4317/5000), Test loss:0.4451
Epoch [48/100], Passed time:[78.077/3747.691]
learning rate: 0.1
Batch [0/704] training loss = 0.2148, training acc = 0.97
Batch [200/704] training loss = 0.2636, training acc = 0.89
Batch [400/704] training loss = 0.4546, training acc = 0.86
Batch [600/704] training loss = 0.3675, training acc = 0.89
Valid Test with nat
Test accuracy: 86.62% (4331/5000), Test loss:0.4420
Epoch [49/100], Passed time:[78.081/3825.991]
learning rate: 0.1
Batch [0/704] training loss = 0.3789, training acc = 0.89
Batch [200/704] training loss = 0.2441, training acc = 0.88
Batch [400/704] training loss = 0.2285, training acc = 0.89
Batch [600/704] training loss = 0.3947, training acc = 0.91
Valid Test with nat
Test accuracy: 87.64% (4382/5000), Test loss:0.3858
Epoch [50/100], Passed time:[78.062/3903.095]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.2422, training acc = 0.94
Batch [200/704] training loss = 0.2136, training acc = 0.91
Batch [400/704] training loss = 0.1501, training acc = 0.91
Batch [600/704] training loss = 0.0783, training acc = 0.98
Valid Test with nat
Test accuracy: 92.10% (4605/5000), Test loss:0.2540
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r65/init_pure/init_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 91.71% (9171/10000), Test loss:0.2655
Epoch [51/100], Passed time:[78.227/3989.590]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.1328, training acc = 0.95
Batch [200/704] training loss = 0.0606, training acc = 0.98
Batch [400/704] training loss = 0.1249, training acc = 0.94
Batch [600/704] training loss = 0.0564, training acc = 0.97
Valid Test with nat
Test accuracy: 92.36% (4618/5000), Test loss:0.2576
Epoch [52/100], Passed time:[78.222/4067.528]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0834, training acc = 0.98
Batch [200/704] training loss = 0.2149, training acc = 0.92
Batch [400/704] training loss = 0.0809, training acc = 0.95
Batch [600/704] training loss = 0.0531, training acc = 0.97
Valid Test with nat
Test accuracy: 92.40% (4620/5000), Test loss:0.2624
Epoch [53/100], Passed time:[78.209/4145.052]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.2162, training acc = 0.91
Batch [200/704] training loss = 0.1238, training acc = 0.97
Batch [400/704] training loss = 0.0966, training acc = 0.94
Batch [600/704] training loss = 0.0485, training acc = 1.00
Valid Test with nat
Test accuracy: 92.44% (4622/5000), Test loss:0.2559
Epoch [54/100], Passed time:[78.146/4219.878]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0487, training acc = 0.97
Batch [200/704] training loss = 0.1558, training acc = 0.95
Batch [400/704] training loss = 0.1065, training acc = 0.97
Batch [600/704] training loss = 0.2251, training acc = 0.91
Valid Test with nat
Test accuracy: 92.46% (4623/5000), Test loss:0.2581
Epoch [55/100], Passed time:[78.161/4298.871]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0992, training acc = 0.97
Batch [200/704] training loss = 0.0674, training acc = 0.97
Batch [400/704] training loss = 0.0507, training acc = 0.97
Batch [600/704] training loss = 0.1047, training acc = 0.97
Valid Test with nat
Test accuracy: 92.68% (4634/5000), Test loss:0.2680
Epoch [56/100], Passed time:[78.194/4378.875]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.1526, training acc = 0.95
Batch [200/704] training loss = 0.1250, training acc = 0.95
Batch [400/704] training loss = 0.0512, training acc = 0.97
Batch [600/704] training loss = 0.0213, training acc = 1.00
Valid Test with nat
Test accuracy: 92.70% (4635/5000), Test loss:0.2651
Epoch [57/100], Passed time:[78.178/4456.166]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.1074, training acc = 0.97
Batch [200/704] training loss = 0.1200, training acc = 0.95
Batch [400/704] training loss = 0.0635, training acc = 0.97
Batch [600/704] training loss = 0.0593, training acc = 0.98
Valid Test with nat
Test accuracy: 92.58% (4629/5000), Test loss:0.2594
Epoch [58/100], Passed time:[78.164/4533.518]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0965, training acc = 0.97
Batch [200/704] training loss = 0.0229, training acc = 1.00
Batch [400/704] training loss = 0.0643, training acc = 0.98
Batch [600/704] training loss = 0.1465, training acc = 0.95
Valid Test with nat
Test accuracy: 92.88% (4644/5000), Test loss:0.2745
Epoch [59/100], Passed time:[78.131/4609.758]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0678, training acc = 0.97
Batch [200/704] training loss = 0.0456, training acc = 0.98
Batch [400/704] training loss = 0.0322, training acc = 0.98
Batch [600/704] training loss = 0.0976, training acc = 0.97
Valid Test with nat
Test accuracy: 92.80% (4640/5000), Test loss:0.2696
Epoch [60/100], Passed time:[78.067/4684.004]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0346, training acc = 1.00
Batch [200/704] training loss = 0.1122, training acc = 0.98
Batch [400/704] training loss = 0.0124, training acc = 1.00
Batch [600/704] training loss = 0.0115, training acc = 1.00
Valid Test with nat
Test accuracy: 92.72% (4636/5000), Test loss:0.2729
Epoch [61/100], Passed time:[78.092/4763.626]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0155, training acc = 1.00
Batch [200/704] training loss = 0.0521, training acc = 0.97
Batch [400/704] training loss = 0.0634, training acc = 0.95
Batch [600/704] training loss = 0.0629, training acc = 0.97
Valid Test with nat
Test accuracy: 92.74% (4637/5000), Test loss:0.2851
Epoch [62/100], Passed time:[78.107/4842.608]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0369, training acc = 0.98
Batch [200/704] training loss = 0.0577, training acc = 0.98
Batch [400/704] training loss = 0.0299, training acc = 0.98
Batch [600/704] training loss = 0.0566, training acc = 0.95
Valid Test with nat
Test accuracy: 92.84% (4642/5000), Test loss:0.2801
Epoch [63/100], Passed time:[78.013/4914.796]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0722, training acc = 0.97
Batch [200/704] training loss = 0.0200, training acc = 1.00
Batch [400/704] training loss = 0.0559, training acc = 0.97
Batch [600/704] training loss = 0.0095, training acc = 1.00
Valid Test with nat
Test accuracy: 92.80% (4640/5000), Test loss:0.2908
Epoch [64/100], Passed time:[77.988/4991.201]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0728, training acc = 0.98
Batch [200/704] training loss = 0.0859, training acc = 0.97
Batch [400/704] training loss = 0.0134, training acc = 1.00
Batch [600/704] training loss = 0.0140, training acc = 1.00
Valid Test with nat
Test accuracy: 92.64% (4632/5000), Test loss:0.2816
Epoch [65/100], Passed time:[77.997/5069.806]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0576, training acc = 0.98
Batch [200/704] training loss = 0.0910, training acc = 0.97
Batch [400/704] training loss = 0.0816, training acc = 0.95
Batch [600/704] training loss = 0.0168, training acc = 1.00
Valid Test with nat
Test accuracy: 92.52% (4626/5000), Test loss:0.2867
Epoch [66/100], Passed time:[77.983/5146.906]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0893, training acc = 0.97
Batch [200/704] training loss = 0.0532, training acc = 0.97
Batch [400/704] training loss = 0.0377, training acc = 0.98
Batch [600/704] training loss = 0.1119, training acc = 0.95
Valid Test with nat
Test accuracy: 92.94% (4647/5000), Test loss:0.2817
Epoch [67/100], Passed time:[77.978/5224.551]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0644, training acc = 0.97
Batch [200/704] training loss = 0.0648, training acc = 0.97
Batch [400/704] training loss = 0.0159, training acc = 1.00
Batch [600/704] training loss = 0.0276, training acc = 1.00
Valid Test with nat
Test accuracy: 92.60% (4630/5000), Test loss:0.2953
Epoch [68/100], Passed time:[77.987/5303.120]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0339, training acc = 0.98
Batch [200/704] training loss = 0.1963, training acc = 0.95
Batch [400/704] training loss = 0.0593, training acc = 0.97
Batch [600/704] training loss = 0.0251, training acc = 1.00
Valid Test with nat
Test accuracy: 92.50% (4625/5000), Test loss:0.2923
Epoch [69/100], Passed time:[78.014/5382.958]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0421, training acc = 0.98
Batch [200/704] training loss = 0.0479, training acc = 0.98
Batch [400/704] training loss = 0.0310, training acc = 1.00
Batch [600/704] training loss = 0.1318, training acc = 0.98
Valid Test with nat
Test accuracy: 92.34% (4617/5000), Test loss:0.2992
Epoch [70/100], Passed time:[77.966/5457.620]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0087, training acc = 1.00
Batch [200/704] training loss = 0.0385, training acc = 0.98
Batch [400/704] training loss = 0.0384, training acc = 0.98
Batch [600/704] training loss = 0.0746, training acc = 0.97
Valid Test with nat
Test accuracy: 92.70% (4635/5000), Test loss:0.3154
Epoch [71/100], Passed time:[77.971/5535.908]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0463, training acc = 0.97
Batch [200/704] training loss = 0.1048, training acc = 0.98
Batch [400/704] training loss = 0.1013, training acc = 0.97
Batch [600/704] training loss = 0.0631, training acc = 0.98
Valid Test with nat
Test accuracy: 92.44% (4622/5000), Test loss:0.2917
Epoch [72/100], Passed time:[77.980/5614.567]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0540, training acc = 0.97
Batch [200/704] training loss = 0.0143, training acc = 1.00
Batch [400/704] training loss = 0.0827, training acc = 0.97
Batch [600/704] training loss = 0.0919, training acc = 0.94
Valid Test with nat
Test accuracy: 92.66% (4633/5000), Test loss:0.2913
Epoch [73/100], Passed time:[77.917/5687.909]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0695, training acc = 0.95
Batch [200/704] training loss = 0.0250, training acc = 0.98
Batch [400/704] training loss = 0.0760, training acc = 0.97
Batch [600/704] training loss = 0.0546, training acc = 0.98
Valid Test with nat
Test accuracy: 92.44% (4622/5000), Test loss:0.3052
Epoch [74/100], Passed time:[77.874/5762.699]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0286, training acc = 0.98
Batch [200/704] training loss = 0.0546, training acc = 0.97
Batch [400/704] training loss = 0.0430, training acc = 0.98
Batch [600/704] training loss = 0.0393, training acc = 0.98
Valid Test with nat
Test accuracy: 92.80% (4640/5000), Test loss:0.3049
Epoch [75/100], Passed time:[77.897/5842.257]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0145, training acc = 1.00
Batch [200/704] training loss = 0.0279, training acc = 0.98
Batch [400/704] training loss = 0.0044, training acc = 1.00
Batch [600/704] training loss = 0.0017, training acc = 1.00
Valid Test with nat
Test accuracy: 93.10% (4655/5000), Test loss:0.2809
Epoch [76/100], Passed time:[77.930/5922.676]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0263, training acc = 0.98
Batch [200/704] training loss = 0.1270, training acc = 0.97
Batch [400/704] training loss = 0.0138, training acc = 1.00
Batch [600/704] training loss = 0.0048, training acc = 1.00
Valid Test with nat
Test accuracy: 93.20% (4660/5000), Test loss:0.2842
Epoch [77/100], Passed time:[77.905/5998.666]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0330, training acc = 0.98
Batch [200/704] training loss = 0.0054, training acc = 1.00
Batch [400/704] training loss = 0.0099, training acc = 1.00
Batch [600/704] training loss = 0.0134, training acc = 1.00
Valid Test with nat
Test accuracy: 93.26% (4663/5000), Test loss:0.2821
Epoch [78/100], Passed time:[77.899/6076.125]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0574, training acc = 0.98
Batch [200/704] training loss = 0.0098, training acc = 1.00
Batch [400/704] training loss = 0.0154, training acc = 1.00
Batch [600/704] training loss = 0.0798, training acc = 0.97
Valid Test with nat
Test accuracy: 93.24% (4662/5000), Test loss:0.2837
Epoch [79/100], Passed time:[77.931/6156.521]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0165, training acc = 1.00
Batch [200/704] training loss = 0.0084, training acc = 1.00
Batch [400/704] training loss = 0.0057, training acc = 1.00
Batch [600/704] training loss = 0.0162, training acc = 1.00
Valid Test with nat
Test accuracy: 93.12% (4656/5000), Test loss:0.2867
Epoch [80/100], Passed time:[77.911/6232.903]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0276, training acc = 0.98
Batch [200/704] training loss = 0.0061, training acc = 1.00
Batch [400/704] training loss = 0.0072, training acc = 1.00
Batch [600/704] training loss = 0.0483, training acc = 0.98
Valid Test with nat
Test accuracy: 93.24% (4662/5000), Test loss:0.3185
Epoch [81/100], Passed time:[77.936/6312.819]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0429, training acc = 0.98
Batch [200/704] training loss = 0.0343, training acc = 1.00
Batch [400/704] training loss = 0.0023, training acc = 1.00
Batch [600/704] training loss = 0.0194, training acc = 0.98
Valid Test with nat
Test accuracy: 92.94% (4647/5000), Test loss:0.3090
Epoch [82/100], Passed time:[77.869/6385.289]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0073, training acc = 1.00
Batch [200/704] training loss = 0.0264, training acc = 0.98
Batch [400/704] training loss = 0.0096, training acc = 1.00
Batch [600/704] training loss = 0.0183, training acc = 1.00
Valid Test with nat
Test accuracy: 93.20% (4660/5000), Test loss:0.2891
Epoch [83/100], Passed time:[77.857/6462.136]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0096, training acc = 1.00
Batch [200/704] training loss = 0.0879, training acc = 0.97
Batch [400/704] training loss = 0.0202, training acc = 0.98
Batch [600/704] training loss = 0.0231, training acc = 1.00
Valid Test with nat
Test accuracy: 93.22% (4661/5000), Test loss:0.2950
Epoch [84/100], Passed time:[77.877/6541.648]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0178, training acc = 1.00
Batch [200/704] training loss = 0.0309, training acc = 0.98
Batch [400/704] training loss = 0.0139, training acc = 1.00
Batch [600/704] training loss = 0.0520, training acc = 0.98
Valid Test with nat
Test accuracy: 93.14% (4657/5000), Test loss:0.2875
Epoch [85/100], Passed time:[77.814/6614.156]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0671, training acc = 0.97
Batch [200/704] training loss = 0.0020, training acc = 1.00
Batch [400/704] training loss = 0.0089, training acc = 1.00
Batch [600/704] training loss = 0.1196, training acc = 0.97
Valid Test with nat
Test accuracy: 93.14% (4657/5000), Test loss:0.2883
Epoch [86/100], Passed time:[77.884/6698.059]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0261, training acc = 0.98
Batch [200/704] training loss = 0.0306, training acc = 1.00
Batch [400/704] training loss = 0.0384, training acc = 0.98
Batch [600/704] training loss = 0.0104, training acc = 1.00
Valid Test with nat
Test accuracy: 93.26% (4663/5000), Test loss:0.2848
Epoch [87/100], Passed time:[77.838/6771.939]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0604, training acc = 0.98
Batch [200/704] training loss = 0.0186, training acc = 0.98
Batch [400/704] training loss = 0.0272, training acc = 1.00
Batch [600/704] training loss = 0.0038, training acc = 1.00
Valid Test with nat
Test accuracy: 93.22% (4661/5000), Test loss:0.2825
Epoch [88/100], Passed time:[77.882/6853.601]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0189, training acc = 0.98
Batch [200/704] training loss = 0.0195, training acc = 0.98
Batch [400/704] training loss = 0.0054, training acc = 1.00
Batch [600/704] training loss = 0.0108, training acc = 1.00
Valid Test with nat
Test accuracy: 93.24% (4662/5000), Test loss:0.2892
Epoch [89/100], Passed time:[77.887/6931.960]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0096, training acc = 1.00
Batch [200/704] training loss = 0.0309, training acc = 0.98
Batch [400/704] training loss = 0.0049, training acc = 1.00
Batch [600/704] training loss = 0.0232, training acc = 0.98
Valid Test with nat
Test accuracy: 93.40% (4670/5000), Test loss:0.2821
Epoch [90/100], Passed time:[77.882/7009.355]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0049, training acc = 1.00
Batch [200/704] training loss = 0.0048, training acc = 1.00
Batch [400/704] training loss = 0.0097, training acc = 1.00
Batch [600/704] training loss = 0.0278, training acc = 0.98
Valid Test with nat
Test accuracy: 93.32% (4666/5000), Test loss:0.2848
Epoch [91/100], Passed time:[77.820/7081.627]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0131, training acc = 1.00
Batch [200/704] training loss = 0.0690, training acc = 0.98
Batch [400/704] training loss = 0.0422, training acc = 0.98
Batch [600/704] training loss = 0.0316, training acc = 0.98
Valid Test with nat
Test accuracy: 93.44% (4672/5000), Test loss:0.2868
Epoch [92/100], Passed time:[77.790/7156.706]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0069, training acc = 1.00
Batch [200/704] training loss = 0.0234, training acc = 0.98
Batch [400/704] training loss = 0.0085, training acc = 1.00
Batch [600/704] training loss = 0.0095, training acc = 1.00
Valid Test with nat
Test accuracy: 93.10% (4655/5000), Test loss:0.3015
Epoch [93/100], Passed time:[77.783/7233.847]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0045, training acc = 1.00
Batch [200/704] training loss = 0.0395, training acc = 0.98
Batch [400/704] training loss = 0.0239, training acc = 0.98
Batch [600/704] training loss = 0.0487, training acc = 0.98
Valid Test with nat
Test accuracy: 93.24% (4662/5000), Test loss:0.2914
Epoch [94/100], Passed time:[77.724/7306.053]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0069, training acc = 1.00
Batch [200/704] training loss = 0.1364, training acc = 0.97
Batch [400/704] training loss = 0.0672, training acc = 0.95
Batch [600/704] training loss = 0.0852, training acc = 0.98
Valid Test with nat
Test accuracy: 93.08% (4654/5000), Test loss:0.2895
Epoch [95/100], Passed time:[77.723/7383.732]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0016, training acc = 1.00
Batch [200/704] training loss = 0.0064, training acc = 1.00
Batch [400/704] training loss = 0.0335, training acc = 0.98
Batch [600/704] training loss = 0.0526, training acc = 0.98
Valid Test with nat
Test accuracy: 93.36% (4668/5000), Test loss:0.2880
Epoch [96/100], Passed time:[77.720/7461.114]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0063, training acc = 1.00
Batch [200/704] training loss = 0.0030, training acc = 1.00
Batch [400/704] training loss = 0.0206, training acc = 0.98
Batch [600/704] training loss = 0.0063, training acc = 1.00
Valid Test with nat
Test accuracy: 93.22% (4661/5000), Test loss:0.2915
Epoch [97/100], Passed time:[77.698/7536.726]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0082, training acc = 1.00
Batch [200/704] training loss = 0.0320, training acc = 0.98
Batch [400/704] training loss = 0.0216, training acc = 1.00
Batch [600/704] training loss = 0.0317, training acc = 0.98
Valid Test with nat
Test accuracy: 93.14% (4657/5000), Test loss:0.2984
Epoch [98/100], Passed time:[77.702/7614.820]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0118, training acc = 1.00
Batch [200/704] training loss = 0.0149, training acc = 1.00
Batch [400/704] training loss = 0.0088, training acc = 1.00
Batch [600/704] training loss = 0.0559, training acc = 0.97
Valid Test with nat
Test accuracy: 93.32% (4666/5000), Test loss:0.2948
Epoch [99/100], Passed time:[77.676/7689.931]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0481, training acc = 0.98
Batch [200/704] training loss = 0.0315, training acc = 1.00
Batch [400/704] training loss = 0.0023, training acc = 1.00
Batch [600/704] training loss = 0.0174, training acc = 1.00
Valid Test with nat
Test accuracy: 93.18% (4659/5000), Test loss:0.2942
Early stop at  [0.25396383663591665, 0.2575548724868359, 0.2624054041523964, 0.25591043779292166, 0.2580562448606659, 0.26799654291990477, 0.2650541304491269, 0.2594493999122045, 0.2744601948234515, 0.269625154729837, 0.2729269413707348, 0.28505990974223, 0.2801313651009248, 0.2907749480352952, 0.2815657852169795, 0.28671347645994943, 0.28174665374442553, 0.2952930921545395, 0.2922884714909089, 0.2992339230691775, 0.3154246794441954, 0.29168935091449666, 0.2913162353902291, 0.30515403092767185, 0.3049168498374713, 0.28086179265609157, 0.284209255893261, 0.2820504254255539, 0.2836984995848093, 0.28671967973693824, 0.31853521194977635, 0.30904518184849084, 0.2890933489856812, 0.29496210703674036, 0.2874905970902779, 0.2883444908910837, 0.28481117631189334, 0.28251266966645533, 0.2892331125166936, 0.2820513396977614, 0.2847761484579398, 0.2868427139444229, 0.30152505225478077, 0.2913956706149456, 0.28952196245201123, 0.28801267742155456, 0.2914762374204703, 0.2983616048899981, 0.29478572903630823, 0.2942287615763071] best model loaded from ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r65/init_pure/init_enhance_m0.01_warmup0.1.pth
model loading from ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r65/init_pure/init_enhance_m0.01_warmup0.1.pth
