model_type : vgg16
init_type : pure
finetune_method : nat
enhance_method : nat
gpu : 5
model_name : seed9_enhance_m0.01_warmup0.1
model_width : 8
n_pruning_steps : 1
max_pruning_ratio : 65
train_epochs : 100
enhance_epochs : None
prune_method : unstructured
dataset : cifar
noise_sd : 1.0
trades_beta : 6.0
seed : 9
warmup : True
create_init : False
init_step : 1400
train_method : nat
early_stop : 50
norm : True
optm : sgd
batch_size : 64
test_batch_size : 100
learning_rate : 0.1
enhance_learning_rate : 0.1
schedule_length : 10
weight_decay : 0.0001
epsilon : 0.03137254901960784
attack_iter : 10
eps_step : 0.00784313725490196
targeted : False
clip_min : 0
clip_max : 1.0
starting_epsilon : 1e-05
interval_weight : 0.1
ft_interval_weight : 50
verbose : 200
resume : 0
model_path : ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r65/init_pure/seed9_enhance_m0.01_warmup0.1.pth
last_model_path : ./trained_models_new/
mask_path : ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r65/init_pure/pruned_lr0.01_mask_r65.npy
mask_name : pruned_lr0.01_mask_r65
log_path : ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r65/init_pure/seed9_enhance_m0.01_warmup0.1.log
init_path : ./trained_models_new/cifar/vgg16/init/pure_vgg16_init.pth
results_path : None
n_classes : 10
eval : False
init : False
transfer : False
CUDA enabled.
Enhance training config:
Enhance training method: nat
model will be saved in: ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r65/init_pure/seed9_enhance_m0.01_warmup0.1.pth
Init model is: ./trained_models_new/cifar/vgg16/init/pure_vgg16_init.pth
Init mask used from: ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r65/init_pure/pruned_lr0.01_mask_r65.npy
Log will be saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r65/init_pure/seed9_enhance_m0.01_warmup0.1.log
Random seed is: 9

Epoch [0/100]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 2.3129, training acc = 0.03
Batch [200/704] training loss = 1.7899, training acc = 0.31
Batch [400/704] training loss = 1.3927, training acc = 0.55
Batch [600/704] training loss = 1.1015, training acc = 0.67
Valid Test with nat
Test accuracy: 47.18% (2359/5000), Test loss:1.6258
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r65/init_pure/seed9_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 44.64% (4464/10000), Test loss:1.7638
Epoch [1/100], Passed time:[71.268/71.268]
learning rate: 0.020000000000000004
Batch [0/704] training loss = 1.3082, training acc = 0.52
Batch [200/704] training loss = 1.5943, training acc = 0.39
Batch [400/704] training loss = 1.1946, training acc = 0.55
Batch [600/704] training loss = 1.0297, training acc = 0.62
Valid Test with nat
Test accuracy: 60.70% (3035/5000), Test loss:1.1303
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r65/init_pure/seed9_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 62.60% (6260/10000), Test loss:1.0692
Epoch [2/100], Passed time:[77.053/154.106]
learning rate: 0.030000000000000006
Batch [0/704] training loss = 1.1216, training acc = 0.56
Batch [200/704] training loss = 0.9809, training acc = 0.69
Batch [400/704] training loss = 0.9390, training acc = 0.69
Batch [600/704] training loss = 0.9725, training acc = 0.64
Valid Test with nat
Test accuracy: 56.32% (2816/5000), Test loss:1.3995
Epoch [3/100], Passed time:[74.086/222.258]
learning rate: 0.04000000000000001
Batch [0/704] training loss = 0.8928, training acc = 0.73
Batch [200/704] training loss = 0.8107, training acc = 0.72
Batch [400/704] training loss = 0.9023, training acc = 0.72
Batch [600/704] training loss = 1.3263, training acc = 0.56
Valid Test with nat
Test accuracy: 74.18% (3709/5000), Test loss:0.7579
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r65/init_pure/seed9_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 74.75% (7475/10000), Test loss:0.7449
Epoch [4/100], Passed time:[74.806/299.225]
learning rate: 0.05
Batch [0/704] training loss = 1.0361, training acc = 0.61
Batch [200/704] training loss = 0.6939, training acc = 0.77
Batch [400/704] training loss = 1.1200, training acc = 0.62
Batch [600/704] training loss = 0.5990, training acc = 0.81
Valid Test with nat
Test accuracy: 75.48% (3774/5000), Test loss:0.7674
Epoch [5/100], Passed time:[74.542/372.711]
learning rate: 0.06000000000000001
Batch [0/704] training loss = 0.9327, training acc = 0.62
Batch [200/704] training loss = 0.5916, training acc = 0.80
Batch [400/704] training loss = 0.7399, training acc = 0.73
Batch [600/704] training loss = 0.5152, training acc = 0.88
Valid Test with nat
Test accuracy: 73.42% (3671/5000), Test loss:0.8169
Epoch [6/100], Passed time:[75.058/450.348]
learning rate: 0.07
Batch [0/704] training loss = 0.7754, training acc = 0.72
Batch [200/704] training loss = 0.9267, training acc = 0.69
Batch [400/704] training loss = 0.7433, training acc = 0.77
Batch [600/704] training loss = 0.6046, training acc = 0.80
Valid Test with nat
Test accuracy: 74.82% (3741/5000), Test loss:0.7955
Epoch [7/100], Passed time:[75.156/526.089]
learning rate: 0.08000000000000002
Batch [0/704] training loss = 0.4287, training acc = 0.88
Batch [200/704] training loss = 0.5525, training acc = 0.77
Batch [400/704] training loss = 0.5324, training acc = 0.80
Batch [600/704] training loss = 0.7813, training acc = 0.75
Valid Test with nat
Test accuracy: 78.86% (3943/5000), Test loss:0.6369
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r65/init_pure/seed9_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 77.45% (7745/10000), Test loss:0.6645
Epoch [8/100], Passed time:[76.252/610.013]
learning rate: 0.09000000000000001
Batch [0/704] training loss = 0.6740, training acc = 0.78
Batch [200/704] training loss = 0.5249, training acc = 0.81
Batch [400/704] training loss = 0.8127, training acc = 0.77
Batch [600/704] training loss = 0.8361, training acc = 0.70
Valid Test with nat
Test accuracy: 73.06% (3653/5000), Test loss:0.8549
Epoch [9/100], Passed time:[76.475/688.274]
learning rate: 0.1
Batch [0/704] training loss = 0.7213, training acc = 0.75
Batch [200/704] training loss = 0.5230, training acc = 0.83
Batch [400/704] training loss = 0.6363, training acc = 0.78
Batch [600/704] training loss = 0.6059, training acc = 0.84
Valid Test with nat
Test accuracy: 76.90% (3845/5000), Test loss:0.7000
Epoch [10/100], Passed time:[76.803/768.025]
learning rate: 0.1
Batch [0/704] training loss = 0.4271, training acc = 0.86
Batch [200/704] training loss = 0.6651, training acc = 0.75
Batch [400/704] training loss = 0.8541, training acc = 0.70
Batch [600/704] training loss = 0.5902, training acc = 0.80
Valid Test with nat
Test accuracy: 77.52% (3876/5000), Test loss:0.6894
Epoch [11/100], Passed time:[76.670/843.369]
learning rate: 0.1
Batch [0/704] training loss = 0.4042, training acc = 0.88
Batch [200/704] training loss = 0.5753, training acc = 0.77
Batch [400/704] training loss = 0.4651, training acc = 0.81
Batch [600/704] training loss = 0.6494, training acc = 0.78
Valid Test with nat
Test accuracy: 80.22% (4011/5000), Test loss:0.5707
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r65/init_pure/seed9_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 80.95% (8095/10000), Test loss:0.5630
Epoch [12/100], Passed time:[76.621/919.447]
learning rate: 0.1
Batch [0/704] training loss = 0.6855, training acc = 0.72
Batch [200/704] training loss = 0.5074, training acc = 0.81
Batch [400/704] training loss = 0.3257, training acc = 0.89
Batch [600/704] training loss = 0.4262, training acc = 0.81
Valid Test with nat
Test accuracy: 80.10% (4005/5000), Test loss:0.6202
Epoch [13/100], Passed time:[77.090/1002.174]
learning rate: 0.1
Batch [0/704] training loss = 0.4356, training acc = 0.86
Batch [200/704] training loss = 0.6196, training acc = 0.78
Batch [400/704] training loss = 0.5759, training acc = 0.84
Batch [600/704] training loss = 0.5896, training acc = 0.80
Valid Test with nat
Test accuracy: 80.18% (4009/5000), Test loss:0.6101
Epoch [14/100], Passed time:[77.065/1078.914]
learning rate: 0.1
Batch [0/704] training loss = 0.5801, training acc = 0.81
Batch [200/704] training loss = 0.3809, training acc = 0.86
Batch [400/704] training loss = 0.5193, training acc = 0.83
Batch [600/704] training loss = 0.4537, training acc = 0.84
Valid Test with nat
Test accuracy: 84.18% (4209/5000), Test loss:0.4872
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r65/init_pure/seed9_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 84.27% (8427/10000), Test loss:0.4656
Epoch [15/100], Passed time:[77.415/1161.220]
learning rate: 0.1
Batch [0/704] training loss = 0.4889, training acc = 0.81
Batch [200/704] training loss = 0.3656, training acc = 0.86
Batch [400/704] training loss = 0.3948, training acc = 0.80
Batch [600/704] training loss = 0.4100, training acc = 0.89
Valid Test with nat
Test accuracy: 83.46% (4173/5000), Test loss:0.5098
Epoch [16/100], Passed time:[77.605/1241.676]
learning rate: 0.1
Batch [0/704] training loss = 0.3572, training acc = 0.86
Batch [200/704] training loss = 0.3721, training acc = 0.89
Batch [400/704] training loss = 0.4965, training acc = 0.81
Batch [600/704] training loss = 0.4519, training acc = 0.86
Valid Test with nat
Test accuracy: 83.80% (4190/5000), Test loss:0.4980
Epoch [17/100], Passed time:[77.761/1321.933]
learning rate: 0.1
Batch [0/704] training loss = 0.3602, training acc = 0.89
Batch [200/704] training loss = 0.5698, training acc = 0.81
Batch [400/704] training loss = 0.4637, training acc = 0.89
Batch [600/704] training loss = 0.4032, training acc = 0.86
Valid Test with nat
Test accuracy: 83.70% (4185/5000), Test loss:0.5046
Epoch [18/100], Passed time:[77.913/1402.442]
learning rate: 0.1
Batch [0/704] training loss = 0.5227, training acc = 0.84
Batch [200/704] training loss = 0.4450, training acc = 0.86
Batch [400/704] training loss = 0.3035, training acc = 0.94
Batch [600/704] training loss = 0.4778, training acc = 0.86
Valid Test with nat
Test accuracy: 78.58% (3929/5000), Test loss:0.7009
Epoch [19/100], Passed time:[78.106/1484.018]
learning rate: 0.1
Batch [0/704] training loss = 0.2843, training acc = 0.92
Batch [200/704] training loss = 0.6869, training acc = 0.83
Batch [400/704] training loss = 0.3198, training acc = 0.89
Batch [600/704] training loss = 0.9114, training acc = 0.73
Valid Test with nat
Test accuracy: 84.40% (4220/5000), Test loss:0.4716
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r65/init_pure/seed9_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 84.30% (8430/10000), Test loss:0.4952
Epoch [20/100], Passed time:[78.346/1566.929]
learning rate: 0.1
Batch [0/704] training loss = 0.2834, training acc = 0.88
Batch [200/704] training loss = 0.2899, training acc = 0.88
Batch [400/704] training loss = 0.2424, training acc = 0.89
Batch [600/704] training loss = 0.4728, training acc = 0.81
Valid Test with nat
Test accuracy: 85.12% (4256/5000), Test loss:0.4658
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r65/init_pure/seed9_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 84.38% (8438/10000), Test loss:0.4620
Epoch [21/100], Passed time:[78.427/1646.976]
learning rate: 0.1
Batch [0/704] training loss = 0.3003, training acc = 0.89
Batch [200/704] training loss = 0.3703, training acc = 0.86
Batch [400/704] training loss = 0.3955, training acc = 0.86
Batch [600/704] training loss = 0.4082, training acc = 0.86
Valid Test with nat
Test accuracy: 80.06% (4003/5000), Test loss:0.6429
Epoch [22/100], Passed time:[78.344/1723.571]
learning rate: 0.1
Batch [0/704] training loss = 0.4292, training acc = 0.84
Batch [200/704] training loss = 0.4169, training acc = 0.86
Batch [400/704] training loss = 0.4255, training acc = 0.86
Batch [600/704] training loss = 0.5756, training acc = 0.78
Valid Test with nat
Test accuracy: 82.64% (4132/5000), Test loss:0.5299
Epoch [23/100], Passed time:[78.346/1801.968]
learning rate: 0.1
Batch [0/704] training loss = 0.4414, training acc = 0.83
Batch [200/704] training loss = 0.6957, training acc = 0.75
Batch [400/704] training loss = 0.4972, training acc = 0.81
Batch [600/704] training loss = 0.3151, training acc = 0.92
Valid Test with nat
Test accuracy: 84.76% (4238/5000), Test loss:0.4734
Epoch [24/100], Passed time:[78.449/1882.766]
learning rate: 0.1
Batch [0/704] training loss = 0.3323, training acc = 0.83
Batch [200/704] training loss = 0.5070, training acc = 0.86
Batch [400/704] training loss = 0.2530, training acc = 0.92
Batch [600/704] training loss = 0.5096, training acc = 0.84
Valid Test with nat
Test accuracy: 83.70% (4185/5000), Test loss:0.4937
Epoch [25/100], Passed time:[78.409/1960.231]
learning rate: 0.1
Batch [0/704] training loss = 0.5264, training acc = 0.83
Batch [200/704] training loss = 0.3877, training acc = 0.84
Batch [400/704] training loss = 0.5394, training acc = 0.78
Batch [600/704] training loss = 0.3076, training acc = 0.88
Valid Test with nat
Test accuracy: 85.52% (4276/5000), Test loss:0.4530
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r65/init_pure/seed9_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 84.92% (8492/10000), Test loss:0.4751
Epoch [26/100], Passed time:[78.783/2048.353]
learning rate: 0.1
Batch [0/704] training loss = 0.3647, training acc = 0.88
Batch [200/704] training loss = 0.5774, training acc = 0.83
Batch [400/704] training loss = 0.2770, training acc = 0.92
Batch [600/704] training loss = 0.3373, training acc = 0.91
Valid Test with nat
Test accuracy: 83.22% (4161/5000), Test loss:0.5185
Epoch [27/100], Passed time:[78.861/2129.260]
learning rate: 0.1
Batch [0/704] training loss = 0.3076, training acc = 0.91
Batch [200/704] training loss = 0.4811, training acc = 0.81
Batch [400/704] training loss = 0.3039, training acc = 0.88
Batch [600/704] training loss = 0.2981, training acc = 0.92
Valid Test with nat
Test accuracy: 84.64% (4232/5000), Test loss:0.4515
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r65/init_pure/seed9_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 84.08% (8408/10000), Test loss:0.4772
Epoch [28/100], Passed time:[79.025/2212.687]
learning rate: 0.1
Batch [0/704] training loss = 0.4029, training acc = 0.84
Batch [200/704] training loss = 0.3945, training acc = 0.89
Batch [400/704] training loss = 0.2139, training acc = 0.94
Batch [600/704] training loss = 0.4125, training acc = 0.86
Valid Test with nat
Test accuracy: 80.40% (4020/5000), Test loss:0.6230
Epoch [29/100], Passed time:[79.009/2291.256]
learning rate: 0.1
Batch [0/704] training loss = 0.3140, training acc = 0.89
Batch [200/704] training loss = 0.2645, training acc = 0.89
Batch [400/704] training loss = 0.2692, training acc = 0.91
Batch [600/704] training loss = 0.3472, training acc = 0.91
Valid Test with nat
Test accuracy: 84.30% (4215/5000), Test loss:0.4831
Epoch [30/100], Passed time:[78.966/2368.978]
learning rate: 0.1
Batch [0/704] training loss = 0.4586, training acc = 0.78
Batch [200/704] training loss = 0.5520, training acc = 0.80
Batch [400/704] training loss = 0.6958, training acc = 0.77
Batch [600/704] training loss = 0.5599, training acc = 0.84
Valid Test with nat
Test accuracy: 83.62% (4181/5000), Test loss:0.5241
Epoch [31/100], Passed time:[78.971/2448.100]
learning rate: 0.1
Batch [0/704] training loss = 0.2993, training acc = 0.91
Batch [200/704] training loss = 0.4192, training acc = 0.86
Batch [400/704] training loss = 0.2301, training acc = 0.89
Batch [600/704] training loss = 0.4122, training acc = 0.89
Valid Test with nat
Test accuracy: 84.70% (4235/5000), Test loss:0.4711
Epoch [32/100], Passed time:[79.072/2530.289]
learning rate: 0.1
Batch [0/704] training loss = 0.5039, training acc = 0.81
Batch [200/704] training loss = 0.3937, training acc = 0.84
Batch [400/704] training loss = 0.3943, training acc = 0.88
Batch [600/704] training loss = 0.5727, training acc = 0.83
Valid Test with nat
Test accuracy: 86.88% (4344/5000), Test loss:0.4228
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r65/init_pure/seed9_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 86.03% (8603/10000), Test loss:0.4323
Epoch [33/100], Passed time:[79.108/2610.564]
learning rate: 0.1
Batch [0/704] training loss = 0.4312, training acc = 0.84
Batch [200/704] training loss = 0.2891, training acc = 0.92
Batch [400/704] training loss = 0.3182, training acc = 0.91
Batch [600/704] training loss = 0.2789, training acc = 0.91
Valid Test with nat
Test accuracy: 86.16% (4308/5000), Test loss:0.4303
Epoch [34/100], Passed time:[79.166/2691.660]
learning rate: 0.1
Batch [0/704] training loss = 0.3309, training acc = 0.86
Batch [200/704] training loss = 0.3224, training acc = 0.91
Batch [400/704] training loss = 0.3411, training acc = 0.89
Batch [600/704] training loss = 0.3791, training acc = 0.86
Valid Test with nat
Test accuracy: 85.64% (4282/5000), Test loss:0.4415
Epoch [35/100], Passed time:[79.197/2771.901]
learning rate: 0.1
Batch [0/704] training loss = 0.2307, training acc = 0.91
Batch [200/704] training loss = 0.2359, training acc = 0.91
Batch [400/704] training loss = 0.3254, training acc = 0.83
Batch [600/704] training loss = 0.2070, training acc = 0.92
Valid Test with nat
Test accuracy: 83.40% (4170/5000), Test loss:0.5120
Epoch [36/100], Passed time:[79.147/2849.284]
learning rate: 0.1
Batch [0/704] training loss = 0.3887, training acc = 0.88
Batch [200/704] training loss = 0.4065, training acc = 0.84
Batch [400/704] training loss = 0.3290, training acc = 0.91
Batch [600/704] training loss = 0.4446, training acc = 0.92
Valid Test with nat
Test accuracy: 86.08% (4304/5000), Test loss:0.4352
Epoch [37/100], Passed time:[79.181/2929.700]
learning rate: 0.1
Batch [0/704] training loss = 0.4567, training acc = 0.80
Batch [200/704] training loss = 0.4588, training acc = 0.81
Batch [400/704] training loss = 0.2054, training acc = 0.95
Batch [600/704] training loss = 0.4663, training acc = 0.83
Valid Test with nat
Test accuracy: 85.18% (4259/5000), Test loss:0.4657
Epoch [38/100], Passed time:[79.280/3012.629]
learning rate: 0.1
Batch [0/704] training loss = 0.2900, training acc = 0.89
Batch [200/704] training loss = 0.3487, training acc = 0.88
Batch [400/704] training loss = 0.2592, training acc = 0.89
Batch [600/704] training loss = 0.3824, training acc = 0.89
Valid Test with nat
Test accuracy: 86.32% (4316/5000), Test loss:0.4107
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r65/init_pure/seed9_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 86.24% (8624/10000), Test loss:0.4205
Epoch [39/100], Passed time:[79.349/3094.625]
learning rate: 0.1
Batch [0/704] training loss = 0.2592, training acc = 0.92
Batch [200/704] training loss = 0.5251, training acc = 0.81
Batch [400/704] training loss = 0.2618, training acc = 0.92
Batch [600/704] training loss = 0.2428, training acc = 0.92
Valid Test with nat
Test accuracy: 84.56% (4228/5000), Test loss:0.4782
Epoch [40/100], Passed time:[79.207/3168.292]
learning rate: 0.1
Batch [0/704] training loss = 0.2398, training acc = 0.91
Batch [200/704] training loss = 0.2479, training acc = 0.92
Batch [400/704] training loss = 0.3868, training acc = 0.86
Batch [600/704] training loss = 0.2902, training acc = 0.86
Valid Test with nat
Test accuracy: 85.04% (4252/5000), Test loss:0.4737
Epoch [41/100], Passed time:[79.282/3250.564]
learning rate: 0.1
Batch [0/704] training loss = 0.2771, training acc = 0.91
Batch [200/704] training loss = 0.4529, training acc = 0.84
Batch [400/704] training loss = 0.3371, training acc = 0.89
Batch [600/704] training loss = 0.3723, training acc = 0.83
Valid Test with nat
Test accuracy: 85.84% (4292/5000), Test loss:0.4268
Epoch [42/100], Passed time:[79.343/3332.404]
learning rate: 0.1
Batch [0/704] training loss = 0.3940, training acc = 0.84
Batch [200/704] training loss = 0.2444, training acc = 0.97
Batch [400/704] training loss = 0.2354, training acc = 0.94
Batch [600/704] training loss = 0.2568, training acc = 0.95
Valid Test with nat
Test accuracy: 85.34% (4267/5000), Test loss:0.4667
Epoch [43/100], Passed time:[79.261/3408.236]
learning rate: 0.1
Batch [0/704] training loss = 0.3774, training acc = 0.86
Batch [200/704] training loss = 0.4648, training acc = 0.83
Batch [400/704] training loss = 0.3900, training acc = 0.88
Batch [600/704] training loss = 0.1959, training acc = 0.95
Valid Test with nat
Test accuracy: 84.16% (4208/5000), Test loss:0.4934
Epoch [44/100], Passed time:[79.321/3490.136]
learning rate: 0.1
Batch [0/704] training loss = 0.2148, training acc = 0.94
Batch [200/704] training loss = 0.2089, training acc = 0.94
Batch [400/704] training loss = 0.2573, training acc = 0.92
Batch [600/704] training loss = 0.4664, training acc = 0.83
Valid Test with nat
Test accuracy: 85.02% (4251/5000), Test loss:0.4548
Epoch [45/100], Passed time:[79.332/3569.930]
learning rate: 0.1
Batch [0/704] training loss = 0.2751, training acc = 0.89
Batch [200/704] training loss = 0.5137, training acc = 0.84
Batch [400/704] training loss = 0.2625, training acc = 0.89
Batch [600/704] training loss = 0.5104, training acc = 0.80
Valid Test with nat
Test accuracy: 84.32% (4216/5000), Test loss:0.5052
Epoch [46/100], Passed time:[79.297/3647.678]
learning rate: 0.1
Batch [0/704] training loss = 0.3571, training acc = 0.84
Batch [200/704] training loss = 0.3331, training acc = 0.91
Batch [400/704] training loss = 0.3256, training acc = 0.86
Batch [600/704] training loss = 0.1666, training acc = 0.92
Valid Test with nat
Test accuracy: 85.84% (4292/5000), Test loss:0.4159
Epoch [47/100], Passed time:[79.074/3716.460]
learning rate: 0.1
Batch [0/704] training loss = 0.2425, training acc = 0.91
Batch [200/704] training loss = 0.2772, training acc = 0.94
Batch [400/704] training loss = 0.2743, training acc = 0.91
Batch [600/704] training loss = 0.2859, training acc = 0.91
Valid Test with nat
Test accuracy: 87.58% (4379/5000), Test loss:0.3826
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r65/init_pure/seed9_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 86.75% (8675/10000), Test loss:0.4086
Epoch [48/100], Passed time:[79.185/3800.888]
learning rate: 0.1
Batch [0/704] training loss = 0.2736, training acc = 0.94
Batch [200/704] training loss = 0.1232, training acc = 0.97
Batch [400/704] training loss = 0.3387, training acc = 0.88
Batch [600/704] training loss = 0.3853, training acc = 0.88
Valid Test with nat
Test accuracy: 87.30% (4365/5000), Test loss:0.3861
Epoch [49/100], Passed time:[79.191/3880.363]
learning rate: 0.1
Batch [0/704] training loss = 0.3383, training acc = 0.88
Batch [200/704] training loss = 0.3833, training acc = 0.88
Batch [400/704] training loss = 0.3151, training acc = 0.91
Batch [600/704] training loss = 0.3982, training acc = 0.86
Valid Test with nat
Test accuracy: 86.42% (4321/5000), Test loss:0.4396
Epoch [50/100], Passed time:[79.149/3957.473]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.3086, training acc = 0.86
Batch [200/704] training loss = 0.1158, training acc = 0.95
Batch [400/704] training loss = 0.2778, training acc = 0.92
Batch [600/704] training loss = 0.2522, training acc = 0.89
Valid Test with nat
Test accuracy: 90.92% (4546/5000), Test loss:0.2785
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r65/init_pure/seed9_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 91.13% (9113/10000), Test loss:0.2750
Epoch [51/100], Passed time:[79.330/4045.845]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.3362, training acc = 0.91
Batch [200/704] training loss = 0.3035, training acc = 0.88
Batch [400/704] training loss = 0.1342, training acc = 0.95
Batch [600/704] training loss = 0.2148, training acc = 0.92
Valid Test with nat
Test accuracy: 91.22% (4561/5000), Test loss:0.2686
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r65/init_pure/seed9_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 91.34% (9134/10000), Test loss:0.2726
Epoch [52/100], Passed time:[79.436/4130.653]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.1332, training acc = 0.95
Batch [200/704] training loss = 0.1145, training acc = 0.92
Batch [400/704] training loss = 0.2136, training acc = 0.92
Batch [600/704] training loss = 0.1488, training acc = 0.95
Valid Test with nat
Test accuracy: 91.88% (4594/5000), Test loss:0.2654
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r65/init_pure/seed9_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 91.09% (9109/10000), Test loss:0.2797
Epoch [53/100], Passed time:[79.399/4208.152]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.1133, training acc = 0.98
Batch [200/704] training loss = 0.1030, training acc = 0.97
Batch [400/704] training loss = 0.2476, training acc = 0.91
Batch [600/704] training loss = 0.1211, training acc = 0.95
Valid Test with nat
Test accuracy: 91.38% (4569/5000), Test loss:0.2809
Epoch [54/100], Passed time:[79.371/4286.013]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.1011, training acc = 0.92
Batch [200/704] training loss = 0.1390, training acc = 0.94
Batch [400/704] training loss = 0.0739, training acc = 0.98
Batch [600/704] training loss = 0.0970, training acc = 0.95
Valid Test with nat
Test accuracy: 91.66% (4583/5000), Test loss:0.2734
Epoch [55/100], Passed time:[79.360/4364.798]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0890, training acc = 0.95
Batch [200/704] training loss = 0.0662, training acc = 0.97
Batch [400/704] training loss = 0.0604, training acc = 0.98
Batch [600/704] training loss = 0.0449, training acc = 1.00
Valid Test with nat
Test accuracy: 91.82% (4591/5000), Test loss:0.2735
Epoch [56/100], Passed time:[79.381/4445.315]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0770, training acc = 0.97
Batch [200/704] training loss = 0.0786, training acc = 0.98
Batch [400/704] training loss = 0.1450, training acc = 0.98
Batch [600/704] training loss = 0.0470, training acc = 0.97
Valid Test with nat
Test accuracy: 91.74% (4587/5000), Test loss:0.2818
Epoch [57/100], Passed time:[79.326/4521.583]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0392, training acc = 0.98
Batch [200/704] training loss = 0.1120, training acc = 0.95
Batch [400/704] training loss = 0.1127, training acc = 0.94
Batch [600/704] training loss = 0.0200, training acc = 1.00
Valid Test with nat
Test accuracy: 92.06% (4603/5000), Test loss:0.2773
Epoch [58/100], Passed time:[79.438/4607.425]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.1835, training acc = 0.95
Batch [200/704] training loss = 0.1008, training acc = 0.95
Batch [400/704] training loss = 0.1137, training acc = 0.97
Batch [600/704] training loss = 0.0506, training acc = 0.97
Valid Test with nat
Test accuracy: 91.90% (4595/5000), Test loss:0.2813
Epoch [59/100], Passed time:[79.381/4683.506]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0796, training acc = 0.98
Batch [200/704] training loss = 0.0864, training acc = 0.97
Batch [400/704] training loss = 0.0371, training acc = 0.98
Batch [600/704] training loss = 0.0769, training acc = 0.98
Valid Test with nat
Test accuracy: 92.10% (4605/5000), Test loss:0.2815
Epoch [60/100], Passed time:[79.366/4761.966]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.1097, training acc = 0.97
Batch [200/704] training loss = 0.0471, training acc = 0.98
Batch [400/704] training loss = 0.0439, training acc = 1.00
Batch [600/704] training loss = 0.1507, training acc = 0.92
Valid Test with nat
Test accuracy: 91.82% (4591/5000), Test loss:0.2804
Epoch [61/100], Passed time:[79.347/4840.193]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0747, training acc = 0.97
Batch [200/704] training loss = 0.0940, training acc = 0.97
Batch [400/704] training loss = 0.0975, training acc = 0.97
Batch [600/704] training loss = 0.0478, training acc = 0.98
Valid Test with nat
Test accuracy: 91.84% (4592/5000), Test loss:0.2842
Epoch [62/100], Passed time:[79.352/4919.841]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0506, training acc = 0.97
Batch [200/704] training loss = 0.0910, training acc = 0.97
Batch [400/704] training loss = 0.0497, training acc = 0.98
Batch [600/704] training loss = 0.1211, training acc = 0.92
Valid Test with nat
Test accuracy: 91.94% (4597/5000), Test loss:0.2881
Epoch [63/100], Passed time:[79.390/5001.601]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.1389, training acc = 0.95
Batch [200/704] training loss = 0.0762, training acc = 0.97
Batch [400/704] training loss = 0.0711, training acc = 0.97
Batch [600/704] training loss = 0.0838, training acc = 0.95
Valid Test with nat
Test accuracy: 91.66% (4583/5000), Test loss:0.2913
Epoch [64/100], Passed time:[79.328/5077.012]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.1121, training acc = 0.97
Batch [200/704] training loss = 0.2328, training acc = 0.94
Batch [400/704] training loss = 0.0811, training acc = 0.97
Batch [600/704] training loss = 0.0818, training acc = 0.97
Valid Test with nat
Test accuracy: 91.68% (4584/5000), Test loss:0.2936
Epoch [65/100], Passed time:[79.381/5159.776]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0583, training acc = 0.98
Batch [200/704] training loss = 0.2066, training acc = 0.94
Batch [400/704] training loss = 0.1354, training acc = 0.97
Batch [600/704] training loss = 0.1293, training acc = 0.95
Valid Test with nat
Test accuracy: 91.78% (4589/5000), Test loss:0.3010
Epoch [66/100], Passed time:[79.322/5235.275]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0398, training acc = 0.98
Batch [200/704] training loss = 0.0334, training acc = 1.00
Batch [400/704] training loss = 0.0549, training acc = 0.98
Batch [600/704] training loss = 0.1284, training acc = 0.95
Valid Test with nat
Test accuracy: 91.32% (4566/5000), Test loss:0.3050
Epoch [67/100], Passed time:[79.281/5311.818]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.1686, training acc = 0.95
Batch [200/704] training loss = 0.1091, training acc = 0.94
Batch [400/704] training loss = 0.0993, training acc = 0.95
Batch [600/704] training loss = 0.0428, training acc = 0.98
Valid Test with nat
Test accuracy: 91.96% (4598/5000), Test loss:0.2955
Epoch [68/100], Passed time:[79.207/5386.104]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0253, training acc = 1.00
Batch [200/704] training loss = 0.2334, training acc = 0.95
Batch [400/704] training loss = 0.1414, training acc = 0.95
Batch [600/704] training loss = 0.0474, training acc = 0.98
Valid Test with nat
Test accuracy: 92.12% (4606/5000), Test loss:0.2933
Epoch [69/100], Passed time:[79.235/5467.199]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0955, training acc = 0.97
Batch [200/704] training loss = 0.0355, training acc = 1.00
Batch [400/704] training loss = 0.0976, training acc = 0.95
Batch [600/704] training loss = 0.0313, training acc = 1.00
Valid Test with nat
Test accuracy: 91.64% (4582/5000), Test loss:0.3220
Epoch [70/100], Passed time:[79.240/5546.814]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0346, training acc = 0.98
Batch [200/704] training loss = 0.0960, training acc = 0.95
Batch [400/704] training loss = 0.1273, training acc = 0.94
Batch [600/704] training loss = 0.0308, training acc = 1.00
Valid Test with nat
Test accuracy: 91.84% (4592/5000), Test loss:0.3054
Epoch [71/100], Passed time:[79.303/5630.517]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0071, training acc = 1.00
Batch [200/704] training loss = 0.0453, training acc = 0.98
Batch [400/704] training loss = 0.0725, training acc = 0.97
Batch [600/704] training loss = 0.0270, training acc = 0.98
Valid Test with nat
Test accuracy: 91.92% (4596/5000), Test loss:0.2945
Epoch [72/100], Passed time:[79.308/5710.142]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0677, training acc = 0.98
Batch [200/704] training loss = 0.1017, training acc = 0.95
Batch [400/704] training loss = 0.0928, training acc = 0.95
Batch [600/704] training loss = 0.1289, training acc = 0.97
Valid Test with nat
Test accuracy: 92.10% (4605/5000), Test loss:0.2946
Epoch [73/100], Passed time:[79.274/5786.987]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0658, training acc = 0.97
Batch [200/704] training loss = 0.0843, training acc = 0.95
Batch [400/704] training loss = 0.0590, training acc = 0.98
Batch [600/704] training loss = 0.0155, training acc = 1.00
Valid Test with nat
Test accuracy: 92.08% (4604/5000), Test loss:0.3028
Epoch [74/100], Passed time:[79.285/5867.068]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.1811, training acc = 0.92
Batch [200/704] training loss = 0.0468, training acc = 0.98
Batch [400/704] training loss = 0.2319, training acc = 0.89
Batch [600/704] training loss = 0.0444, training acc = 0.97
Valid Test with nat
Test accuracy: 91.84% (4592/5000), Test loss:0.3070
Epoch [75/100], Passed time:[79.350/5951.286]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0481, training acc = 0.97
Batch [200/704] training loss = 0.0345, training acc = 0.98
Batch [400/704] training loss = 0.0726, training acc = 0.97
Batch [600/704] training loss = 0.0192, training acc = 1.00
Valid Test with nat
Test accuracy: 92.30% (4615/5000), Test loss:0.2858
Epoch [76/100], Passed time:[79.376/6032.569]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0515, training acc = 0.98
Batch [200/704] training loss = 0.0623, training acc = 0.97
Batch [400/704] training loss = 0.0286, training acc = 0.98
Batch [600/704] training loss = 0.0485, training acc = 0.98
Valid Test with nat
Test accuracy: 92.60% (4630/5000), Test loss:0.2842
Epoch [77/100], Passed time:[79.396/6113.512]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.1188, training acc = 0.95
Batch [200/704] training loss = 0.1211, training acc = 0.95
Batch [400/704] training loss = 0.0263, training acc = 1.00
Batch [600/704] training loss = 0.0961, training acc = 0.98
Valid Test with nat
Test accuracy: 92.54% (4627/5000), Test loss:0.2966
Epoch [78/100], Passed time:[79.371/6190.927]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0247, training acc = 0.98
Batch [200/704] training loss = 0.0448, training acc = 0.98
Batch [400/704] training loss = 0.1026, training acc = 0.95
Batch [600/704] training loss = 0.0788, training acc = 0.97
Valid Test with nat
Test accuracy: 92.50% (4625/5000), Test loss:0.2839
Epoch [79/100], Passed time:[79.407/6273.127]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0110, training acc = 1.00
Batch [200/704] training loss = 0.1269, training acc = 0.95
Batch [400/704] training loss = 0.0190, training acc = 1.00
Batch [600/704] training loss = 0.0113, training acc = 1.00
Valid Test with nat
Test accuracy: 92.48% (4624/5000), Test loss:0.2901
Epoch [80/100], Passed time:[79.395/6351.599]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0802, training acc = 0.95
Batch [200/704] training loss = 0.0392, training acc = 0.98
Batch [400/704] training loss = 0.0392, training acc = 0.98
Batch [600/704] training loss = 0.0155, training acc = 1.00
Valid Test with nat
Test accuracy: 92.48% (4624/5000), Test loss:0.2901
Epoch [81/100], Passed time:[79.347/6427.110]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0220, training acc = 1.00
Batch [200/704] training loss = 0.0153, training acc = 1.00
Batch [400/704] training loss = 0.0881, training acc = 0.97
Batch [600/704] training loss = 0.0363, training acc = 0.98
Valid Test with nat
Test accuracy: 92.70% (4635/5000), Test loss:0.2984
Epoch [82/100], Passed time:[79.346/6506.364]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0084, training acc = 1.00
Batch [200/704] training loss = 0.0068, training acc = 1.00
Batch [400/704] training loss = 0.0933, training acc = 0.98
Batch [600/704] training loss = 0.0162, training acc = 0.98
Valid Test with nat
Test accuracy: 92.70% (4635/5000), Test loss:0.2894
Epoch [83/100], Passed time:[79.401/6590.313]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0731, training acc = 0.98
Batch [200/704] training loss = 0.0647, training acc = 0.98
Batch [400/704] training loss = 0.0175, training acc = 1.00
Batch [600/704] training loss = 0.0767, training acc = 0.97
Valid Test with nat
Test accuracy: 92.58% (4629/5000), Test loss:0.2888
Epoch [84/100], Passed time:[79.431/6672.217]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0042, training acc = 1.00
Batch [200/704] training loss = 0.0106, training acc = 1.00
Batch [400/704] training loss = 0.0029, training acc = 1.00
Batch [600/704] training loss = 0.0179, training acc = 1.00
Valid Test with nat
Test accuracy: 92.84% (4642/5000), Test loss:0.2874
Epoch [85/100], Passed time:[79.471/6755.038]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0034, training acc = 1.00
Batch [200/704] training loss = 0.0157, training acc = 1.00
Batch [400/704] training loss = 0.0842, training acc = 0.97
Batch [600/704] training loss = 0.0030, training acc = 1.00
Valid Test with nat
Test accuracy: 92.64% (4632/5000), Test loss:0.2907
Epoch [86/100], Passed time:[79.403/6828.624]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0119, training acc = 1.00
Batch [200/704] training loss = 0.1049, training acc = 0.97
Batch [400/704] training loss = 0.0208, training acc = 1.00
Batch [600/704] training loss = 0.0140, training acc = 1.00
Valid Test with nat
Test accuracy: 92.54% (4627/5000), Test loss:0.2952
Epoch [87/100], Passed time:[79.408/6908.471]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0495, training acc = 0.97
Batch [200/704] training loss = 0.1117, training acc = 0.98
Batch [400/704] training loss = 0.0072, training acc = 1.00
Batch [600/704] training loss = 0.0222, training acc = 1.00
Valid Test with nat
Test accuracy: 92.48% (4624/5000), Test loss:0.3136
Epoch [88/100], Passed time:[79.343/6982.204]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0985, training acc = 0.97
Batch [200/704] training loss = 0.0426, training acc = 0.98
Batch [400/704] training loss = 0.0053, training acc = 1.00
Batch [600/704] training loss = 0.0119, training acc = 1.00
Valid Test with nat
Test accuracy: 92.50% (4625/5000), Test loss:0.2931
Epoch [89/100], Passed time:[79.332/7060.544]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.1092, training acc = 0.95
Batch [200/704] training loss = 0.0146, training acc = 1.00
Batch [400/704] training loss = 0.0144, training acc = 1.00
Batch [600/704] training loss = 0.0474, training acc = 0.98
Valid Test with nat
Test accuracy: 92.74% (4637/5000), Test loss:0.2992
Epoch [90/100], Passed time:[79.361/7142.511]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0523, training acc = 0.97
Batch [200/704] training loss = 0.0068, training acc = 1.00
Batch [400/704] training loss = 0.0349, training acc = 0.98
Batch [600/704] training loss = 0.0828, training acc = 0.97
Valid Test with nat
Test accuracy: 92.52% (4626/5000), Test loss:0.2982
Epoch [91/100], Passed time:[79.376/7223.219]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0813, training acc = 0.97
Batch [200/704] training loss = 0.0587, training acc = 0.97
Batch [400/704] training loss = 0.0117, training acc = 1.00
Batch [600/704] training loss = 0.0517, training acc = 0.97
Valid Test with nat
Test accuracy: 92.54% (4627/5000), Test loss:0.2954
Epoch [92/100], Passed time:[79.362/7301.289]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0337, training acc = 0.98
Batch [200/704] training loss = 0.0836, training acc = 0.97
Batch [400/704] training loss = 0.0388, training acc = 0.98
Batch [600/704] training loss = 0.0727, training acc = 0.98
Valid Test with nat
Test accuracy: 92.72% (4636/5000), Test loss:0.2975
Epoch [93/100], Passed time:[79.333/7377.955]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0357, training acc = 0.98
Batch [200/704] training loss = 0.0162, training acc = 1.00
Batch [400/704] training loss = 0.0266, training acc = 0.98
Batch [600/704] training loss = 0.0141, training acc = 1.00
Valid Test with nat
Test accuracy: 92.82% (4641/5000), Test loss:0.2923
Epoch [94/100], Passed time:[79.310/7455.096]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0041, training acc = 1.00
Batch [200/704] training loss = 0.0063, training acc = 1.00
Batch [400/704] training loss = 0.0350, training acc = 1.00
Batch [600/704] training loss = 0.0390, training acc = 1.00
Valid Test with nat
Test accuracy: 92.54% (4627/5000), Test loss:0.2975
Epoch [95/100], Passed time:[79.314/7534.798]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0433, training acc = 0.98
Batch [200/704] training loss = 0.0036, training acc = 1.00
Batch [400/704] training loss = 0.0155, training acc = 0.98
Batch [600/704] training loss = 0.0094, training acc = 1.00
Valid Test with nat
Test accuracy: 92.76% (4638/5000), Test loss:0.2922
Epoch [96/100], Passed time:[79.320/7614.735]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0095, training acc = 1.00
Batch [200/704] training loss = 0.0391, training acc = 0.98
Batch [400/704] training loss = 0.1578, training acc = 0.98
Batch [600/704] training loss = 0.0471, training acc = 0.97
Valid Test with nat
Test accuracy: 92.92% (4646/5000), Test loss:0.2914
Epoch [97/100], Passed time:[79.310/7693.050]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0933, training acc = 0.95
Batch [200/704] training loss = 0.0458, training acc = 0.98
Batch [400/704] training loss = 0.0739, training acc = 0.97
Batch [600/704] training loss = 0.0194, training acc = 1.00
Valid Test with nat
Test accuracy: 92.68% (4634/5000), Test loss:0.2936
Epoch [98/100], Passed time:[79.359/7777.222]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0620, training acc = 0.98
Batch [200/704] training loss = 0.0176, training acc = 1.00
Batch [400/704] training loss = 0.0290, training acc = 0.98
Batch [600/704] training loss = 0.0119, training acc = 1.00
Valid Test with nat
Test accuracy: 92.80% (4640/5000), Test loss:0.2973
Epoch [99/100], Passed time:[79.359/7856.525]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0142, training acc = 1.00
Batch [200/704] training loss = 0.0249, training acc = 0.98
Batch [400/704] training loss = 0.0993, training acc = 0.95
Batch [600/704] training loss = 0.0265, training acc = 1.00
Valid Test with nat
Test accuracy: 92.84% (4642/5000), Test loss:0.3069
Training done, model saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r65/init_pure/seed9_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 92.34% (9234/10000), Test loss:0.3211
