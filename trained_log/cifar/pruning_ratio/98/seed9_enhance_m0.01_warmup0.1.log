results_path : None
model_name : seed9_enhance_m0.01_warmup0.1
learning_rate : 0.1
init_step : 1400
train_method : nat
model_path : ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r98/init_pure/seed9_enhance_m0.01_warmup0.1.pth
n_pruning_steps : 1
gpu : 1
mask_path : ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r98/init_pure/pruned_lr0.01_mask_r98.npy
early_stop : 50
norm : True
last_model_path : ./trained_models_new/
dataset : cifar
parallel : False
clip_min : 0
model_width : 8
model_type : vgg16
targeted : False
transfer : False
eval : False
weight_decay : 0.0001
init : False
test_batch_size : 100
verbose : 200
ft_interval_weight : 50
resume : 0
prune_method : unstructured
optm : sgd
init_type : pure
starting_epsilon : 1e-05
n_classes : 10
epsilon : 0.03137254901960784
warmup : True
log_path : ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r98/init_pure/seed9_enhance_m0.01_warmup0.1.log
init_path : ./trained_models_new/cifar/vgg16/init/pure_vgg16_init.pth
interval_weight : 0.1
eps_step : 0.00784313725490196
enhance_method : nat
clip_max : 1.0
schedule_length : 10
seed : 9
trades_beta : 6.0
train_epochs : 100
create_init : False
noise_sd : 1.0
max_pruning_ratio : 98
mask_name : pruned_lr0.01_mask_r98
attack_iter : 10
enhance_epochs : None
enhance_learning_rate : 0.1
batch_size : 64
finetune_method : nat
CUDA enabled.
Enhance training config:
Enhance training method: nat
model will be saved in: ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r98/init_pure/seed9_enhance_m0.01_warmup0.1.pth
Init model is: ./trained_models_new/cifar/vgg16/init/pure_vgg16_init.pth
Init mask used from: ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r98/init_pure/pruned_lr0.01_mask_r98.npy
Log will be saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r98/init_pure/seed9_enhance_m0.01_warmup0.1.log
Random seed is: 9

Epoch [0/100]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 2.3041, training acc = 0.08
Batch [200/704] training loss = 2.0936, training acc = 0.27
Batch [400/704] training loss = 1.7115, training acc = 0.41
Batch [600/704] training loss = 1.6497, training acc = 0.42
Valid Test with nat
Test accuracy: 41.40% (2070/5000), Test loss:1.7206
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r98/init_pure/seed9_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 36.55% (3655/10000), Test loss:1.8349
Epoch [1/100], Passed time:[65.628/65.628]
learning rate: 0.020000000000000004
Batch [0/704] training loss = 1.5636, training acc = 0.45
Batch [200/704] training loss = 1.7731, training acc = 0.31
Batch [400/704] training loss = 1.2587, training acc = 0.58
Batch [600/704] training loss = 1.4680, training acc = 0.50
Valid Test with nat
Test accuracy: 55.64% (2782/5000), Test loss:1.3081
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r98/init_pure/seed9_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 56.62% (5662/10000), Test loss:1.2582
Epoch [2/100], Passed time:[64.613/129.226]
learning rate: 0.030000000000000006
Batch [0/704] training loss = 1.1585, training acc = 0.61
Batch [200/704] training loss = 1.2299, training acc = 0.52
Batch [400/704] training loss = 1.0322, training acc = 0.64
Batch [600/704] training loss = 1.0493, training acc = 0.66
Valid Test with nat
Test accuracy: 52.98% (2649/5000), Test loss:1.4696
Epoch [3/100], Passed time:[63.526/190.578]
learning rate: 0.04000000000000001
Batch [0/704] training loss = 1.0423, training acc = 0.58
Batch [200/704] training loss = 1.0488, training acc = 0.67
Batch [400/704] training loss = 1.1604, training acc = 0.58
Batch [600/704] training loss = 1.4876, training acc = 0.53
Valid Test with nat
Test accuracy: 65.78% (3289/5000), Test loss:0.9721
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r98/init_pure/seed9_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 64.44% (6444/10000), Test loss:1.0137
Epoch [4/100], Passed time:[63.817/255.269]
learning rate: 0.05
Batch [0/704] training loss = 1.2354, training acc = 0.59
Batch [200/704] training loss = 0.9864, training acc = 0.64
Batch [400/704] training loss = 1.1070, training acc = 0.58
Batch [600/704] training loss = 0.8880, training acc = 0.66
Valid Test with nat
Test accuracy: 67.92% (3396/5000), Test loss:0.9447
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r98/init_pure/seed9_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 68.61% (6861/10000), Test loss:0.9009
Epoch [5/100], Passed time:[64.088/320.442]
learning rate: 0.06000000000000001
Batch [0/704] training loss = 0.5586, training acc = 0.78
Batch [200/704] training loss = 0.9401, training acc = 0.66
Batch [400/704] training loss = 1.0332, training acc = 0.67
Batch [600/704] training loss = 0.7201, training acc = 0.77
Valid Test with nat
Test accuracy: 66.58% (3329/5000), Test loss:1.0118
Epoch [6/100], Passed time:[64.066/384.394]
learning rate: 0.07
Batch [0/704] training loss = 0.9794, training acc = 0.62
Batch [200/704] training loss = 0.6812, training acc = 0.77
Batch [400/704] training loss = 0.9925, training acc = 0.58
Batch [600/704] training loss = 0.8055, training acc = 0.75
Valid Test with nat
Test accuracy: 71.12% (3556/5000), Test loss:0.8294
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r98/init_pure/seed9_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 73.04% (7304/10000), Test loss:0.7771
Epoch [7/100], Passed time:[64.228/449.597]
learning rate: 0.08000000000000002
Batch [0/704] training loss = 0.9603, training acc = 0.67
Batch [200/704] training loss = 0.8241, training acc = 0.73
Batch [400/704] training loss = 1.0331, training acc = 0.66
Batch [600/704] training loss = 0.8196, training acc = 0.78
Valid Test with nat
Test accuracy: 69.00% (3450/5000), Test loss:0.9212
Epoch [8/100], Passed time:[63.971/511.769]
learning rate: 0.09000000000000001
Batch [0/704] training loss = 0.8370, training acc = 0.67
Batch [200/704] training loss = 0.7315, training acc = 0.70
Batch [400/704] training loss = 1.0244, training acc = 0.69
Batch [600/704] training loss = 0.7395, training acc = 0.72
Valid Test with nat
Test accuracy: 72.96% (3648/5000), Test loss:0.7977
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r98/init_pure/seed9_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 73.13% (7313/10000), Test loss:0.7795
Epoch [9/100], Passed time:[64.188/577.696]
learning rate: 0.1
Batch [0/704] training loss = 0.8506, training acc = 0.72
Batch [200/704] training loss = 0.7404, training acc = 0.75
Batch [400/704] training loss = 0.8324, training acc = 0.69
Batch [600/704] training loss = 0.5717, training acc = 0.81
Valid Test with nat
Test accuracy: 68.76% (3438/5000), Test loss:0.9063
Epoch [10/100], Passed time:[63.974/639.743]
learning rate: 0.1
Batch [0/704] training loss = 0.7916, training acc = 0.73
Batch [200/704] training loss = 0.5396, training acc = 0.83
Batch [400/704] training loss = 0.9354, training acc = 0.67
Batch [600/704] training loss = 0.8205, training acc = 0.67
Valid Test with nat
Test accuracy: 70.52% (3526/5000), Test loss:0.8644
Epoch [11/100], Passed time:[63.902/702.922]
learning rate: 0.1
Batch [0/704] training loss = 0.9390, training acc = 0.75
Batch [200/704] training loss = 0.7768, training acc = 0.70
Batch [400/704] training loss = 0.6871, training acc = 0.72
Batch [600/704] training loss = 0.8591, training acc = 0.66
Valid Test with nat
Test accuracy: 63.38% (3169/5000), Test loss:1.2099
Epoch [12/100], Passed time:[63.751/765.013]
learning rate: 0.1
Batch [0/704] training loss = 0.7002, training acc = 0.75
Batch [200/704] training loss = 0.7294, training acc = 0.77
Batch [400/704] training loss = 0.7934, training acc = 0.69
Batch [600/704] training loss = 0.7151, training acc = 0.75
Valid Test with nat
Test accuracy: 70.34% (3517/5000), Test loss:0.9262
Epoch [13/100], Passed time:[63.689/827.955]
learning rate: 0.1
Batch [0/704] training loss = 0.5178, training acc = 0.84
Batch [200/704] training loss = 0.7798, training acc = 0.69
Batch [400/704] training loss = 0.7287, training acc = 0.75
Batch [600/704] training loss = 0.8182, training acc = 0.64
Valid Test with nat
Test accuracy: 73.88% (3694/5000), Test loss:0.7926
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r98/init_pure/seed9_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 74.01% (7401/10000), Test loss:0.7741
Epoch [14/100], Passed time:[63.675/891.447]
learning rate: 0.1
Batch [0/704] training loss = 0.7187, training acc = 0.70
Batch [200/704] training loss = 0.6736, training acc = 0.75
Batch [400/704] training loss = 0.8855, training acc = 0.69
Batch [600/704] training loss = 0.7322, training acc = 0.81
Valid Test with nat
Test accuracy: 74.98% (3749/5000), Test loss:0.7405
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r98/init_pure/seed9_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 75.87% (7587/10000), Test loss:0.7139
Epoch [15/100], Passed time:[63.817/957.260]
learning rate: 0.1
Batch [0/704] training loss = 0.6325, training acc = 0.80
Batch [200/704] training loss = 0.7109, training acc = 0.73
Batch [400/704] training loss = 0.7509, training acc = 0.61
Batch [600/704] training loss = 1.2530, training acc = 0.62
Valid Test with nat
Test accuracy: 71.58% (3579/5000), Test loss:0.8521
Epoch [16/100], Passed time:[63.766/1020.264]
learning rate: 0.1
Batch [0/704] training loss = 0.6116, training acc = 0.80
Batch [200/704] training loss = 0.5977, training acc = 0.81
Batch [400/704] training loss = 0.8336, training acc = 0.70
Batch [600/704] training loss = 0.9209, training acc = 0.72
Valid Test with nat
Test accuracy: 73.84% (3692/5000), Test loss:0.8069
Epoch [17/100], Passed time:[63.701/1082.921]
learning rate: 0.1
Batch [0/704] training loss = 0.6092, training acc = 0.78
Batch [200/704] training loss = 0.7658, training acc = 0.70
Batch [400/704] training loss = 0.6477, training acc = 0.81
Batch [600/704] training loss = 0.6551, training acc = 0.77
Valid Test with nat
Test accuracy: 75.76% (3788/5000), Test loss:0.7083
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r98/init_pure/seed9_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 75.95% (7595/10000), Test loss:0.7108
Epoch [18/100], Passed time:[63.836/1149.055]
learning rate: 0.1
Batch [0/704] training loss = 0.6409, training acc = 0.75
Batch [200/704] training loss = 0.5916, training acc = 0.81
Batch [400/704] training loss = 0.7322, training acc = 0.77
Batch [600/704] training loss = 0.7919, training acc = 0.70
Valid Test with nat
Test accuracy: 70.80% (3540/5000), Test loss:0.8644
Epoch [19/100], Passed time:[63.728/1210.828]
learning rate: 0.1
Batch [0/704] training loss = 0.7550, training acc = 0.77
Batch [200/704] training loss = 0.9722, training acc = 0.64
Batch [400/704] training loss = 1.0543, training acc = 0.67
Batch [600/704] training loss = 0.8732, training acc = 0.66
Valid Test with nat
Test accuracy: 70.96% (3548/5000), Test loss:0.8758
Epoch [20/100], Passed time:[63.681/1273.630]
learning rate: 0.1
Batch [0/704] training loss = 0.5060, training acc = 0.83
Batch [200/704] training loss = 0.7956, training acc = 0.72
Batch [400/704] training loss = 0.7035, training acc = 0.75
Batch [600/704] training loss = 0.7617, training acc = 0.70
Valid Test with nat
Test accuracy: 73.82% (3691/5000), Test loss:0.7785
Epoch [21/100], Passed time:[63.643/1336.505]
learning rate: 0.1
Batch [0/704] training loss = 0.8653, training acc = 0.75
Batch [200/704] training loss = 0.5550, training acc = 0.72
Batch [400/704] training loss = 0.6232, training acc = 0.78
Batch [600/704] training loss = 0.6510, training acc = 0.80
Valid Test with nat
Test accuracy: 77.72% (3886/5000), Test loss:0.6631
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r98/init_pure/seed9_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 77.17% (7717/10000), Test loss:0.6660
Epoch [22/100], Passed time:[63.688/1401.127]
learning rate: 0.1
Batch [0/704] training loss = 0.7720, training acc = 0.72
Batch [200/704] training loss = 0.5946, training acc = 0.75
Batch [400/704] training loss = 0.7649, training acc = 0.78
Batch [600/704] training loss = 0.7724, training acc = 0.67
Valid Test with nat
Test accuracy: 76.20% (3810/5000), Test loss:0.7226
Epoch [23/100], Passed time:[63.645/1463.829]
learning rate: 0.1
Batch [0/704] training loss = 0.8685, training acc = 0.66
Batch [200/704] training loss = 0.7532, training acc = 0.73
Batch [400/704] training loss = 0.6876, training acc = 0.72
Batch [600/704] training loss = 0.8759, training acc = 0.72
Valid Test with nat
Test accuracy: 77.76% (3888/5000), Test loss:0.6924
Epoch [24/100], Passed time:[63.642/1527.400]
learning rate: 0.1
Batch [0/704] training loss = 0.5645, training acc = 0.75
Batch [200/704] training loss = 0.6614, training acc = 0.73
Batch [400/704] training loss = 0.4827, training acc = 0.83
Batch [600/704] training loss = 0.8237, training acc = 0.72
Valid Test with nat
Test accuracy: 66.16% (3308/5000), Test loss:0.9942
Epoch [25/100], Passed time:[63.545/1588.636]
learning rate: 0.1
Batch [0/704] training loss = 0.9585, training acc = 0.67
Batch [200/704] training loss = 0.5521, training acc = 0.77
Batch [400/704] training loss = 0.5232, training acc = 0.89
Batch [600/704] training loss = 0.8592, training acc = 0.67
Valid Test with nat
Test accuracy: 78.14% (3907/5000), Test loss:0.6520
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r98/init_pure/seed9_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 76.24% (7624/10000), Test loss:0.7011
Epoch [26/100], Passed time:[63.651/1654.927]
learning rate: 0.1
Batch [0/704] training loss = 0.9120, training acc = 0.66
Batch [200/704] training loss = 0.7927, training acc = 0.73
Batch [400/704] training loss = 0.8378, training acc = 0.73
Batch [600/704] training loss = 0.4395, training acc = 0.84
Valid Test with nat
Test accuracy: 76.34% (3817/5000), Test loss:0.6917
Epoch [27/100], Passed time:[63.664/1718.919]
learning rate: 0.1
Batch [0/704] training loss = 0.7162, training acc = 0.78
Batch [200/704] training loss = 0.5746, training acc = 0.77
Batch [400/704] training loss = 0.8242, training acc = 0.69
Batch [600/704] training loss = 0.7772, training acc = 0.75
Valid Test with nat
Test accuracy: 74.30% (3715/5000), Test loss:0.7410
Epoch [28/100], Passed time:[63.646/1782.084]
learning rate: 0.1
Batch [0/704] training loss = 0.8013, training acc = 0.70
Batch [200/704] training loss = 0.7643, training acc = 0.69
Batch [400/704] training loss = 0.4976, training acc = 0.84
Batch [600/704] training loss = 0.7438, training acc = 0.75
Valid Test with nat
Test accuracy: 77.10% (3855/5000), Test loss:0.6703
Epoch [29/100], Passed time:[63.633/1845.349]
learning rate: 0.1
Batch [0/704] training loss = 0.8603, training acc = 0.72
Batch [200/704] training loss = 0.6564, training acc = 0.78
Batch [400/704] training loss = 0.3539, training acc = 0.89
Batch [600/704] training loss = 0.5888, training acc = 0.75
Valid Test with nat
Test accuracy: 76.14% (3807/5000), Test loss:0.7201
Epoch [30/100], Passed time:[63.603/1908.092]
learning rate: 0.1
Batch [0/704] training loss = 0.6996, training acc = 0.80
Batch [200/704] training loss = 0.6732, training acc = 0.73
Batch [400/704] training loss = 0.6979, training acc = 0.77
Batch [600/704] training loss = 0.5623, training acc = 0.83
Valid Test with nat
Test accuracy: 75.70% (3785/5000), Test loss:0.7402
Epoch [31/100], Passed time:[63.600/1971.604]
learning rate: 0.1
Batch [0/704] training loss = 0.6431, training acc = 0.77
Batch [200/704] training loss = 0.4637, training acc = 0.81
Batch [400/704] training loss = 0.7237, training acc = 0.72
Batch [600/704] training loss = 0.4084, training acc = 0.86
Valid Test with nat
Test accuracy: 77.24% (3862/5000), Test loss:0.6693
Epoch [32/100], Passed time:[63.599/2035.179]
learning rate: 0.1
Batch [0/704] training loss = 0.5649, training acc = 0.80
Batch [200/704] training loss = 0.5643, training acc = 0.77
Batch [400/704] training loss = 0.7762, training acc = 0.77
Batch [600/704] training loss = 0.5622, training acc = 0.80
Valid Test with nat
Test accuracy: 77.32% (3866/5000), Test loss:0.6630
Epoch [33/100], Passed time:[63.599/2098.758]
learning rate: 0.1
Batch [0/704] training loss = 0.6807, training acc = 0.75
Batch [200/704] training loss = 0.5754, training acc = 0.80
Batch [400/704] training loss = 0.6007, training acc = 0.77
Batch [600/704] training loss = 0.6396, training acc = 0.77
Valid Test with nat
Test accuracy: 75.54% (3777/5000), Test loss:0.7496
Epoch [34/100], Passed time:[63.711/2166.188]
learning rate: 0.1
Batch [0/704] training loss = 0.7067, training acc = 0.75
Batch [200/704] training loss = 0.6054, training acc = 0.83
Batch [400/704] training loss = 0.6552, training acc = 0.73
Batch [600/704] training loss = 0.7668, training acc = 0.77
Valid Test with nat
Test accuracy: 75.50% (3775/5000), Test loss:0.7167
Epoch [35/100], Passed time:[63.803/2233.098]
learning rate: 0.1
Batch [0/704] training loss = 0.6635, training acc = 0.75
Batch [200/704] training loss = 0.6815, training acc = 0.72
Batch [400/704] training loss = 0.6348, training acc = 0.81
Batch [600/704] training loss = 0.5482, training acc = 0.78
Valid Test with nat
Test accuracy: 76.64% (3832/5000), Test loss:0.6920
Epoch [36/100], Passed time:[63.955/2302.363]
learning rate: 0.1
Batch [0/704] training loss = 0.6053, training acc = 0.80
Batch [200/704] training loss = 0.6496, training acc = 0.78
Batch [400/704] training loss = 0.5933, training acc = 0.84
Batch [600/704] training loss = 0.7767, training acc = 0.75
Valid Test with nat
Test accuracy: 74.76% (3738/5000), Test loss:0.7579
Epoch [37/100], Passed time:[64.002/2368.070]
learning rate: 0.1
Batch [0/704] training loss = 0.8578, training acc = 0.70
Batch [200/704] training loss = 0.6273, training acc = 0.78
Batch [400/704] training loss = 0.4710, training acc = 0.81
Batch [600/704] training loss = 0.7782, training acc = 0.80
Valid Test with nat
Test accuracy: 74.42% (3721/5000), Test loss:0.7653
Epoch [38/100], Passed time:[64.093/2435.523]
learning rate: 0.1
Batch [0/704] training loss = 0.6872, training acc = 0.72
Batch [200/704] training loss = 0.9249, training acc = 0.75
Batch [400/704] training loss = 0.5455, training acc = 0.80
Batch [600/704] training loss = 0.6979, training acc = 0.73
Valid Test with nat
Test accuracy: 77.10% (3855/5000), Test loss:0.6771
Epoch [39/100], Passed time:[64.173/2502.735]
learning rate: 0.1
Batch [0/704] training loss = 0.5164, training acc = 0.81
Batch [200/704] training loss = 0.8169, training acc = 0.69
Batch [400/704] training loss = 0.7551, training acc = 0.70
Batch [600/704] training loss = 0.7739, training acc = 0.69
Valid Test with nat
Test accuracy: 75.52% (3776/5000), Test loss:0.7310
Epoch [40/100], Passed time:[64.277/2571.081]
learning rate: 0.1
Batch [0/704] training loss = 0.6131, training acc = 0.78
Batch [200/704] training loss = 0.8231, training acc = 0.73
Batch [400/704] training loss = 0.6749, training acc = 0.75
Batch [600/704] training loss = 0.7516, training acc = 0.75
Valid Test with nat
Test accuracy: 75.80% (3790/5000), Test loss:0.7422
Epoch [41/100], Passed time:[64.390/2639.994]
learning rate: 0.1
Batch [0/704] training loss = 0.4790, training acc = 0.83
Batch [200/704] training loss = 0.6201, training acc = 0.78
Batch [400/704] training loss = 0.6885, training acc = 0.77
Batch [600/704] training loss = 0.7660, training acc = 0.75
Valid Test with nat
Test accuracy: 76.82% (3841/5000), Test loss:0.6811
Epoch [42/100], Passed time:[64.470/2707.761]
learning rate: 0.1
Batch [0/704] training loss = 0.8703, training acc = 0.72
Batch [200/704] training loss = 0.6859, training acc = 0.78
Batch [400/704] training loss = 0.7341, training acc = 0.70
Batch [600/704] training loss = 0.5780, training acc = 0.73
Valid Test with nat
Test accuracy: 76.44% (3822/5000), Test loss:0.7203
Epoch [43/100], Passed time:[64.568/2776.408]
learning rate: 0.1
Batch [0/704] training loss = 0.6219, training acc = 0.80
Batch [200/704] training loss = 0.5675, training acc = 0.80
Batch [400/704] training loss = 0.4800, training acc = 0.84
Batch [600/704] training loss = 0.6470, training acc = 0.78
Valid Test with nat
Test accuracy: 74.54% (3727/5000), Test loss:0.8097
Epoch [44/100], Passed time:[64.644/2844.358]
learning rate: 0.1
Batch [0/704] training loss = 0.4423, training acc = 0.84
Batch [200/704] training loss = 0.5624, training acc = 0.84
Batch [400/704] training loss = 0.7265, training acc = 0.80
Batch [600/704] training loss = 0.5467, training acc = 0.83
Valid Test with nat
Test accuracy: 77.24% (3862/5000), Test loss:0.6652
Epoch [45/100], Passed time:[64.740/2913.283]
learning rate: 0.1
Batch [0/704] training loss = 0.5789, training acc = 0.78
Batch [200/704] training loss = 0.6130, training acc = 0.72
Batch [400/704] training loss = 0.4843, training acc = 0.77
Batch [600/704] training loss = 0.5025, training acc = 0.75
Valid Test with nat
Test accuracy: 77.82% (3891/5000), Test loss:0.6855
Epoch [46/100], Passed time:[64.784/2980.083]
learning rate: 0.1
Batch [0/704] training loss = 0.6776, training acc = 0.78
Batch [200/704] training loss = 0.6008, training acc = 0.77
Batch [400/704] training loss = 0.7428, training acc = 0.80
Batch [600/704] training loss = 0.8687, training acc = 0.70
Valid Test with nat
Test accuracy: 78.50% (3925/5000), Test loss:0.6463
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r98/init_pure/seed9_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 77.82% (7782/10000), Test loss:0.6688
Epoch [47/100], Passed time:[64.918/3051.128]
learning rate: 0.1
Batch [0/704] training loss = 0.5480, training acc = 0.81
Batch [200/704] training loss = 0.5754, training acc = 0.81
Batch [400/704] training loss = 0.6683, training acc = 0.75
Batch [600/704] training loss = 0.6850, training acc = 0.75
Valid Test with nat
Test accuracy: 74.56% (3728/5000), Test loss:0.7493
Epoch [48/100], Passed time:[64.978/3118.932]
learning rate: 0.1
Batch [0/704] training loss = 0.5763, training acc = 0.78
Batch [200/704] training loss = 0.6347, training acc = 0.80
Batch [400/704] training loss = 0.6818, training acc = 0.78
Batch [600/704] training loss = 0.7232, training acc = 0.80
Valid Test with nat
Test accuracy: 79.16% (3958/5000), Test loss:0.6333
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r98/init_pure/seed9_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 78.77% (7877/10000), Test loss:0.6269
Epoch [49/100], Passed time:[65.108/3190.313]
learning rate: 0.1
Batch [0/704] training loss = 0.6021, training acc = 0.81
Batch [200/704] training loss = 0.6763, training acc = 0.77
Batch [400/704] training loss = 0.6003, training acc = 0.77
Batch [600/704] training loss = 0.7156, training acc = 0.75
Valid Test with nat
Test accuracy: 76.86% (3843/5000), Test loss:0.6989
Epoch [50/100], Passed time:[65.130/3256.516]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.6200, training acc = 0.80
Batch [200/704] training loss = 0.4240, training acc = 0.88
Batch [400/704] training loss = 0.5251, training acc = 0.84
Batch [600/704] training loss = 0.4935, training acc = 0.83
Valid Test with nat
Test accuracy: 82.76% (4138/5000), Test loss:0.4991
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r98/init_pure/seed9_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 82.88% (8288/10000), Test loss:0.4943
Epoch [51/100], Passed time:[65.213/3325.878]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.4658, training acc = 0.86
Batch [200/704] training loss = 0.5398, training acc = 0.80
Batch [400/704] training loss = 0.3166, training acc = 0.91
Batch [600/704] training loss = 0.6063, training acc = 0.80
Valid Test with nat
Test accuracy: 83.78% (4189/5000), Test loss:0.4761
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r98/init_pure/seed9_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 83.60% (8360/10000), Test loss:0.4769
Epoch [52/100], Passed time:[65.293/3395.259]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.4692, training acc = 0.80
Batch [200/704] training loss = 0.4995, training acc = 0.84
Batch [400/704] training loss = 0.7220, training acc = 0.70
Batch [600/704] training loss = 0.4732, training acc = 0.86
Valid Test with nat
Test accuracy: 84.68% (4234/5000), Test loss:0.4694
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r98/init_pure/seed9_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 83.90% (8390/10000), Test loss:0.4703
Epoch [53/100], Passed time:[65.372/3464.740]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.6339, training acc = 0.81
Batch [200/704] training loss = 0.5282, training acc = 0.83
Batch [400/704] training loss = 0.7072, training acc = 0.75
Batch [600/704] training loss = 0.6163, training acc = 0.80
Valid Test with nat
Test accuracy: 84.38% (4219/5000), Test loss:0.4655
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r98/init_pure/seed9_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 84.34% (8434/10000), Test loss:0.4565
Epoch [54/100], Passed time:[65.441/3533.796]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.3620, training acc = 0.83
Batch [200/704] training loss = 0.4731, training acc = 0.83
Batch [400/704] training loss = 0.3640, training acc = 0.84
Batch [600/704] training loss = 0.5182, training acc = 0.81
Valid Test with nat
Test accuracy: 84.22% (4211/5000), Test loss:0.4659
Epoch [55/100], Passed time:[65.519/3603.540]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.5062, training acc = 0.81
Batch [200/704] training loss = 0.3590, training acc = 0.84
Batch [400/704] training loss = 0.3931, training acc = 0.84
Batch [600/704] training loss = 0.5536, training acc = 0.80
Valid Test with nat
Test accuracy: 84.76% (4238/5000), Test loss:0.4552
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r98/init_pure/seed9_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 84.73% (8473/10000), Test loss:0.4601
Epoch [56/100], Passed time:[65.616/3674.486]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.3341, training acc = 0.88
Batch [200/704] training loss = 0.3863, training acc = 0.89
Batch [400/704] training loss = 0.2618, training acc = 0.89
Batch [600/704] training loss = 0.4010, training acc = 0.86
Valid Test with nat
Test accuracy: 85.02% (4251/5000), Test loss:0.4527
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r98/init_pure/seed9_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 84.74% (8474/10000), Test loss:0.4562
Epoch [57/100], Passed time:[65.699/3744.831]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.2152, training acc = 0.94
Batch [200/704] training loss = 0.3086, training acc = 0.89
Batch [400/704] training loss = 0.4292, training acc = 0.81
Batch [600/704] training loss = 0.4195, training acc = 0.81
Valid Test with nat
Test accuracy: 84.56% (4228/5000), Test loss:0.4687
Epoch [58/100], Passed time:[65.746/3813.288]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.7112, training acc = 0.70
Batch [200/704] training loss = 0.5024, training acc = 0.83
Batch [400/704] training loss = 0.6111, training acc = 0.78
Batch [600/704] training loss = 0.2875, training acc = 0.91
Valid Test with nat
Test accuracy: 84.64% (4232/5000), Test loss:0.4532
Epoch [59/100], Passed time:[65.775/3880.698]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.3185, training acc = 0.86
Batch [200/704] training loss = 0.3949, training acc = 0.84
Batch [400/704] training loss = 0.4254, training acc = 0.83
Batch [600/704] training loss = 0.3369, training acc = 0.84
Valid Test with nat
Test accuracy: 85.16% (4258/5000), Test loss:0.4572
Epoch [60/100], Passed time:[65.824/3949.422]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.4610, training acc = 0.84
Batch [200/704] training loss = 0.5306, training acc = 0.86
Batch [400/704] training loss = 0.6513, training acc = 0.77
Batch [600/704] training loss = 0.3330, training acc = 0.88
Valid Test with nat
Test accuracy: 85.00% (4250/5000), Test loss:0.4569
Epoch [61/100], Passed time:[65.874/4018.316]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.3796, training acc = 0.86
Batch [200/704] training loss = 0.3413, training acc = 0.88
Batch [400/704] training loss = 0.3557, training acc = 0.84
Batch [600/704] training loss = 0.4067, training acc = 0.83
Valid Test with nat
Test accuracy: 84.70% (4235/5000), Test loss:0.4553
Epoch [62/100], Passed time:[65.906/4086.178]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.4278, training acc = 0.84
Batch [200/704] training loss = 0.4697, training acc = 0.86
Batch [400/704] training loss = 0.4949, training acc = 0.83
Batch [600/704] training loss = 0.3561, training acc = 0.89
Valid Test with nat
Test accuracy: 85.24% (4262/5000), Test loss:0.4533
Epoch [63/100], Passed time:[65.914/4152.559]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.3940, training acc = 0.81
Batch [200/704] training loss = 0.5128, training acc = 0.80
Batch [400/704] training loss = 0.4335, training acc = 0.83
Batch [600/704] training loss = 0.3694, training acc = 0.88
Valid Test with nat
Test accuracy: 84.86% (4243/5000), Test loss:0.4466
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r98/init_pure/seed9_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 84.76% (8476/10000), Test loss:0.4531
Epoch [64/100], Passed time:[65.980/4222.746]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.4293, training acc = 0.86
Batch [200/704] training loss = 0.3140, training acc = 0.91
Batch [400/704] training loss = 0.3829, training acc = 0.86
Batch [600/704] training loss = 0.5062, training acc = 0.86
Valid Test with nat
Test accuracy: 84.72% (4236/5000), Test loss:0.4638
Epoch [65/100], Passed time:[66.015/4290.999]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.6139, training acc = 0.84
Batch [200/704] training loss = 0.5332, training acc = 0.78
Batch [400/704] training loss = 0.4310, training acc = 0.86
Batch [600/704] training loss = 0.2831, training acc = 0.91
Valid Test with nat
Test accuracy: 84.80% (4240/5000), Test loss:0.4411
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r98/init_pure/seed9_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 84.80% (8480/10000), Test loss:0.4503
Epoch [66/100], Passed time:[66.075/4360.956]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.3072, training acc = 0.91
Batch [200/704] training loss = 0.4502, training acc = 0.80
Batch [400/704] training loss = 0.3352, training acc = 0.91
Batch [600/704] training loss = 0.4914, training acc = 0.78
Valid Test with nat
Test accuracy: 84.90% (4245/5000), Test loss:0.4478
Epoch [67/100], Passed time:[66.095/4428.333]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.2622, training acc = 0.95
Batch [200/704] training loss = 0.6218, training acc = 0.78
Batch [400/704] training loss = 0.5355, training acc = 0.81
Batch [600/704] training loss = 0.4130, training acc = 0.84
Valid Test with nat
Test accuracy: 85.12% (4256/5000), Test loss:0.4440
Epoch [68/100], Passed time:[66.105/4495.144]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.3623, training acc = 0.91
Batch [200/704] training loss = 0.5915, training acc = 0.78
Batch [400/704] training loss = 0.5175, training acc = 0.83
Batch [600/704] training loss = 0.3713, training acc = 0.88
Valid Test with nat
Test accuracy: 85.04% (4252/5000), Test loss:0.4526
Epoch [69/100], Passed time:[66.109/4561.507]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.2571, training acc = 0.94
Batch [200/704] training loss = 0.2991, training acc = 0.91
Batch [400/704] training loss = 0.4206, training acc = 0.81
Batch [600/704] training loss = 0.4462, training acc = 0.88
Valid Test with nat
Test accuracy: 85.48% (4274/5000), Test loss:0.4337
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r98/init_pure/seed9_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 84.89% (8489/10000), Test loss:0.4494
Epoch [70/100], Passed time:[66.176/4632.304]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.2916, training acc = 0.91
Batch [200/704] training loss = 0.4552, training acc = 0.86
Batch [400/704] training loss = 0.3333, training acc = 0.91
Batch [600/704] training loss = 0.3382, training acc = 0.94
Valid Test with nat
Test accuracy: 85.78% (4289/5000), Test loss:0.4323
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r98/init_pure/seed9_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 85.01% (8501/10000), Test loss:0.4454
Epoch [71/100], Passed time:[66.233/4702.521]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.4696, training acc = 0.86
Batch [200/704] training loss = 0.5255, training acc = 0.81
Batch [400/704] training loss = 0.1805, training acc = 0.98
Batch [600/704] training loss = 0.3629, training acc = 0.86
Valid Test with nat
Test accuracy: 85.20% (4260/5000), Test loss:0.4439
Epoch [72/100], Passed time:[66.263/4770.939]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.3556, training acc = 0.91
Batch [200/704] training loss = 0.4373, training acc = 0.84
Batch [400/704] training loss = 0.5573, training acc = 0.83
Batch [600/704] training loss = 0.3693, training acc = 0.86
Valid Test with nat
Test accuracy: 85.50% (4275/5000), Test loss:0.4360
Epoch [73/100], Passed time:[66.291/4839.240]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.3880, training acc = 0.88
Batch [200/704] training loss = 0.5344, training acc = 0.83
Batch [400/704] training loss = 0.5409, training acc = 0.80
Batch [600/704] training loss = 0.3917, training acc = 0.81
Valid Test with nat
Test accuracy: 85.58% (4279/5000), Test loss:0.4372
Epoch [74/100], Passed time:[66.301/4906.252]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.3492, training acc = 0.89
Batch [200/704] training loss = 0.2794, training acc = 0.89
Batch [400/704] training loss = 0.3961, training acc = 0.86
Batch [600/704] training loss = 0.6785, training acc = 0.88
Valid Test with nat
Test accuracy: 85.44% (4272/5000), Test loss:0.4388
Epoch [75/100], Passed time:[66.302/4972.638]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.4845, training acc = 0.83
Batch [200/704] training loss = 0.4911, training acc = 0.80
Batch [400/704] training loss = 0.5898, training acc = 0.77
Batch [600/704] training loss = 0.2817, training acc = 0.91
Valid Test with nat
Test accuracy: 85.94% (4297/5000), Test loss:0.4186
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r98/init_pure/seed9_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 85.22% (8522/10000), Test loss:0.4356
Epoch [76/100], Passed time:[66.350/5042.563]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.3024, training acc = 0.92
Batch [200/704] training loss = 0.3795, training acc = 0.91
Batch [400/704] training loss = 0.3599, training acc = 0.91
Batch [600/704] training loss = 0.2499, training acc = 0.91
Valid Test with nat
Test accuracy: 86.16% (4308/5000), Test loss:0.4168
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r98/init_pure/seed9_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 85.29% (8529/10000), Test loss:0.4423
Epoch [77/100], Passed time:[66.407/5113.328]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.4747, training acc = 0.83
Batch [200/704] training loss = 0.3109, training acc = 0.88
Batch [400/704] training loss = 0.2600, training acc = 0.89
Batch [600/704] training loss = 0.4515, training acc = 0.84
Valid Test with nat
Test accuracy: 86.52% (4326/5000), Test loss:0.4123
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r98/init_pure/seed9_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 85.28% (8528/10000), Test loss:0.4316
Epoch [78/100], Passed time:[66.460/5183.889]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.3745, training acc = 0.91
Batch [200/704] training loss = 0.4033, training acc = 0.88
Batch [400/704] training loss = 0.3783, training acc = 0.86
Batch [600/704] training loss = 0.3322, training acc = 0.86
Valid Test with nat
Test accuracy: 86.14% (4307/5000), Test loss:0.4200
Epoch [79/100], Passed time:[66.468/5250.961]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.2813, training acc = 0.89
Batch [200/704] training loss = 0.4244, training acc = 0.86
Batch [400/704] training loss = 0.2825, training acc = 0.92
Batch [600/704] training loss = 0.2738, training acc = 0.88
Valid Test with nat
Test accuracy: 86.10% (4305/5000), Test loss:0.4137
Epoch [80/100], Passed time:[66.467/5317.367]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.2777, training acc = 0.94
Batch [200/704] training loss = 0.3161, training acc = 0.94
Batch [400/704] training loss = 0.2364, training acc = 0.92
Batch [600/704] training loss = 0.2550, training acc = 0.94
Valid Test with nat
Test accuracy: 85.98% (4299/5000), Test loss:0.4118
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r98/init_pure/seed9_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 85.48% (8548/10000), Test loss:0.4287
Epoch [81/100], Passed time:[66.522/5388.305]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.4834, training acc = 0.83
Batch [200/704] training loss = 0.3301, training acc = 0.86
Batch [400/704] training loss = 0.3991, training acc = 0.88
Batch [600/704] training loss = 0.3576, training acc = 0.89
Valid Test with nat
Test accuracy: 85.98% (4299/5000), Test loss:0.4144
Epoch [82/100], Passed time:[66.517/5454.419]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.3036, training acc = 0.86
Batch [200/704] training loss = 0.4397, training acc = 0.88
Batch [400/704] training loss = 0.3509, training acc = 0.89
Batch [600/704] training loss = 0.5242, training acc = 0.83
Valid Test with nat
Test accuracy: 86.08% (4304/5000), Test loss:0.4162
Epoch [83/100], Passed time:[66.534/5522.343]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.3562, training acc = 0.83
Batch [200/704] training loss = 0.3625, training acc = 0.86
Batch [400/704] training loss = 0.3429, training acc = 0.86
Batch [600/704] training loss = 0.4402, training acc = 0.83
Valid Test with nat
Test accuracy: 85.98% (4299/5000), Test loss:0.4205
Epoch [84/100], Passed time:[66.564/5591.408]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.2984, training acc = 0.91
Batch [200/704] training loss = 0.1503, training acc = 0.92
Batch [400/704] training loss = 0.4058, training acc = 0.86
Batch [600/704] training loss = 0.4359, training acc = 0.89
Valid Test with nat
Test accuracy: 86.42% (4321/5000), Test loss:0.4056
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r98/init_pure/seed9_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 85.67% (8567/10000), Test loss:0.4303
Epoch [85/100], Passed time:[66.628/5663.354]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.4880, training acc = 0.84
Batch [200/704] training loss = 0.4764, training acc = 0.86
Batch [400/704] training loss = 0.4248, training acc = 0.86
Batch [600/704] training loss = 0.3931, training acc = 0.84
Valid Test with nat
Test accuracy: 86.30% (4315/5000), Test loss:0.4162
Epoch [86/100], Passed time:[66.650/5731.868]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.5101, training acc = 0.83
Batch [200/704] training loss = 0.3540, training acc = 0.86
Batch [400/704] training loss = 0.3356, training acc = 0.88
Batch [600/704] training loss = 0.3633, training acc = 0.88
Valid Test with nat
Test accuracy: 86.44% (4322/5000), Test loss:0.4121
Epoch [87/100], Passed time:[66.670/5800.261]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.3901, training acc = 0.84
Batch [200/704] training loss = 0.3000, training acc = 0.89
Batch [400/704] training loss = 0.2116, training acc = 0.92
Batch [600/704] training loss = 0.2920, training acc = 0.89
Valid Test with nat
Test accuracy: 86.38% (4319/5000), Test loss:0.4110
Epoch [88/100], Passed time:[66.678/5867.626]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.3618, training acc = 0.84
Batch [200/704] training loss = 0.2943, training acc = 0.89
Batch [400/704] training loss = 0.3943, training acc = 0.84
Batch [600/704] training loss = 0.1385, training acc = 0.95
Valid Test with nat
Test accuracy: 86.26% (4313/5000), Test loss:0.4120
Epoch [89/100], Passed time:[66.681/5934.641]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.2520, training acc = 0.88
Batch [200/704] training loss = 0.1048, training acc = 0.98
Batch [400/704] training loss = 0.3267, training acc = 0.88
Batch [600/704] training loss = 0.3129, training acc = 0.91
Valid Test with nat
Test accuracy: 86.40% (4320/5000), Test loss:0.4107
Epoch [90/100], Passed time:[66.704/6003.387]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.4152, training acc = 0.86
Batch [200/704] training loss = 0.1541, training acc = 0.95
Batch [400/704] training loss = 0.3513, training acc = 0.83
Batch [600/704] training loss = 0.3373, training acc = 0.88
Valid Test with nat
Test accuracy: 86.36% (4318/5000), Test loss:0.4045
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r98/init_pure/seed9_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 85.59% (8559/10000), Test loss:0.4314
Epoch [91/100], Passed time:[66.740/6073.349]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.3640, training acc = 0.89
Batch [200/704] training loss = 0.4418, training acc = 0.86
Batch [400/704] training loss = 0.3690, training acc = 0.86
Batch [600/704] training loss = 0.4453, training acc = 0.83
Valid Test with nat
Test accuracy: 86.48% (4324/5000), Test loss:0.4108
Epoch [92/100], Passed time:[66.751/6141.116]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.4393, training acc = 0.84
Batch [200/704] training loss = 0.2244, training acc = 0.94
Batch [400/704] training loss = 0.3340, training acc = 0.89
Batch [600/704] training loss = 0.3104, training acc = 0.91
Valid Test with nat
Test accuracy: 86.40% (4320/5000), Test loss:0.4221
Epoch [93/100], Passed time:[66.777/6210.267]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.3954, training acc = 0.91
Batch [200/704] training loss = 0.5244, training acc = 0.84
Batch [400/704] training loss = 0.2109, training acc = 0.92
Batch [600/704] training loss = 0.4311, training acc = 0.86
Valid Test with nat
Test accuracy: 86.62% (4331/5000), Test loss:0.4054
Epoch [94/100], Passed time:[66.776/6276.988]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.5288, training acc = 0.83
Batch [200/704] training loss = 0.2992, training acc = 0.88
Batch [400/704] training loss = 0.5210, training acc = 0.78
Batch [600/704] training loss = 0.2291, training acc = 0.88
Valid Test with nat
Test accuracy: 86.38% (4319/5000), Test loss:0.4212
Epoch [95/100], Passed time:[66.787/6344.724]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.3736, training acc = 0.89
Batch [200/704] training loss = 0.2119, training acc = 0.92
Batch [400/704] training loss = 0.4824, training acc = 0.80
Batch [600/704] training loss = 0.2903, training acc = 0.91
Valid Test with nat
Test accuracy: 86.58% (4329/5000), Test loss:0.4150
Epoch [96/100], Passed time:[66.802/6413.028]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.6074, training acc = 0.81
Batch [200/704] training loss = 0.3581, training acc = 0.91
Batch [400/704] training loss = 0.2214, training acc = 0.91
Batch [600/704] training loss = 0.3582, training acc = 0.88
Valid Test with nat
Test accuracy: 86.30% (4315/5000), Test loss:0.4098
Epoch [97/100], Passed time:[66.673/6467.242]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.2318, training acc = 0.91
Batch [200/704] training loss = 0.4174, training acc = 0.86
Batch [400/704] training loss = 0.2319, training acc = 0.92
Batch [600/704] training loss = 0.3723, training acc = 0.88
Valid Test with nat
Test accuracy: 86.38% (4319/5000), Test loss:0.4100
Epoch [98/100], Passed time:[66.466/6513.714]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.3301, training acc = 0.86
Batch [200/704] training loss = 0.4245, training acc = 0.88
Batch [400/704] training loss = 0.3430, training acc = 0.83
Batch [600/704] training loss = 0.3458, training acc = 0.92
Valid Test with nat
Test accuracy: 86.36% (4318/5000), Test loss:0.4061
Epoch [99/100], Passed time:[66.264/6560.128]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.4088, training acc = 0.86
Batch [200/704] training loss = 0.2426, training acc = 0.94
Batch [400/704] training loss = 0.3729, training acc = 0.84
Batch [600/704] training loss = 0.3962, training acc = 0.88
Valid Test with nat
Test accuracy: 86.16% (4308/5000), Test loss:0.4157
Training done, model saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r98/init_pure/seed9_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 85.65% (8565/10000), Test loss:0.4340
