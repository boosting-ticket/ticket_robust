model_type : vgg16
weight_decay : 0.0001
finetune_method : nat
init : True
last_model_path : ./trained_models_new/
model_path : ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r92/init_pure/init_enhance_m0.01_warmup0.1.pth
mask_name : pruned_lr0.01_mask_r92
trades_beta : 6.0
interval_weight : 0.1
train_epochs : 100
dataset : cifar
batch_size : 64
early_stop : 50
init_step : 1400
starting_epsilon : 1e-05
noise_sd : 1.0
schedule_length : 10
gpu : 2
attack_iter : 10
prune_method : unstructured
seed : 7
verbose : 200
n_pruning_steps : 1
learning_rate : 0.1
eps_step : 0.00784313725490196
mask_path : ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r92/init_pure/pruned_lr0.01_mask_r92.npy
log_path : ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r92/init_pure/init_enhance_m0.01_warmup0.1.log
clip_min : 0
n_classes : 10
test_batch_size : 100
model_width : 8
enhance_method : nat
enhance_epochs : None
warmup : True
clip_max : 1.0
transfer : False
resume : 0
optm : sgd
targeted : False
eval : False
enhance_learning_rate : 0.1
train_method : nat
model_name : init_enhance_m0.01_warmup0.1
init_type : pure
create_init : False
init_path : ./trained_models_new/cifar/vgg16/init/pure_vgg16_init.pth
norm : True
epsilon : 0.03137254901960784
results_path : None
ft_interval_weight : 50
max_pruning_ratio : 92
CUDA enabled.
Enhance training config:
Enhance training method: nat
model will be saved in: ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r92/init_pure/init_enhance_m0.01_warmup0.1.pth
Init model is: ./trained_models_new/cifar/vgg16/init/pure_vgg16_init.pth
Init mask used from: ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r92/init_pure/pruned_lr0.01_mask_r92.npy
Log will be saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r92/init_pure/init_enhance_m0.01_warmup0.1.log
Random seed is: 7

model loading from ./trained_models_new/cifar/vgg16/init/pure_vgg16_init.pth
Epoch [0/100]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 2.2805, training acc = 0.16
Batch [200/704] training loss = 1.3530, training acc = 0.50
Batch [400/704] training loss = 1.0993, training acc = 0.64
Batch [600/704] training loss = 0.6541, training acc = 0.78
Valid Test with nat
Test accuracy: 73.16% (3658/5000), Test loss:0.7881
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r92/init_pure/init_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 72.95% (7295/10000), Test loss:0.7904
Epoch [1/100], Passed time:[58.289/58.289]
learning rate: 0.020000000000000004
Batch [0/704] training loss = 0.6817, training acc = 0.72
Batch [200/704] training loss = 0.8239, training acc = 0.73
Batch [400/704] training loss = 0.6833, training acc = 0.78
Batch [600/704] training loss = 0.7998, training acc = 0.72
Valid Test with nat
Test accuracy: 76.58% (3829/5000), Test loss:0.7015
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r92/init_pure/init_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 74.64% (7464/10000), Test loss:0.7588
Epoch [2/100], Passed time:[60.484/120.968]
learning rate: 0.030000000000000006
Batch [0/704] training loss = 0.4130, training acc = 0.89
Batch [200/704] training loss = 0.5143, training acc = 0.80
Batch [400/704] training loss = 0.6817, training acc = 0.75
Batch [600/704] training loss = 0.6558, training acc = 0.75
Valid Test with nat
Test accuracy: 78.80% (3940/5000), Test loss:0.6256
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r92/init_pure/init_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 79.16% (7916/10000), Test loss:0.6206
Epoch [3/100], Passed time:[61.184/183.551]
learning rate: 0.04000000000000001
Batch [0/704] training loss = 0.4403, training acc = 0.86
Batch [200/704] training loss = 0.5969, training acc = 0.81
Batch [400/704] training loss = 0.6732, training acc = 0.77
Batch [600/704] training loss = 0.6178, training acc = 0.78
Valid Test with nat
Test accuracy: 79.74% (3987/5000), Test loss:0.6270
Epoch [4/100], Passed time:[61.183/244.733]
learning rate: 0.05
Batch [0/704] training loss = 0.3306, training acc = 0.88
Batch [200/704] training loss = 0.7032, training acc = 0.75
Batch [400/704] training loss = 0.5209, training acc = 0.81
Batch [600/704] training loss = 0.5611, training acc = 0.81
Valid Test with nat
Test accuracy: 80.82% (4041/5000), Test loss:0.5749
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r92/init_pure/init_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 80.91% (8091/10000), Test loss:0.5749
Epoch [5/100], Passed time:[61.676/308.381]
learning rate: 0.06000000000000001
Batch [0/704] training loss = 0.6032, training acc = 0.80
Batch [200/704] training loss = 0.4152, training acc = 0.88
Batch [400/704] training loss = 0.5247, training acc = 0.80
Batch [600/704] training loss = 0.4781, training acc = 0.83
Valid Test with nat
Test accuracy: 71.62% (3581/5000), Test loss:0.9002
Epoch [6/100], Passed time:[61.765/370.591]
learning rate: 0.07
Batch [0/704] training loss = 0.4935, training acc = 0.81
Batch [200/704] training loss = 0.6110, training acc = 0.81
Batch [400/704] training loss = 0.4725, training acc = 0.83
Batch [600/704] training loss = 0.5980, training acc = 0.80
Valid Test with nat
Test accuracy: 80.50% (4025/5000), Test loss:0.5862
Epoch [7/100], Passed time:[61.841/432.887]
learning rate: 0.08000000000000002
Batch [0/704] training loss = 0.4638, training acc = 0.83
Batch [200/704] training loss = 0.4292, training acc = 0.80
Batch [400/704] training loss = 0.6053, training acc = 0.81
Batch [600/704] training loss = 0.5692, training acc = 0.81
Valid Test with nat
Test accuracy: 77.46% (3873/5000), Test loss:0.6850
Epoch [8/100], Passed time:[61.961/495.684]
learning rate: 0.09000000000000001
Batch [0/704] training loss = 0.5329, training acc = 0.81
Batch [200/704] training loss = 0.6793, training acc = 0.77
Batch [400/704] training loss = 0.5027, training acc = 0.83
Batch [600/704] training loss = 0.4577, training acc = 0.86
Valid Test with nat
Test accuracy: 83.64% (4182/5000), Test loss:0.5021
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r92/init_pure/init_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 82.84% (8284/10000), Test loss:0.5137
Epoch [9/100], Passed time:[62.134/559.208]
learning rate: 0.1
Batch [0/704] training loss = 0.4989, training acc = 0.86
Batch [200/704] training loss = 0.4994, training acc = 0.81
Batch [400/704] training loss = 0.5319, training acc = 0.81
Batch [600/704] training loss = 0.2580, training acc = 0.91
Valid Test with nat
Test accuracy: 74.54% (3727/5000), Test loss:0.7859
Epoch [10/100], Passed time:[62.198/621.980]
learning rate: 0.1
Batch [0/704] training loss = 0.5904, training acc = 0.86
Batch [200/704] training loss = 0.5256, training acc = 0.81
Batch [400/704] training loss = 0.3109, training acc = 0.94
Batch [600/704] training loss = 0.5946, training acc = 0.75
Valid Test with nat
Test accuracy: 84.22% (4211/5000), Test loss:0.4866
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r92/init_pure/init_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 83.06% (8306/10000), Test loss:0.5089
Epoch [11/100], Passed time:[62.331/685.641]
learning rate: 0.1
Batch [0/704] training loss = 0.4933, training acc = 0.83
Batch [200/704] training loss = 0.3742, training acc = 0.84
Batch [400/704] training loss = 0.5018, training acc = 0.84
Batch [600/704] training loss = 0.4042, training acc = 0.81
Valid Test with nat
Test accuracy: 83.90% (4195/5000), Test loss:0.4830
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r92/init_pure/init_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 83.94% (8394/10000), Test loss:0.4714
Epoch [12/100], Passed time:[62.525/750.299]
learning rate: 0.1
Batch [0/704] training loss = 0.4901, training acc = 0.83
Batch [200/704] training loss = 0.5604, training acc = 0.80
Batch [400/704] training loss = 0.4822, training acc = 0.84
Batch [600/704] training loss = 0.6131, training acc = 0.80
Valid Test with nat
Test accuracy: 84.00% (4200/5000), Test loss:0.5060
Epoch [13/100], Passed time:[62.601/813.810]
learning rate: 0.1
Batch [0/704] training loss = 0.4983, training acc = 0.88
Batch [200/704] training loss = 0.3472, training acc = 0.88
Batch [400/704] training loss = 0.3458, training acc = 0.88
Batch [600/704] training loss = 0.4494, training acc = 0.84
Valid Test with nat
Test accuracy: 82.72% (4136/5000), Test loss:0.5249
Epoch [14/100], Passed time:[62.550/875.700]
learning rate: 0.1
Batch [0/704] training loss = 0.3013, training acc = 0.86
Batch [200/704] training loss = 0.5342, training acc = 0.80
Batch [400/704] training loss = 0.4353, training acc = 0.81
Batch [600/704] training loss = 0.2906, training acc = 0.89
Valid Test with nat
Test accuracy: 85.38% (4269/5000), Test loss:0.4547
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r92/init_pure/init_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 84.52% (8452/10000), Test loss:0.4582
Epoch [15/100], Passed time:[62.617/939.259]
learning rate: 0.1
Batch [0/704] training loss = 0.4617, training acc = 0.83
Batch [200/704] training loss = 0.4299, training acc = 0.86
Batch [400/704] training loss = 0.3929, training acc = 0.89
Batch [600/704] training loss = 0.4240, training acc = 0.89
Valid Test with nat
Test accuracy: 83.76% (4188/5000), Test loss:0.5052
Epoch [16/100], Passed time:[62.651/1002.416]
learning rate: 0.1
Batch [0/704] training loss = 0.5622, training acc = 0.78
Batch [200/704] training loss = 0.4937, training acc = 0.81
Batch [400/704] training loss = 0.3238, training acc = 0.88
Batch [600/704] training loss = 0.4219, training acc = 0.86
Valid Test with nat
Test accuracy: 82.60% (4130/5000), Test loss:0.5546
Epoch [17/100], Passed time:[62.578/1063.828]
learning rate: 0.1
Batch [0/704] training loss = 0.3082, training acc = 0.88
Batch [200/704] training loss = 0.2003, training acc = 0.95
Batch [400/704] training loss = 0.2644, training acc = 0.89
Batch [600/704] training loss = 0.5415, training acc = 0.78
Valid Test with nat
Test accuracy: 80.26% (4013/5000), Test loss:0.6102
Epoch [18/100], Passed time:[62.549/1125.884]
learning rate: 0.1
Batch [0/704] training loss = 0.3890, training acc = 0.83
Batch [200/704] training loss = 0.3424, training acc = 0.89
Batch [400/704] training loss = 0.2857, training acc = 0.91
Batch [600/704] training loss = 0.6138, training acc = 0.78
Valid Test with nat
Test accuracy: 81.60% (4080/5000), Test loss:0.6031
Epoch [19/100], Passed time:[62.617/1189.729]
learning rate: 0.1
Batch [0/704] training loss = 0.3896, training acc = 0.86
Batch [200/704] training loss = 0.3927, training acc = 0.84
Batch [400/704] training loss = 0.5572, training acc = 0.80
Batch [600/704] training loss = 0.3871, training acc = 0.89
Valid Test with nat
Test accuracy: 80.84% (4042/5000), Test loss:0.6267
Epoch [20/100], Passed time:[62.566/1251.330]
learning rate: 0.1
Batch [0/704] training loss = 0.5259, training acc = 0.86
Batch [200/704] training loss = 0.2698, training acc = 0.91
Batch [400/704] training loss = 0.4746, training acc = 0.80
Batch [600/704] training loss = 0.4216, training acc = 0.86
Valid Test with nat
Test accuracy: 84.80% (4240/5000), Test loss:0.4719
Epoch [21/100], Passed time:[62.546/1313.474]
learning rate: 0.1
Batch [0/704] training loss = 0.5041, training acc = 0.80
Batch [200/704] training loss = 0.3159, training acc = 0.86
Batch [400/704] training loss = 0.3524, training acc = 0.92
Batch [600/704] training loss = 0.2062, training acc = 0.94
Valid Test with nat
Test accuracy: 80.48% (4024/5000), Test loss:0.6307
Epoch [22/100], Passed time:[62.600/1377.206]
learning rate: 0.1
Batch [0/704] training loss = 0.3705, training acc = 0.83
Batch [200/704] training loss = 0.4008, training acc = 0.84
Batch [400/704] training loss = 0.3601, training acc = 0.88
Batch [600/704] training loss = 0.3070, training acc = 0.91
Valid Test with nat
Test accuracy: 84.24% (4212/5000), Test loss:0.4941
Epoch [23/100], Passed time:[62.554/1438.743]
learning rate: 0.1
Batch [0/704] training loss = 0.3529, training acc = 0.84
Batch [200/704] training loss = 0.3673, training acc = 0.89
Batch [400/704] training loss = 0.2706, training acc = 0.94
Batch [600/704] training loss = 0.6394, training acc = 0.80
Valid Test with nat
Test accuracy: 84.04% (4202/5000), Test loss:0.4883
Epoch [24/100], Passed time:[62.465/1499.171]
learning rate: 0.1
Batch [0/704] training loss = 0.1992, training acc = 0.94
Batch [200/704] training loss = 0.5290, training acc = 0.86
Batch [400/704] training loss = 0.3409, training acc = 0.88
Batch [600/704] training loss = 0.3266, training acc = 0.89
Valid Test with nat
Test accuracy: 82.18% (4109/5000), Test loss:0.5434
Epoch [25/100], Passed time:[62.435/1560.879]
learning rate: 0.1
Batch [0/704] training loss = 0.4637, training acc = 0.86
Batch [200/704] training loss = 0.2763, training acc = 0.91
Batch [400/704] training loss = 0.2963, training acc = 0.91
Batch [600/704] training loss = 0.3034, training acc = 0.91
Valid Test with nat
Test accuracy: 85.32% (4266/5000), Test loss:0.4414
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r92/init_pure/init_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 85.56% (8556/10000), Test loss:0.4441
Epoch [26/100], Passed time:[62.474/1624.316]
learning rate: 0.1
Batch [0/704] training loss = 0.3309, training acc = 0.88
Batch [200/704] training loss = 0.6028, training acc = 0.81
Batch [400/704] training loss = 0.4194, training acc = 0.83
Batch [600/704] training loss = 0.5941, training acc = 0.81
Valid Test with nat
Test accuracy: 85.18% (4259/5000), Test loss:0.4282
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r92/init_pure/init_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 85.06% (8506/10000), Test loss:0.4367
Epoch [27/100], Passed time:[62.521/1688.068]
learning rate: 0.1
Batch [0/704] training loss = 0.3809, training acc = 0.89
Batch [200/704] training loss = 0.2753, training acc = 0.91
Batch [400/704] training loss = 0.3361, training acc = 0.94
Batch [600/704] training loss = 0.4623, training acc = 0.86
Valid Test with nat
Test accuracy: 82.34% (4117/5000), Test loss:0.5683
Epoch [28/100], Passed time:[62.560/1751.680]
learning rate: 0.1
Batch [0/704] training loss = 0.3209, training acc = 0.91
Batch [200/704] training loss = 0.4495, training acc = 0.91
Batch [400/704] training loss = 0.1725, training acc = 0.95
Batch [600/704] training loss = 0.4267, training acc = 0.84
Valid Test with nat
Test accuracy: 85.52% (4276/5000), Test loss:0.4358
Epoch [29/100], Passed time:[62.570/1814.534]
learning rate: 0.1
Batch [0/704] training loss = 0.2588, training acc = 0.92
Batch [200/704] training loss = 0.2712, training acc = 0.91
Batch [400/704] training loss = 0.2129, training acc = 0.91
Batch [600/704] training loss = 0.3786, training acc = 0.89
Valid Test with nat
Test accuracy: 84.72% (4236/5000), Test loss:0.4919
Epoch [30/100], Passed time:[62.585/1877.560]
learning rate: 0.1
Batch [0/704] training loss = 0.2494, training acc = 0.91
Batch [200/704] training loss = 0.3229, training acc = 0.88
Batch [400/704] training loss = 0.5274, training acc = 0.80
Batch [600/704] training loss = 0.4873, training acc = 0.84
Valid Test with nat
Test accuracy: 80.64% (4032/5000), Test loss:0.6721
Epoch [31/100], Passed time:[62.575/1939.821]
learning rate: 0.1
Batch [0/704] training loss = 0.4058, training acc = 0.86
Batch [200/704] training loss = 0.3318, training acc = 0.84
Batch [400/704] training loss = 0.6162, training acc = 0.81
Batch [600/704] training loss = 0.2835, training acc = 0.88
Valid Test with nat
Test accuracy: 85.04% (4252/5000), Test loss:0.4389
Epoch [32/100], Passed time:[62.581/2002.591]
learning rate: 0.1
Batch [0/704] training loss = 0.2696, training acc = 0.91
Batch [200/704] training loss = 0.4634, training acc = 0.84
Batch [400/704] training loss = 0.2808, training acc = 0.89
Batch [600/704] training loss = 0.2388, training acc = 0.92
Valid Test with nat
Test accuracy: 84.56% (4228/5000), Test loss:0.4906
Epoch [33/100], Passed time:[62.609/2066.084]
learning rate: 0.1
Batch [0/704] training loss = 0.2740, training acc = 0.91
Batch [200/704] training loss = 0.3234, training acc = 0.92
Batch [400/704] training loss = 0.4178, training acc = 0.86
Batch [600/704] training loss = 0.5018, training acc = 0.86
Valid Test with nat
Test accuracy: 84.58% (4229/5000), Test loss:0.4911
Epoch [34/100], Passed time:[62.631/2129.437]
learning rate: 0.1
Batch [0/704] training loss = 0.3219, training acc = 0.89
Batch [200/704] training loss = 0.4251, training acc = 0.84
Batch [400/704] training loss = 0.5773, training acc = 0.86
Batch [600/704] training loss = 0.5137, training acc = 0.84
Valid Test with nat
Test accuracy: 85.22% (4261/5000), Test loss:0.4711
Epoch [35/100], Passed time:[62.620/2191.700]
learning rate: 0.1
Batch [0/704] training loss = 0.2103, training acc = 0.92
Batch [200/704] training loss = 0.2824, training acc = 0.88
Batch [400/704] training loss = 0.4472, training acc = 0.84
Batch [600/704] training loss = 0.5117, training acc = 0.81
Valid Test with nat
Test accuracy: 83.74% (4187/5000), Test loss:0.5354
Epoch [36/100], Passed time:[62.627/2254.566]
learning rate: 0.1
Batch [0/704] training loss = 0.5010, training acc = 0.84
Batch [200/704] training loss = 0.2145, training acc = 0.95
Batch [400/704] training loss = 0.4432, training acc = 0.89
Batch [600/704] training loss = 0.2954, training acc = 0.86
Valid Test with nat
Test accuracy: 84.56% (4228/5000), Test loss:0.4664
Epoch [37/100], Passed time:[62.767/2322.377]
learning rate: 0.1
Batch [0/704] training loss = 0.2406, training acc = 0.94
Batch [200/704] training loss = 0.5015, training acc = 0.84
Batch [400/704] training loss = 0.3488, training acc = 0.89
Batch [600/704] training loss = 0.3674, training acc = 0.88
Valid Test with nat
Test accuracy: 85.42% (4271/5000), Test loss:0.4600
Epoch [38/100], Passed time:[63.266/2404.116]
learning rate: 0.1
Batch [0/704] training loss = 0.3684, training acc = 0.81
Batch [200/704] training loss = 0.3165, training acc = 0.91
Batch [400/704] training loss = 0.2045, training acc = 0.94
Batch [600/704] training loss = 0.2764, training acc = 0.88
Valid Test with nat
Test accuracy: 85.42% (4271/5000), Test loss:0.4437
Epoch [39/100], Passed time:[63.661/2482.778]
learning rate: 0.1
Batch [0/704] training loss = 0.2434, training acc = 0.88
Batch [200/704] training loss = 0.3740, training acc = 0.88
Batch [400/704] training loss = 0.6117, training acc = 0.78
Batch [600/704] training loss = 0.4156, training acc = 0.86
Valid Test with nat
Test accuracy: 84.78% (4239/5000), Test loss:0.4622
Epoch [40/100], Passed time:[64.156/2566.251]
learning rate: 0.1
Batch [0/704] training loss = 0.2753, training acc = 0.91
Batch [200/704] training loss = 0.3845, training acc = 0.89
Batch [400/704] training loss = 0.4325, training acc = 0.86
Batch [600/704] training loss = 0.5818, training acc = 0.80
Valid Test with nat
Test accuracy: 83.88% (4194/5000), Test loss:0.4852
Epoch [41/100], Passed time:[64.545/2646.335]
learning rate: 0.1
Batch [0/704] training loss = 0.4642, training acc = 0.83
Batch [200/704] training loss = 0.2461, training acc = 0.92
Batch [400/704] training loss = 0.3148, training acc = 0.89
Batch [600/704] training loss = 0.4222, training acc = 0.88
Valid Test with nat
Test accuracy: 84.38% (4219/5000), Test loss:0.4859
Epoch [42/100], Passed time:[64.958/2728.247]
learning rate: 0.1
Batch [0/704] training loss = 0.3684, training acc = 0.89
Batch [200/704] training loss = 0.3150, training acc = 0.92
Batch [400/704] training loss = 0.3740, training acc = 0.88
Batch [600/704] training loss = 0.4858, training acc = 0.83
Valid Test with nat
Test accuracy: 84.68% (4234/5000), Test loss:0.4856
Epoch [43/100], Passed time:[65.384/2811.505]
learning rate: 0.1
Batch [0/704] training loss = 0.2341, training acc = 0.89
Batch [200/704] training loss = 0.2257, training acc = 0.92
Batch [400/704] training loss = 0.3442, training acc = 0.84
Batch [600/704] training loss = 0.4670, training acc = 0.86
Valid Test with nat
Test accuracy: 81.34% (4067/5000), Test loss:0.6136
Epoch [44/100], Passed time:[65.694/2890.544]
learning rate: 0.1
Batch [0/704] training loss = 0.4923, training acc = 0.83
Batch [200/704] training loss = 0.2845, training acc = 0.94
Batch [400/704] training loss = 0.3859, training acc = 0.84
Batch [600/704] training loss = 0.4894, training acc = 0.83
Valid Test with nat
Test accuracy: 83.78% (4189/5000), Test loss:0.5256
Epoch [45/100], Passed time:[66.042/2971.899]
learning rate: 0.1
Batch [0/704] training loss = 0.3045, training acc = 0.89
Batch [200/704] training loss = 0.5994, training acc = 0.81
Batch [400/704] training loss = 0.2084, training acc = 0.94
Batch [600/704] training loss = 0.3703, training acc = 0.86
Valid Test with nat
Test accuracy: 86.48% (4324/5000), Test loss:0.4348
Epoch [46/100], Passed time:[66.383/3053.615]
learning rate: 0.1
Batch [0/704] training loss = 0.3674, training acc = 0.84
Batch [200/704] training loss = 0.3890, training acc = 0.88
Batch [400/704] training loss = 0.5923, training acc = 0.80
Batch [600/704] training loss = 0.4766, training acc = 0.84
Valid Test with nat
Test accuracy: 84.64% (4232/5000), Test loss:0.4710
Epoch [47/100], Passed time:[66.728/3136.197]
learning rate: 0.1
Batch [0/704] training loss = 0.4954, training acc = 0.86
Batch [200/704] training loss = 0.3509, training acc = 0.84
Batch [400/704] training loss = 0.4647, training acc = 0.86
Batch [600/704] training loss = 0.3504, training acc = 0.88
Valid Test with nat
Test accuracy: 81.98% (4099/5000), Test loss:0.5601
Epoch [48/100], Passed time:[67.050/3218.396]
learning rate: 0.1
Batch [0/704] training loss = 0.1991, training acc = 0.94
Batch [200/704] training loss = 0.3222, training acc = 0.89
Batch [400/704] training loss = 0.4479, training acc = 0.84
Batch [600/704] training loss = 0.3547, training acc = 0.89
Valid Test with nat
Test accuracy: 85.80% (4290/5000), Test loss:0.4439
Epoch [49/100], Passed time:[67.348/3300.041]
learning rate: 0.1
Batch [0/704] training loss = 0.3511, training acc = 0.88
Batch [200/704] training loss = 0.3480, training acc = 0.88
Batch [400/704] training loss = 0.3675, training acc = 0.88
Batch [600/704] training loss = 0.4861, training acc = 0.89
Valid Test with nat
Test accuracy: 84.54% (4227/5000), Test loss:0.4846
Epoch [50/100], Passed time:[67.654/3382.687]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.3980, training acc = 0.86
Batch [200/704] training loss = 0.1842, training acc = 0.91
Batch [400/704] training loss = 0.2153, training acc = 0.92
Batch [600/704] training loss = 0.2654, training acc = 0.89
Valid Test with nat
Test accuracy: 89.42% (4471/5000), Test loss:0.3168
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r92/init_pure/init_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 89.94% (8994/10000), Test loss:0.3156
Epoch [51/100], Passed time:[68.019/3468.952]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.2878, training acc = 0.91
Batch [200/704] training loss = 0.1146, training acc = 0.97
Batch [400/704] training loss = 0.3646, training acc = 0.83
Batch [600/704] training loss = 0.1325, training acc = 0.97
Valid Test with nat
Test accuracy: 90.32% (4516/5000), Test loss:0.2999
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r92/init_pure/init_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 90.06% (9006/10000), Test loss:0.3116
Epoch [52/100], Passed time:[68.341/3553.744]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.2316, training acc = 0.92
Batch [200/704] training loss = 0.1869, training acc = 0.94
Batch [400/704] training loss = 0.0789, training acc = 0.98
Batch [600/704] training loss = 0.2559, training acc = 0.88
Valid Test with nat
Test accuracy: 89.82% (4491/5000), Test loss:0.3058
Epoch [53/100], Passed time:[68.534/3632.319]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0896, training acc = 0.98
Batch [200/704] training loss = 0.1897, training acc = 0.95
Batch [400/704] training loss = 0.3384, training acc = 0.94
Batch [600/704] training loss = 0.2454, training acc = 0.91
Valid Test with nat
Test accuracy: 90.08% (4504/5000), Test loss:0.3092
Epoch [54/100], Passed time:[68.712/3710.448]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.2118, training acc = 0.89
Batch [200/704] training loss = 0.2132, training acc = 0.91
Batch [400/704] training loss = 0.2045, training acc = 0.91
Batch [600/704] training loss = 0.1236, training acc = 0.95
Valid Test with nat
Test accuracy: 90.30% (4515/5000), Test loss:0.2995
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r92/init_pure/init_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 90.64% (9064/10000), Test loss:0.2969
Epoch [55/100], Passed time:[68.990/3794.452]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.1741, training acc = 0.95
Batch [200/704] training loss = 0.3826, training acc = 0.88
Batch [400/704] training loss = 0.2280, training acc = 0.94
Batch [600/704] training loss = 0.0670, training acc = 0.98
Valid Test with nat
Test accuracy: 90.30% (4515/5000), Test loss:0.2985
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r92/init_pure/init_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 90.29% (9029/10000), Test loss:0.3091
Epoch [56/100], Passed time:[69.288/3880.111]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.1476, training acc = 0.95
Batch [200/704] training loss = 0.0993, training acc = 0.95
Batch [400/704] training loss = 0.0676, training acc = 1.00
Batch [600/704] training loss = 0.2333, training acc = 0.92
Valid Test with nat
Test accuracy: 90.50% (4525/5000), Test loss:0.2950
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r92/init_pure/init_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 90.60% (9060/10000), Test loss:0.2980
Epoch [57/100], Passed time:[69.568/3965.359]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.1490, training acc = 0.95
Batch [200/704] training loss = 0.1679, training acc = 0.94
Batch [400/704] training loss = 0.1132, training acc = 0.95
Batch [600/704] training loss = 0.0745, training acc = 0.98
Valid Test with nat
Test accuracy: 90.02% (4501/5000), Test loss:0.3041
Epoch [58/100], Passed time:[69.720/4043.736]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.1383, training acc = 0.95
Batch [200/704] training loss = 0.1283, training acc = 0.94
Batch [400/704] training loss = 0.1765, training acc = 0.94
Batch [600/704] training loss = 0.1325, training acc = 0.95
Valid Test with nat
Test accuracy: 90.18% (4509/5000), Test loss:0.3071
Epoch [59/100], Passed time:[69.883/4123.104]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.1811, training acc = 0.92
Batch [200/704] training loss = 0.3171, training acc = 0.88
Batch [400/704] training loss = 0.1311, training acc = 0.97
Batch [600/704] training loss = 0.0856, training acc = 0.98
Valid Test with nat
Test accuracy: 90.58% (4529/5000), Test loss:0.2943
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r92/init_pure/init_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 90.30% (9030/10000), Test loss:0.3066
Epoch [60/100], Passed time:[70.117/4206.998]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.1778, training acc = 0.92
Batch [200/704] training loss = 0.0489, training acc = 0.98
Batch [400/704] training loss = 0.2111, training acc = 0.92
Batch [600/704] training loss = 0.0941, training acc = 0.98
Valid Test with nat
Test accuracy: 90.66% (4533/5000), Test loss:0.2997
Epoch [61/100], Passed time:[70.303/4288.463]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0670, training acc = 0.98
Batch [200/704] training loss = 0.1568, training acc = 0.95
Batch [400/704] training loss = 0.1281, training acc = 0.95
Batch [600/704] training loss = 0.3400, training acc = 0.88
Valid Test with nat
Test accuracy: 90.32% (4516/5000), Test loss:0.3123
Epoch [62/100], Passed time:[70.462/4368.643]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.1744, training acc = 0.95
Batch [200/704] training loss = 0.1704, training acc = 0.92
Batch [400/704] training loss = 0.1404, training acc = 0.92
Batch [600/704] training loss = 0.1759, training acc = 0.95
Valid Test with nat
Test accuracy: 90.58% (4529/5000), Test loss:0.3051
Epoch [63/100], Passed time:[70.631/4449.772]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.1218, training acc = 0.95
Batch [200/704] training loss = 0.0997, training acc = 0.98
Batch [400/704] training loss = 0.1235, training acc = 0.95
Batch [600/704] training loss = 0.2193, training acc = 0.94
Valid Test with nat
Test accuracy: 90.36% (4518/5000), Test loss:0.3074
Epoch [64/100], Passed time:[70.797/4530.985]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.1311, training acc = 0.95
Batch [200/704] training loss = 0.0541, training acc = 0.98
Batch [400/704] training loss = 0.0947, training acc = 0.97
Batch [600/704] training loss = 0.1579, training acc = 0.95
Valid Test with nat
Test accuracy: 90.28% (4514/5000), Test loss:0.3171
Epoch [65/100], Passed time:[70.970/4613.043]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.1209, training acc = 0.95
Batch [200/704] training loss = 0.2515, training acc = 0.89
Batch [400/704] training loss = 0.5115, training acc = 0.84
Batch [600/704] training loss = 0.1328, training acc = 0.95
Valid Test with nat
Test accuracy: 90.04% (4502/5000), Test loss:0.3165
Epoch [66/100], Passed time:[71.118/4693.775]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.1630, training acc = 0.95
Batch [200/704] training loss = 0.1500, training acc = 0.95
Batch [400/704] training loss = 0.1204, training acc = 0.98
Batch [600/704] training loss = 0.1616, training acc = 0.95
Valid Test with nat
Test accuracy: 90.48% (4524/5000), Test loss:0.3083
Epoch [67/100], Passed time:[71.259/4774.351]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.2651, training acc = 0.92
Batch [200/704] training loss = 0.0822, training acc = 0.97
Batch [400/704] training loss = 0.2342, training acc = 0.94
Batch [600/704] training loss = 0.1276, training acc = 0.98
Valid Test with nat
Test accuracy: 90.04% (4502/5000), Test loss:0.3247
Epoch [68/100], Passed time:[71.399/4855.150]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0535, training acc = 1.00
Batch [200/704] training loss = 0.1568, training acc = 0.92
Batch [400/704] training loss = 0.1441, training acc = 0.95
Batch [600/704] training loss = 0.1341, training acc = 0.95
Valid Test with nat
Test accuracy: 90.08% (4504/5000), Test loss:0.3240
Epoch [69/100], Passed time:[71.515/4934.568]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.2303, training acc = 0.94
Batch [200/704] training loss = 0.1742, training acc = 0.94
Batch [400/704] training loss = 0.1270, training acc = 0.95
Batch [600/704] training loss = 0.1070, training acc = 0.95
Valid Test with nat
Test accuracy: 89.84% (4492/5000), Test loss:0.3213
Epoch [70/100], Passed time:[71.648/5015.369]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.1534, training acc = 0.94
Batch [200/704] training loss = 0.0623, training acc = 1.00
Batch [400/704] training loss = 0.1395, training acc = 0.92
Batch [600/704] training loss = 0.1833, training acc = 0.92
Valid Test with nat
Test accuracy: 90.28% (4514/5000), Test loss:0.3250
Epoch [71/100], Passed time:[71.751/5094.327]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0768, training acc = 0.98
Batch [200/704] training loss = 0.1748, training acc = 0.94
Batch [400/704] training loss = 0.1664, training acc = 0.94
Batch [600/704] training loss = 0.1882, training acc = 0.94
Valid Test with nat
Test accuracy: 90.70% (4535/5000), Test loss:0.3144
Epoch [72/100], Passed time:[71.861/5173.978]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0351, training acc = 1.00
Batch [200/704] training loss = 0.1318, training acc = 0.94
Batch [400/704] training loss = 0.0653, training acc = 0.97
Batch [600/704] training loss = 0.1387, training acc = 0.92
Valid Test with nat
Test accuracy: 90.42% (4521/5000), Test loss:0.3175
Epoch [73/100], Passed time:[72.026/5257.866]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.1261, training acc = 0.95
Batch [200/704] training loss = 0.1346, training acc = 0.94
Batch [400/704] training loss = 0.1353, training acc = 0.95
Batch [600/704] training loss = 0.1575, training acc = 0.92
Valid Test with nat
Test accuracy: 90.26% (4513/5000), Test loss:0.3095
Epoch [74/100], Passed time:[72.161/5339.917]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.2537, training acc = 0.91
Batch [200/704] training loss = 0.0884, training acc = 0.98
Batch [400/704] training loss = 0.1803, training acc = 0.95
Batch [600/704] training loss = 0.0972, training acc = 0.97
Valid Test with nat
Test accuracy: 90.50% (4525/5000), Test loss:0.3264
Epoch [75/100], Passed time:[72.272/5420.382]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.3074, training acc = 0.89
Batch [200/704] training loss = 0.1012, training acc = 0.97
Batch [400/704] training loss = 0.1355, training acc = 0.94
Batch [600/704] training loss = 0.3306, training acc = 0.92
Valid Test with nat
Test accuracy: 90.68% (4534/5000), Test loss:0.3159
Epoch [76/100], Passed time:[72.414/5503.433]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.1348, training acc = 0.95
Batch [200/704] training loss = 0.0894, training acc = 0.97
Batch [400/704] training loss = 0.1755, training acc = 0.92
Batch [600/704] training loss = 0.0807, training acc = 0.97
Valid Test with nat
Test accuracy: 90.46% (4523/5000), Test loss:0.3160
Epoch [77/100], Passed time:[72.549/5586.276]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.1319, training acc = 0.97
Batch [200/704] training loss = 0.1195, training acc = 0.95
Batch [400/704] training loss = 0.0762, training acc = 0.98
Batch [600/704] training loss = 0.0400, training acc = 0.98
Valid Test with nat
Test accuracy: 90.68% (4534/5000), Test loss:0.3175
Epoch [78/100], Passed time:[72.658/5667.297]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.1150, training acc = 0.98
Batch [200/704] training loss = 0.0504, training acc = 0.98
Batch [400/704] training loss = 0.2712, training acc = 0.91
Batch [600/704] training loss = 0.0692, training acc = 0.98
Valid Test with nat
Test accuracy: 90.68% (4534/5000), Test loss:0.3101
Epoch [79/100], Passed time:[72.768/5748.706]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.1292, training acc = 0.94
Batch [200/704] training loss = 0.1044, training acc = 0.97
Batch [400/704] training loss = 0.1789, training acc = 0.91
Batch [600/704] training loss = 0.0527, training acc = 0.97
Valid Test with nat
Test accuracy: 90.70% (4535/5000), Test loss:0.3066
Epoch [80/100], Passed time:[72.869/5829.491]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.1462, training acc = 0.94
Batch [200/704] training loss = 0.1134, training acc = 0.95
Batch [400/704] training loss = 0.0249, training acc = 1.00
Batch [600/704] training loss = 0.0757, training acc = 0.95
Valid Test with nat
Test accuracy: 91.00% (4550/5000), Test loss:0.3109
Epoch [81/100], Passed time:[72.977/5911.124]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0445, training acc = 1.00
Batch [200/704] training loss = 0.0683, training acc = 0.97
Batch [400/704] training loss = 0.1240, training acc = 0.97
Batch [600/704] training loss = 0.0723, training acc = 0.98
Valid Test with nat
Test accuracy: 90.90% (4545/5000), Test loss:0.3235
Epoch [82/100], Passed time:[73.092/5993.517]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0822, training acc = 0.95
Batch [200/704] training loss = 0.1494, training acc = 0.97
Batch [400/704] training loss = 0.1616, training acc = 0.97
Batch [600/704] training loss = 0.2055, training acc = 0.91
Valid Test with nat
Test accuracy: 90.90% (4545/5000), Test loss:0.3057
Epoch [83/100], Passed time:[73.175/6073.549]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.1756, training acc = 0.92
Batch [200/704] training loss = 0.1516, training acc = 0.95
Batch [400/704] training loss = 0.1583, training acc = 0.94
Batch [600/704] training loss = 0.0449, training acc = 1.00
Valid Test with nat
Test accuracy: 90.98% (4549/5000), Test loss:0.3127
Epoch [84/100], Passed time:[73.267/6154.429]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.1575, training acc = 0.95
Batch [200/704] training loss = 0.1737, training acc = 0.94
Batch [400/704] training loss = 0.0647, training acc = 0.98
Batch [600/704] training loss = 0.1224, training acc = 0.95
Valid Test with nat
Test accuracy: 90.94% (4547/5000), Test loss:0.3126
Epoch [85/100], Passed time:[73.338/6233.699]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.1307, training acc = 0.95
Batch [200/704] training loss = 0.0901, training acc = 0.97
Batch [400/704] training loss = 0.2081, training acc = 0.97
Batch [600/704] training loss = 0.0694, training acc = 1.00
Valid Test with nat
Test accuracy: 90.96% (4548/5000), Test loss:0.3293
Epoch [86/100], Passed time:[73.422/6314.306]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.1507, training acc = 0.97
Batch [200/704] training loss = 0.0834, training acc = 0.98
Batch [400/704] training loss = 0.0491, training acc = 0.98
Batch [600/704] training loss = 0.1949, training acc = 0.92
Valid Test with nat
Test accuracy: 90.78% (4539/5000), Test loss:0.3151
Epoch [87/100], Passed time:[73.524/6396.631]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.1803, training acc = 0.89
Batch [200/704] training loss = 0.1158, training acc = 0.97
Batch [400/704] training loss = 0.1287, training acc = 0.95
Batch [600/704] training loss = 0.0377, training acc = 1.00
Valid Test with nat
Test accuracy: 90.82% (4541/5000), Test loss:0.3174
Epoch [88/100], Passed time:[73.595/6476.334]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.1364, training acc = 0.92
Batch [200/704] training loss = 0.0729, training acc = 0.98
Batch [400/704] training loss = 0.0522, training acc = 0.98
Batch [600/704] training loss = 0.0467, training acc = 0.98
Valid Test with nat
Test accuracy: 91.00% (4550/5000), Test loss:0.3109
Epoch [89/100], Passed time:[73.672/6556.780]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.1300, training acc = 0.95
Batch [200/704] training loss = 0.1047, training acc = 0.94
Batch [400/704] training loss = 0.1784, training acc = 0.92
Batch [600/704] training loss = 0.0660, training acc = 0.98
Valid Test with nat
Test accuracy: 90.72% (4536/5000), Test loss:0.3257
Epoch [90/100], Passed time:[73.739/6636.539]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.1425, training acc = 0.97
Batch [200/704] training loss = 0.1924, training acc = 0.94
Batch [400/704] training loss = 0.0785, training acc = 0.95
Batch [600/704] training loss = 0.1485, training acc = 0.97
Valid Test with nat
Test accuracy: 90.94% (4547/5000), Test loss:0.3137
Epoch [91/100], Passed time:[73.815/6717.185]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0293, training acc = 1.00
Batch [200/704] training loss = 0.0925, training acc = 0.97
Batch [400/704] training loss = 0.2307, training acc = 0.92
Batch [600/704] training loss = 0.0707, training acc = 0.97
Valid Test with nat
Test accuracy: 91.20% (4560/5000), Test loss:0.3147
Epoch [92/100], Passed time:[73.896/6798.475]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.1028, training acc = 0.97
Batch [200/704] training loss = 0.0978, training acc = 0.95
Batch [400/704] training loss = 0.0381, training acc = 1.00
Batch [600/704] training loss = 0.0936, training acc = 0.98
Valid Test with nat
Test accuracy: 91.06% (4553/5000), Test loss:0.3191
Epoch [93/100], Passed time:[74.006/6882.565]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.1409, training acc = 0.94
Batch [200/704] training loss = 0.1280, training acc = 0.94
Batch [400/704] training loss = 0.1065, training acc = 0.95
Batch [600/704] training loss = 0.1419, training acc = 0.94
Valid Test with nat
Test accuracy: 90.98% (4549/5000), Test loss:0.3142
Epoch [94/100], Passed time:[74.089/6964.379]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.1209, training acc = 0.92
Batch [200/704] training loss = 0.1684, training acc = 0.97
Batch [400/704] training loss = 0.1074, training acc = 0.95
Batch [600/704] training loss = 0.0713, training acc = 0.97
Valid Test with nat
Test accuracy: 90.88% (4544/5000), Test loss:0.3218
Epoch [95/100], Passed time:[74.156/7044.774]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.1233, training acc = 0.95
Batch [200/704] training loss = 0.0405, training acc = 1.00
Batch [400/704] training loss = 0.1667, training acc = 0.94
Batch [600/704] training loss = 0.0963, training acc = 0.97
Valid Test with nat
Test accuracy: 90.92% (4546/5000), Test loss:0.3208
Epoch [96/100], Passed time:[74.222/7125.330]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0415, training acc = 0.98
Batch [200/704] training loss = 0.1035, training acc = 0.95
Batch [400/704] training loss = 0.0844, training acc = 0.98
Batch [600/704] training loss = 0.0686, training acc = 0.98
Valid Test with nat
Test accuracy: 91.06% (4553/5000), Test loss:0.3157
Epoch [97/100], Passed time:[74.275/7204.631]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0564, training acc = 0.98
Batch [200/704] training loss = 0.0351, training acc = 0.98
Batch [400/704] training loss = 0.1169, training acc = 0.97
Batch [600/704] training loss = 0.0375, training acc = 0.98
Valid Test with nat
Test accuracy: 91.26% (4563/5000), Test loss:0.3278
Epoch [98/100], Passed time:[74.361/7287.374]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.0864, training acc = 0.95
Batch [200/704] training loss = 0.2644, training acc = 0.94
Batch [400/704] training loss = 0.0610, training acc = 0.95
Batch [600/704] training loss = 0.0376, training acc = 0.98
Valid Test with nat
Test accuracy: 91.16% (4558/5000), Test loss:0.3177
Epoch [99/100], Passed time:[74.422/7367.777]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.1404, training acc = 0.94
Batch [200/704] training loss = 0.0400, training acc = 0.98
Batch [400/704] training loss = 0.2249, training acc = 0.91
Batch [600/704] training loss = 0.0341, training acc = 1.00
Valid Test with nat
Test accuracy: 91.02% (4551/5000), Test loss:0.3167
Training done, model saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r92/init_pure/init_enhance_m0.01_warmup0.1.pth
Test on test set:
Test accuracy: 91.04% (9104/10000), Test loss:0.3210
