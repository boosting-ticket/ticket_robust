model_type : vgg16
init_type : pure
finetune_method : nat
enhance_method : nat
gpu : 6
model_name : init_enhance20_m0.005_warmup0.1
model_width : 8
n_pruning_steps : 1
max_pruning_ratio : 80
train_epochs : 20
enhance_epochs : 20
prune_method : unstructured
dataset : cifar
noise_sd : 1.0
trades_beta : 6.0
seed : 7
warmup : True
parallel : False
create_init : False
init_step : 1400
train_method : nat
early_stop : 100
norm : True
optm : sgd
batch_size : 64
test_batch_size : 100
learning_rate : 0.1
enhance_learning_rate : 0.1
schedule_length : 10
weight_decay : 0.0001
epsilon : 0.03137254901960784
attack_iter : 10
eps_step : 0.00784313725490196
targeted : False
clip_min : 0
clip_max : 1.0
starting_epsilon : 1e-05
interval_weight : 0.1
ft_interval_weight : 50
verbose : 200
resume : 0
model_path : ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance20_m0.005_warmup0.1.pth
last_model_path : ./trained_models_new/
mask_path : ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/pruned_lr0.005_mask_r80.npy
mask_name : pruned_lr0.005_mask_r80
log_path : ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance20_m0.005_warmup0.1.log
init_path : ./trained_models_new/cifar/vgg16/init/pure_vgg16_init.pth
results_path : None
n_classes : 10
eval : False
init : True
transfer : False
CUDA enabled.
Enhance training config:
Enhance training method: nat
model will be saved in: ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance20_m0.005_warmup0.1.pth
Init model is: ./trained_models_new/cifar/vgg16/init/pure_vgg16_init.pth
Init mask used from: ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/pruned_lr0.005_mask_r80.npy
Log will be saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance20_m0.005_warmup0.1.log
Random seed is: 7

model loading from ./trained_models_new/cifar/vgg16/init/pure_vgg16_init.pth
Epoch [0/20]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 2.2123, training acc = 0.28
Batch [200/704] training loss = 0.9874, training acc = 0.67
Batch [400/704] training loss = 0.8101, training acc = 0.69
Batch [600/704] training loss = 0.5278, training acc = 0.80
Valid Test with nat
Test accuracy: 79.60% (3980/5000), Test loss:0.6169
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance20_m0.005_warmup0.1.pth
Test on test set:
Test accuracy: 78.31% (7831/10000), Test loss:0.6531
Epoch [1/20], Passed time:[89.219/89.219]
learning rate: 0.020000000000000004
Batch [0/704] training loss = 0.4679, training acc = 0.86
Batch [200/704] training loss = 0.5665, training acc = 0.77
Batch [400/704] training loss = 0.5289, training acc = 0.81
Batch [600/704] training loss = 0.5871, training acc = 0.81
Valid Test with nat
Test accuracy: 78.36% (3918/5000), Test loss:0.6647
Epoch [2/20], Passed time:[92.598/185.197]
learning rate: 0.030000000000000006
Batch [0/704] training loss = 0.4940, training acc = 0.83
Batch [200/704] training loss = 0.5166, training acc = 0.81
Batch [400/704] training loss = 0.4274, training acc = 0.88
Batch [600/704] training loss = 0.4785, training acc = 0.84
Valid Test with nat
Test accuracy: 81.74% (4087/5000), Test loss:0.5505
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance20_m0.005_warmup0.1.pth
Test on test set:
Test accuracy: 81.34% (8134/10000), Test loss:0.5743
Epoch [3/20], Passed time:[95.059/285.177]
learning rate: 0.04000000000000001
Batch [0/704] training loss = 0.4527, training acc = 0.83
Batch [200/704] training loss = 0.4976, training acc = 0.81
Batch [400/704] training loss = 0.6565, training acc = 0.80
Batch [600/704] training loss = 0.6046, training acc = 0.83
Valid Test with nat
Test accuracy: 83.10% (4155/5000), Test loss:0.5136
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance20_m0.005_warmup0.1.pth
Test on test set:
Test accuracy: 83.56% (8356/10000), Test loss:0.4943
Epoch [4/20], Passed time:[93.500/374.000]
learning rate: 0.05
Batch [0/704] training loss = 0.2605, training acc = 0.91
Batch [200/704] training loss = 0.4614, training acc = 0.86
Batch [400/704] training loss = 0.6591, training acc = 0.72
Batch [600/704] training loss = 0.4978, training acc = 0.86
Valid Test with nat
Test accuracy: 81.70% (4085/5000), Test loss:0.5478
Epoch [5/20], Passed time:[90.786/453.931]
learning rate: 0.06000000000000001
Batch [0/704] training loss = 0.2957, training acc = 0.91
Batch [200/704] training loss = 0.5756, training acc = 0.80
Batch [400/704] training loss = 0.4317, training acc = 0.83
Batch [600/704] training loss = 0.4042, training acc = 0.84
Valid Test with nat
Test accuracy: 78.16% (3908/5000), Test loss:0.6705
Epoch [6/20], Passed time:[88.996/533.978]
learning rate: 0.07
Batch [0/704] training loss = 0.3307, training acc = 0.88
Batch [200/704] training loss = 0.2891, training acc = 0.92
Batch [400/704] training loss = 0.4058, training acc = 0.83
Batch [600/704] training loss = 0.4143, training acc = 0.88
Valid Test with nat
Test accuracy: 82.42% (4121/5000), Test loss:0.5365
Epoch [7/20], Passed time:[87.608/613.256]
learning rate: 0.08000000000000002
Batch [0/704] training loss = 0.3561, training acc = 0.89
Batch [200/704] training loss = 0.4689, training acc = 0.81
Batch [400/704] training loss = 0.5344, training acc = 0.84
Batch [600/704] training loss = 0.2842, training acc = 0.91
Valid Test with nat
Test accuracy: 81.00% (4050/5000), Test loss:0.5713
Epoch [8/20], Passed time:[86.613/692.901]
learning rate: 0.09000000000000001
Batch [0/704] training loss = 0.6344, training acc = 0.80
Batch [200/704] training loss = 0.3278, training acc = 0.92
Batch [400/704] training loss = 0.5659, training acc = 0.81
Batch [600/704] training loss = 0.5620, training acc = 0.80
Valid Test with nat
Test accuracy: 80.52% (4026/5000), Test loss:0.6012
Epoch [9/20], Passed time:[85.507/769.563]
learning rate: 0.1
Batch [0/704] training loss = 0.5551, training acc = 0.83
Batch [200/704] training loss = 0.3798, training acc = 0.89
Batch [400/704] training loss = 0.2711, training acc = 0.92
Batch [600/704] training loss = 0.4655, training acc = 0.83
Valid Test with nat
Test accuracy: 78.64% (3932/5000), Test loss:0.6921
Epoch [10/20], Passed time:[84.748/847.480]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.5990, training acc = 0.83
Batch [200/704] training loss = 0.1885, training acc = 0.94
Batch [400/704] training loss = 0.2573, training acc = 0.88
Batch [600/704] training loss = 0.1679, training acc = 0.95
Valid Test with nat
Test accuracy: 89.72% (4486/5000), Test loss:0.3139
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance20_m0.005_warmup0.1.pth
Test on test set:
Test accuracy: 89.55% (8955/10000), Test loss:0.3224
Epoch [11/20], Passed time:[85.939/945.328]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.2056, training acc = 0.94
Batch [200/704] training loss = 0.2077, training acc = 0.94
Batch [400/704] training loss = 0.1391, training acc = 0.97
Batch [600/704] training loss = 0.1761, training acc = 0.97
Valid Test with nat
Test accuracy: 89.84% (4492/5000), Test loss:0.3131
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance20_m0.005_warmup0.1.pth
Test on test set:
Test accuracy: 89.85% (8985/10000), Test loss:0.3181
Epoch [12/20], Passed time:[87.071/1044.849]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.3000, training acc = 0.94
Batch [200/704] training loss = 0.2177, training acc = 0.95
Batch [400/704] training loss = 0.1496, training acc = 0.97
Batch [600/704] training loss = 0.1188, training acc = 0.95
Valid Test with nat
Test accuracy: 90.12% (4506/5000), Test loss:0.3023
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance20_m0.005_warmup0.1.pth
Test on test set:
Test accuracy: 90.19% (9019/10000), Test loss:0.3062
Epoch [13/20], Passed time:[88.594/1151.720]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.3344, training acc = 0.89
Batch [200/704] training loss = 0.2117, training acc = 0.92
Batch [400/704] training loss = 0.1463, training acc = 0.94
Batch [600/704] training loss = 0.1420, training acc = 0.97
Valid Test with nat
Test accuracy: 90.08% (4504/5000), Test loss:0.3119
Epoch [14/20], Passed time:[89.190/1248.663]
learning rate: 0.010000000000000002
Batch [0/704] training loss = 0.0951, training acc = 0.97
Batch [200/704] training loss = 0.2288, training acc = 0.92
Batch [400/704] training loss = 0.3284, training acc = 0.89
Batch [600/704] training loss = 0.1650, training acc = 0.94
Valid Test with nat
Test accuracy: 90.44% (4522/5000), Test loss:0.3083
Epoch [15/20], Passed time:[89.269/1339.034]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.1322, training acc = 0.98
Batch [200/704] training loss = 0.1194, training acc = 0.94
Batch [400/704] training loss = 0.3465, training acc = 0.92
Batch [600/704] training loss = 0.1061, training acc = 0.97
Valid Test with nat
Test accuracy: 90.66% (4533/5000), Test loss:0.2930
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance20_m0.005_warmup0.1.pth
Test on test set:
Test accuracy: 90.70% (9070/10000), Test loss:0.2892
Epoch [16/20], Passed time:[90.206/1443.294]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.1363, training acc = 0.92
Batch [200/704] training loss = 0.1618, training acc = 0.94
Batch [400/704] training loss = 0.2249, training acc = 0.91
Batch [600/704] training loss = 0.1537, training acc = 0.97
Valid Test with nat
Test accuracy: 90.58% (4529/5000), Test loss:0.2990
Epoch [17/20], Passed time:[90.293/1534.974]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.1201, training acc = 0.97
Batch [200/704] training loss = 0.1668, training acc = 0.95
Batch [400/704] training loss = 0.1170, training acc = 0.97
Batch [600/704] training loss = 0.1389, training acc = 0.97
Valid Test with nat
Test accuracy: 91.00% (4550/5000), Test loss:0.2889
Best model so far saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance20_m0.005_warmup0.1.pth
Test on test set:
Test accuracy: 90.73% (9073/10000), Test loss:0.2883
Epoch [18/20], Passed time:[90.183/1623.290]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.2168, training acc = 0.94
Batch [200/704] training loss = 0.1217, training acc = 0.98
Batch [400/704] training loss = 0.0654, training acc = 0.97
Batch [600/704] training loss = 0.1694, training acc = 0.98
Valid Test with nat
Test accuracy: 90.94% (4547/5000), Test loss:0.2919
Epoch [19/20], Passed time:[89.782/1705.862]
learning rate: 0.0010000000000000002
Batch [0/704] training loss = 0.2116, training acc = 0.92
Batch [200/704] training loss = 0.3014, training acc = 0.89
Batch [400/704] training loss = 0.1995, training acc = 0.92
Batch [600/704] training loss = 0.1457, training acc = 0.95
Valid Test with nat
Test accuracy: 91.04% (4552/5000), Test loss:0.2996
Training done, model saved in ./trained_models_new/cifar/vgg16/nat/pruned1_epoch100_r80/init_pure/init_enhance20_m0.005_warmup0.1.pth
Test on test set:
Test accuracy: 91.06% (9106/10000), Test loss:0.2845
