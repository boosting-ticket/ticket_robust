norm : True
train_epochs : 100
results_path : None
batch_size : 128
attack_iter : 10
finetune_method : nat
log_path : ./trained_models_new/cifar/wideresnet_34_2/nat/pruned1_epoch100_r80/init_pure/init_enhance_m0.05_warmup0.1.log
parallel : False
test_batch_size : 100
dataset : cifar
enhance_learning_rate : 0.1
prune_method : unstructured
transfer : False
model_path : ./trained_models_new/cifar/wideresnet_34_2/nat/pruned1_epoch100_r80/init_pure/init_enhance_m0.05_warmup0.1.pth
gpu : 2
n_pruning_steps : 1
enhance_epochs : None
eval : False
init_path : ./trained_models_new/cifar/wideresnet_34_2/init/pure_wideresnet_34_2_init.pth
weight_decay : 0.0001
clip_min : 0
resume : 0
optm : sgd
verbose : 200
learning_rate : 0.1
model_name : init_enhance_m0.05_warmup0.1
n_classes : 10
last_model_path : ./trained_models_new/
train_method : nat
model_width : 8
starting_epsilon : 1e-05
init_step : 1400
mask_path : ./trained_models_new/cifar/wideresnet_34_2/nat/pruned1_epoch100_r80/init_pure/pruned_lr0.05_mask_r80.npy
seed : 7
warmup : True
targeted : False
ft_interval_weight : 50
early_stop : 50
enhance_method : nat
trades_beta : 6.0
model_type : wideresnet_34_2
mask_name : pruned_lr0.05_mask_r80
schedule_length : 10
clip_max : 1.0
create_init : False
epsilon : 0.03137254901960784
eps_step : 0.00784313725490196
interval_weight : 0.1
noise_sd : 1.0
init : True
max_pruning_ratio : 80
init_type : pure
CUDA enabled.
Enhance training config:
Enhance training method: nat
model will be saved in: ./trained_models_new/cifar/wideresnet_34_2/nat/pruned1_epoch100_r80/init_pure/init_enhance_m0.05_warmup0.1.pth
Init model is: ./trained_models_new/cifar/wideresnet_34_2/init/pure_wideresnet_34_2_init.pth
Init mask used from: ./trained_models_new/cifar/wideresnet_34_2/nat/pruned1_epoch100_r80/init_pure/pruned_lr0.05_mask_r80.npy
Log will be saved in ./trained_models_new/cifar/wideresnet_34_2/nat/pruned1_epoch100_r80/init_pure/init_enhance_m0.05_warmup0.1.log
Random seed is: 7

model loading from ./trained_models_new/cifar/wideresnet_34_2/init/pure_wideresnet_34_2_init.pth
Epoch [0/100]
learning rate: 0.05
Batch [0/352] training loss = 2.2565, training acc = 0.19
Batch [200/352] training loss = 0.8185, training acc = 0.73
Valid Test with nat
Test accuracy: 72.94% (3647/5000), Test loss:0.8332
Best model so far saved in ./trained_models_new/cifar/wideresnet_34_2/nat/pruned1_epoch100_r80/init_pure/init_enhance_m0.05_warmup0.1.pth
Test on test set:
Test accuracy: 73.26% (7326/10000), Test loss:0.7864
Epoch [1/100], Passed time:[24.078/24.078]
learning rate: 0.055
Batch [0/352] training loss = 0.6286, training acc = 0.79
Batch [200/352] training loss = 0.6071, training acc = 0.80
Valid Test with nat
Test accuracy: 75.82% (3791/5000), Test loss:0.7957
Best model so far saved in ./trained_models_new/cifar/wideresnet_34_2/nat/pruned1_epoch100_r80/init_pure/init_enhance_m0.05_warmup0.1.pth
Test on test set:
Test accuracy: 77.73% (7773/10000), Test loss:0.7082
Epoch [2/100], Passed time:[23.951/47.902]
learning rate: 0.060000000000000005
Batch [0/352] training loss = 0.4694, training acc = 0.84
Batch [200/352] training loss = 0.4772, training acc = 0.84
Valid Test with nat
Test accuracy: 81.76% (4088/5000), Test loss:0.5938
Best model so far saved in ./trained_models_new/cifar/wideresnet_34_2/nat/pruned1_epoch100_r80/init_pure/init_enhance_m0.05_warmup0.1.pth
Test on test set:
Test accuracy: 82.46% (8246/10000), Test loss:0.5648
Epoch [3/100], Passed time:[24.037/72.110]
learning rate: 0.065
Batch [0/352] training loss = 0.3580, training acc = 0.88
Batch [200/352] training loss = 0.5399, training acc = 0.83
Valid Test with nat
Test accuracy: 83.56% (4178/5000), Test loss:0.5246
Best model so far saved in ./trained_models_new/cifar/wideresnet_34_2/nat/pruned1_epoch100_r80/init_pure/init_enhance_m0.05_warmup0.1.pth
Test on test set:
Test accuracy: 84.80% (8480/10000), Test loss:0.4725
Epoch [4/100], Passed time:[24.085/96.339]
learning rate: 0.07
Batch [0/352] training loss = 0.4010, training acc = 0.88
Batch [200/352] training loss = 0.1925, training acc = 0.94
Valid Test with nat
Test accuracy: 83.86% (4193/5000), Test loss:0.5324
Epoch [5/100], Passed time:[23.841/119.203]
learning rate: 0.07500000000000001
Batch [0/352] training loss = 0.3277, training acc = 0.89
Batch [200/352] training loss = 0.3782, training acc = 0.84
Valid Test with nat
Test accuracy: 80.84% (4042/5000), Test loss:0.6343
Epoch [6/100], Passed time:[23.520/141.118]
learning rate: 0.08000000000000002
Batch [0/352] training loss = 0.1987, training acc = 0.93
Batch [200/352] training loss = 0.2770, training acc = 0.88
Valid Test with nat
Test accuracy: 82.04% (4102/5000), Test loss:0.6219
Epoch [7/100], Passed time:[23.329/163.305]
learning rate: 0.085
Batch [0/352] training loss = 0.3916, training acc = 0.84
Batch [200/352] training loss = 0.2274, training acc = 0.93
Valid Test with nat
Test accuracy: 86.58% (4329/5000), Test loss:0.4410
Best model so far saved in ./trained_models_new/cifar/wideresnet_34_2/nat/pruned1_epoch100_r80/init_pure/init_enhance_m0.05_warmup0.1.pth
Test on test set:
Test accuracy: 85.72% (8572/10000), Test loss:0.4612
Epoch [8/100], Passed time:[23.446/187.570]
learning rate: 0.09
Batch [0/352] training loss = 0.3055, training acc = 0.90
Batch [200/352] training loss = 0.3821, training acc = 0.89
Valid Test with nat
Test accuracy: 85.92% (4296/5000), Test loss:0.4841
Epoch [9/100], Passed time:[23.322/209.894]
learning rate: 0.095
Batch [0/352] training loss = 0.1779, training acc = 0.95
Batch [200/352] training loss = 0.3299, training acc = 0.88
Valid Test with nat
Test accuracy: 85.48% (4274/5000), Test loss:0.4899
Epoch [10/100], Passed time:[23.217/232.169]
learning rate: 0.1
Batch [0/352] training loss = 0.2103, training acc = 0.94
Batch [200/352] training loss = 0.3357, training acc = 0.91
Valid Test with nat
Test accuracy: 86.28% (4314/5000), Test loss:0.4510
Epoch [11/100], Passed time:[23.142/254.564]
learning rate: 0.1
Batch [0/352] training loss = 0.2195, training acc = 0.93
Batch [200/352] training loss = 0.2488, training acc = 0.90
Valid Test with nat
Test accuracy: 85.18% (4259/5000), Test loss:0.4970
Epoch [12/100], Passed time:[23.097/277.159]
learning rate: 0.1
Batch [0/352] training loss = 0.2760, training acc = 0.88
Batch [200/352] training loss = 0.2422, training acc = 0.91
Valid Test with nat
Test accuracy: 87.08% (4354/5000), Test loss:0.4190
Best model so far saved in ./trained_models_new/cifar/wideresnet_34_2/nat/pruned1_epoch100_r80/init_pure/init_enhance_m0.05_warmup0.1.pth
Test on test set:
Test accuracy: 86.12% (8612/10000), Test loss:0.4784
Epoch [13/100], Passed time:[23.129/300.680]
learning rate: 0.1
Batch [0/352] training loss = 0.2865, training acc = 0.88
Batch [200/352] training loss = 0.3001, training acc = 0.91
Valid Test with nat
Test accuracy: 84.40% (4220/5000), Test loss:0.5366
Epoch [14/100], Passed time:[23.085/323.193]
learning rate: 0.1
Batch [0/352] training loss = 0.1699, training acc = 0.91
Batch [200/352] training loss = 0.1942, training acc = 0.93
Valid Test with nat
Test accuracy: 87.02% (4351/5000), Test loss:0.4346
Epoch [15/100], Passed time:[23.045/345.671]
learning rate: 0.1
Batch [0/352] training loss = 0.2255, training acc = 0.91
Batch [200/352] training loss = 0.2569, training acc = 0.91
Valid Test with nat
Test accuracy: 87.46% (4373/5000), Test loss:0.4397
Epoch [16/100], Passed time:[22.998/367.961]
learning rate: 0.1
Batch [0/352] training loss = 0.3139, training acc = 0.88
Batch [200/352] training loss = 0.1400, training acc = 0.95
Valid Test with nat
Test accuracy: 86.28% (4314/5000), Test loss:0.4627
Epoch [17/100], Passed time:[22.948/390.109]
learning rate: 0.1
Batch [0/352] training loss = 0.2014, training acc = 0.95
Batch [200/352] training loss = 0.1617, training acc = 0.93
Valid Test with nat
Test accuracy: 89.56% (4478/5000), Test loss:0.3776
Best model so far saved in ./trained_models_new/cifar/wideresnet_34_2/nat/pruned1_epoch100_r80/init_pure/init_enhance_m0.05_warmup0.1.pth
Test on test set:
Test accuracy: 88.53% (8853/10000), Test loss:0.3821
Epoch [18/100], Passed time:[22.995/413.911]
learning rate: 0.1
Batch [0/352] training loss = 0.1682, training acc = 0.91
Batch [200/352] training loss = 0.1744, training acc = 0.94
Valid Test with nat
Test accuracy: 84.96% (4248/5000), Test loss:0.5749
Epoch [19/100], Passed time:[22.986/436.734]
learning rate: 0.1
Batch [0/352] training loss = 0.1214, training acc = 0.96
Batch [200/352] training loss = 0.2595, training acc = 0.92
Valid Test with nat
Test accuracy: 87.42% (4371/5000), Test loss:0.4217
Epoch [20/100], Passed time:[22.945/458.898]
learning rate: 0.1
Batch [0/352] training loss = 0.2762, training acc = 0.91
Batch [200/352] training loss = 0.2297, training acc = 0.93
Valid Test with nat
Test accuracy: 86.20% (4310/5000), Test loss:0.4771
Epoch [21/100], Passed time:[22.935/481.635]
learning rate: 0.1
Batch [0/352] training loss = 0.1743, training acc = 0.93
Batch [200/352] training loss = 0.2289, training acc = 0.93
Valid Test with nat
Test accuracy: 88.34% (4417/5000), Test loss:0.3804
Epoch [22/100], Passed time:[22.934/504.538]
learning rate: 0.1
Batch [0/352] training loss = 0.1775, training acc = 0.95
Batch [200/352] training loss = 0.2801, training acc = 0.88
Valid Test with nat
Test accuracy: 88.38% (4419/5000), Test loss:0.4154
Epoch [23/100], Passed time:[22.909/526.903]
learning rate: 0.1
Batch [0/352] training loss = 0.1520, training acc = 0.95
Batch [200/352] training loss = 0.1549, training acc = 0.95
Valid Test with nat
Test accuracy: 87.64% (4382/5000), Test loss:0.3939
Epoch [24/100], Passed time:[22.876/549.015]
learning rate: 0.1
Batch [0/352] training loss = 0.1432, training acc = 0.94
Batch [200/352] training loss = 0.1866, training acc = 0.94
Valid Test with nat
Test accuracy: 88.00% (4400/5000), Test loss:0.4119
Epoch [25/100], Passed time:[22.867/571.677]
learning rate: 0.1
Batch [0/352] training loss = 0.0658, training acc = 0.98
Batch [200/352] training loss = 0.2687, training acc = 0.89
Valid Test with nat
Test accuracy: 84.60% (4230/5000), Test loss:0.5660
Epoch [26/100], Passed time:[22.828/593.520]
learning rate: 0.1
Batch [0/352] training loss = 0.1726, training acc = 0.95
Batch [200/352] training loss = 0.1811, training acc = 0.94
Valid Test with nat
Test accuracy: 84.68% (4234/5000), Test loss:0.5738
Epoch [27/100], Passed time:[22.821/616.159]
learning rate: 0.1
Batch [0/352] training loss = 0.2138, training acc = 0.91
Batch [200/352] training loss = 0.0867, training acc = 0.98
Valid Test with nat
Test accuracy: 87.08% (4354/5000), Test loss:0.4555
Epoch [28/100], Passed time:[22.812/638.739]
learning rate: 0.1
Batch [0/352] training loss = 0.2233, training acc = 0.91
Batch [200/352] training loss = 0.1662, training acc = 0.93
Valid Test with nat
Test accuracy: 86.84% (4342/5000), Test loss:0.4875
Epoch [29/100], Passed time:[22.806/661.385]
learning rate: 0.1
Batch [0/352] training loss = 0.1978, training acc = 0.93
Batch [200/352] training loss = 0.2148, training acc = 0.94
Valid Test with nat
Test accuracy: 87.06% (4353/5000), Test loss:0.4780
Epoch [30/100], Passed time:[22.805/684.138]
learning rate: 0.1
Batch [0/352] training loss = 0.1025, training acc = 0.98
Batch [200/352] training loss = 0.2874, training acc = 0.88
Valid Test with nat
Test accuracy: 86.22% (4311/5000), Test loss:0.5115
Epoch [31/100], Passed time:[22.786/706.370]
learning rate: 0.1
Batch [0/352] training loss = 0.3004, training acc = 0.90
Batch [200/352] training loss = 0.1810, training acc = 0.95
Valid Test with nat
Test accuracy: 88.60% (4430/5000), Test loss:0.4075
Epoch [32/100], Passed time:[22.771/728.672]
learning rate: 0.1
Batch [0/352] training loss = 0.2318, training acc = 0.95
Batch [200/352] training loss = 0.1908, training acc = 0.91
Valid Test with nat
Test accuracy: 88.08% (4404/5000), Test loss:0.3893
Epoch [33/100], Passed time:[22.771/751.443]
learning rate: 0.1
Batch [0/352] training loss = 0.2045, training acc = 0.91
Batch [200/352] training loss = 0.2449, training acc = 0.92
Valid Test with nat
Test accuracy: 87.60% (4380/5000), Test loss:0.4139
Epoch [34/100], Passed time:[22.763/773.929]
learning rate: 0.1
Batch [0/352] training loss = 0.1810, training acc = 0.95
Batch [200/352] training loss = 0.2366, training acc = 0.94
Valid Test with nat
Test accuracy: 86.30% (4315/5000), Test loss:0.5306
Epoch [35/100], Passed time:[22.743/796.009]
learning rate: 0.1
Batch [0/352] training loss = 0.1769, training acc = 0.94
Batch [200/352] training loss = 0.3204, training acc = 0.90
Valid Test with nat
Test accuracy: 88.88% (4444/5000), Test loss:0.4153
Epoch [36/100], Passed time:[22.734/818.413]
learning rate: 0.1
Batch [0/352] training loss = 0.1893, training acc = 0.94
Batch [200/352] training loss = 0.2199, training acc = 0.91
Valid Test with nat
Test accuracy: 86.86% (4343/5000), Test loss:0.4712
Epoch [37/100], Passed time:[22.744/841.521]
learning rate: 0.1
Batch [0/352] training loss = 0.1967, training acc = 0.94
Batch [200/352] training loss = 0.2416, training acc = 0.92
Valid Test with nat
Test accuracy: 87.98% (4399/5000), Test loss:0.4082
Epoch [38/100], Passed time:[22.739/864.090]
learning rate: 0.1
Batch [0/352] training loss = 0.1768, training acc = 0.94
Batch [200/352] training loss = 0.2690, training acc = 0.91
Valid Test with nat
Test accuracy: 88.92% (4446/5000), Test loss:0.4481
Epoch [39/100], Passed time:[22.722/886.152]
learning rate: 0.1
Batch [0/352] training loss = 0.1181, training acc = 0.95
Batch [200/352] training loss = 0.1615, training acc = 0.96
Valid Test with nat
Test accuracy: 87.44% (4372/5000), Test loss:0.4393
Epoch [40/100], Passed time:[22.717/908.689]
learning rate: 0.1
Batch [0/352] training loss = 0.1678, training acc = 0.95
Batch [200/352] training loss = 0.1870, training acc = 0.93
Valid Test with nat
Test accuracy: 86.36% (4318/5000), Test loss:0.5311
Epoch [41/100], Passed time:[22.715/931.321]
learning rate: 0.1
Batch [0/352] training loss = 0.1133, training acc = 0.95
Batch [200/352] training loss = 0.2293, training acc = 0.91
Valid Test with nat
Test accuracy: 89.10% (4455/5000), Test loss:0.3543
Best model so far saved in ./trained_models_new/cifar/wideresnet_34_2/nat/pruned1_epoch100_r80/init_pure/init_enhance_m0.05_warmup0.1.pth
Test on test set:
Test accuracy: 89.00% (8900/10000), Test loss:0.3701
Epoch [42/100], Passed time:[22.740/955.062]
learning rate: 0.1
Batch [0/352] training loss = 0.1533, training acc = 0.94
Batch [200/352] training loss = 0.2389, training acc = 0.91
Valid Test with nat
Test accuracy: 83.04% (4152/5000), Test loss:0.6147
Epoch [43/100], Passed time:[22.733/977.516]
learning rate: 0.1
Batch [0/352] training loss = 0.1334, training acc = 0.96
Batch [200/352] training loss = 0.2506, training acc = 0.91
Valid Test with nat
Test accuracy: 87.36% (4368/5000), Test loss:0.4626
Epoch [44/100], Passed time:[22.730/1000.106]
learning rate: 0.1
Batch [0/352] training loss = 0.0891, training acc = 0.98
Batch [200/352] training loss = 0.2611, training acc = 0.90
Valid Test with nat
Test accuracy: 86.94% (4347/5000), Test loss:0.5052
Epoch [45/100], Passed time:[22.725/1022.635]
learning rate: 0.1
Batch [0/352] training loss = 0.1900, training acc = 0.95
Batch [200/352] training loss = 0.2422, training acc = 0.91
Valid Test with nat
Test accuracy: 88.60% (4430/5000), Test loss:0.3690
Epoch [46/100], Passed time:[22.722/1045.217]
learning rate: 0.1
Batch [0/352] training loss = 0.1404, training acc = 0.95
Batch [200/352] training loss = 0.1568, training acc = 0.96
Valid Test with nat
Test accuracy: 84.88% (4244/5000), Test loss:0.5568
Epoch [47/100], Passed time:[22.712/1067.459]
learning rate: 0.1
Batch [0/352] training loss = 0.1812, training acc = 0.95
Batch [200/352] training loss = 0.1626, training acc = 0.95
Valid Test with nat
Test accuracy: 89.66% (4483/5000), Test loss:0.3631
Epoch [48/100], Passed time:[22.704/1089.785]
learning rate: 0.1
Batch [0/352] training loss = 0.1585, training acc = 0.95
Batch [200/352] training loss = 0.2178, training acc = 0.95
Valid Test with nat
Test accuracy: 87.80% (4390/5000), Test loss:0.4244
Epoch [49/100], Passed time:[22.700/1112.295]
learning rate: 0.1
Batch [0/352] training loss = 0.1088, training acc = 0.96
Batch [200/352] training loss = 0.1166, training acc = 0.95
Valid Test with nat
Test accuracy: 86.80% (4340/5000), Test loss:0.5323
Epoch [50/100], Passed time:[22.690/1134.516]
learning rate: 0.010000000000000002
Batch [0/352] training loss = 0.2365, training acc = 0.90
Batch [200/352] training loss = 0.1039, training acc = 0.96
Valid Test with nat
Test accuracy: 92.14% (4607/5000), Test loss:0.2773
Best model so far saved in ./trained_models_new/cifar/wideresnet_34_2/nat/pruned1_epoch100_r80/init_pure/init_enhance_m0.05_warmup0.1.pth
Test on test set:
Test accuracy: 91.88% (9188/10000), Test loss:0.2821
Epoch [51/100], Passed time:[22.712/1158.295]
learning rate: 0.010000000000000002
Batch [0/352] training loss = 0.1029, training acc = 0.95
Batch [200/352] training loss = 0.1527, training acc = 0.95
Valid Test with nat
Test accuracy: 92.52% (4626/5000), Test loss:0.2617
Best model so far saved in ./trained_models_new/cifar/wideresnet_34_2/nat/pruned1_epoch100_r80/init_pure/init_enhance_m0.05_warmup0.1.pth
Test on test set:
Test accuracy: 91.98% (9198/10000), Test loss:0.2863
Epoch [52/100], Passed time:[22.741/1182.545]
learning rate: 0.010000000000000002
Batch [0/352] training loss = 0.1298, training acc = 0.95
Batch [200/352] training loss = 0.0512, training acc = 0.98
Valid Test with nat
Test accuracy: 92.30% (4615/5000), Test loss:0.2741
Epoch [53/100], Passed time:[22.737/1205.064]
learning rate: 0.010000000000000002
Batch [0/352] training loss = 0.0643, training acc = 0.97
Batch [200/352] training loss = 0.1233, training acc = 0.96
Valid Test with nat
Test accuracy: 92.44% (4622/5000), Test loss:0.2721
Epoch [54/100], Passed time:[22.743/1228.147]
learning rate: 0.010000000000000002
Batch [0/352] training loss = 0.0751, training acc = 0.97
Batch [200/352] training loss = 0.0303, training acc = 1.00
Valid Test with nat
Test accuracy: 92.48% (4624/5000), Test loss:0.2681
Epoch [55/100], Passed time:[22.735/1250.436]
learning rate: 0.010000000000000002
Batch [0/352] training loss = 0.0684, training acc = 0.98
Batch [200/352] training loss = 0.0686, training acc = 0.97
Valid Test with nat
Test accuracy: 92.50% (4625/5000), Test loss:0.2790
Epoch [56/100], Passed time:[22.723/1272.475]
learning rate: 0.010000000000000002
Batch [0/352] training loss = 0.0463, training acc = 0.98
Batch [200/352] training loss = 0.1050, training acc = 0.98
Valid Test with nat
Test accuracy: 92.32% (4616/5000), Test loss:0.2808
Epoch [57/100], Passed time:[22.721/1295.069]
learning rate: 0.010000000000000002
Batch [0/352] training loss = 0.1398, training acc = 0.95
Batch [200/352] training loss = 0.0445, training acc = 0.99
Valid Test with nat
Test accuracy: 92.54% (4627/5000), Test loss:0.2771
Epoch [58/100], Passed time:[22.706/1316.975]
learning rate: 0.010000000000000002
Batch [0/352] training loss = 0.0239, training acc = 1.00
Batch [200/352] training loss = 0.0628, training acc = 0.97
Valid Test with nat
Test accuracy: 92.20% (4610/5000), Test loss:0.2878
Epoch [59/100], Passed time:[22.698/1339.178]
learning rate: 0.010000000000000002
Batch [0/352] training loss = 0.0509, training acc = 0.97
Batch [200/352] training loss = 0.0251, training acc = 0.99
Valid Test with nat
Test accuracy: 92.16% (4608/5000), Test loss:0.2873
Epoch [60/100], Passed time:[22.697/1361.795]
learning rate: 0.010000000000000002
Batch [0/352] training loss = 0.0270, training acc = 0.99
Batch [200/352] training loss = 0.0492, training acc = 0.99
Valid Test with nat
Test accuracy: 92.74% (4637/5000), Test loss:0.2777
Epoch [61/100], Passed time:[22.691/1384.172]
learning rate: 0.010000000000000002
Batch [0/352] training loss = 0.0281, training acc = 1.00
Batch [200/352] training loss = 0.0480, training acc = 0.98
Valid Test with nat
Test accuracy: 92.66% (4633/5000), Test loss:0.2892
Epoch [62/100], Passed time:[22.701/1407.447]
learning rate: 0.010000000000000002
Batch [0/352] training loss = 0.0190, training acc = 0.99
Batch [200/352] training loss = 0.0577, training acc = 0.96
Valid Test with nat
Test accuracy: 92.30% (4615/5000), Test loss:0.3443
Epoch [63/100], Passed time:[22.693/1429.663]
learning rate: 0.010000000000000002
Batch [0/352] training loss = 0.0199, training acc = 0.99
Batch [200/352] training loss = 0.0581, training acc = 0.98
Valid Test with nat
Test accuracy: 92.46% (4623/5000), Test loss:0.2962
Epoch [64/100], Passed time:[22.684/1451.758]
learning rate: 0.010000000000000002
Batch [0/352] training loss = 0.0218, training acc = 0.99
Batch [200/352] training loss = 0.0749, training acc = 0.98
Valid Test with nat
Test accuracy: 92.56% (4628/5000), Test loss:0.3098
Epoch [65/100], Passed time:[22.681/1474.283]
learning rate: 0.010000000000000002
Batch [0/352] training loss = 0.0495, training acc = 0.98
Batch [200/352] training loss = 0.0357, training acc = 0.99
Valid Test with nat
Test accuracy: 92.64% (4632/5000), Test loss:0.2820
Epoch [66/100], Passed time:[22.676/1496.602]
learning rate: 0.010000000000000002
Batch [0/352] training loss = 0.0151, training acc = 1.00
Batch [200/352] training loss = 0.0743, training acc = 0.98
Valid Test with nat
Test accuracy: 92.36% (4618/5000), Test loss:0.3139
Epoch [67/100], Passed time:[22.667/1518.719]
learning rate: 0.010000000000000002
Batch [0/352] training loss = 0.0211, training acc = 0.99
Batch [200/352] training loss = 0.0422, training acc = 0.99
Valid Test with nat
Test accuracy: 92.88% (4644/5000), Test loss:0.3018
Epoch [68/100], Passed time:[22.670/1541.558]
learning rate: 0.010000000000000002
Batch [0/352] training loss = 0.0562, training acc = 0.98
Batch [200/352] training loss = 0.0828, training acc = 0.97
Valid Test with nat
Test accuracy: 92.62% (4631/5000), Test loss:0.2926
Epoch [69/100], Passed time:[22.672/1564.351]
learning rate: 0.010000000000000002
Batch [0/352] training loss = 0.0125, training acc = 1.00
Batch [200/352] training loss = 0.0505, training acc = 0.98
Valid Test with nat
Test accuracy: 92.72% (4636/5000), Test loss:0.3104
Epoch [70/100], Passed time:[22.676/1587.298]
learning rate: 0.010000000000000002
Batch [0/352] training loss = 0.0163, training acc = 1.00
Batch [200/352] training loss = 0.0654, training acc = 0.98
Valid Test with nat
Test accuracy: 92.64% (4632/5000), Test loss:0.3059
Epoch [71/100], Passed time:[22.666/1609.253]
learning rate: 0.010000000000000002
Batch [0/352] training loss = 0.0379, training acc = 0.98
Batch [200/352] training loss = 0.0228, training acc = 0.99
Valid Test with nat
Test accuracy: 92.54% (4627/5000), Test loss:0.3070
Epoch [72/100], Passed time:[22.659/1631.442]
learning rate: 0.010000000000000002
Batch [0/352] training loss = 0.0136, training acc = 1.00
Batch [200/352] training loss = 0.0350, training acc = 0.98
Valid Test with nat
Test accuracy: 92.80% (4640/5000), Test loss:0.3064
Epoch [73/100], Passed time:[22.663/1654.422]
learning rate: 0.010000000000000002
Batch [0/352] training loss = 0.0444, training acc = 0.99
Batch [200/352] training loss = 0.0489, training acc = 0.98
Valid Test with nat
Test accuracy: 92.72% (4636/5000), Test loss:0.3093
Epoch [74/100], Passed time:[22.658/1676.688]
learning rate: 0.010000000000000002
Batch [0/352] training loss = 0.0172, training acc = 0.99
Batch [200/352] training loss = 0.0700, training acc = 0.97
Valid Test with nat
Test accuracy: 92.60% (4630/5000), Test loss:0.3046
Epoch [75/100], Passed time:[22.655/1699.102]
learning rate: 0.0010000000000000002
Batch [0/352] training loss = 0.0497, training acc = 0.99
Batch [200/352] training loss = 0.0112, training acc = 0.99
Valid Test with nat
Test accuracy: 93.08% (4654/5000), Test loss:0.3029
Epoch [76/100], Passed time:[22.656/1721.836]
learning rate: 0.0010000000000000002
Batch [0/352] training loss = 0.0413, training acc = 0.98
Batch [200/352] training loss = 0.0364, training acc = 0.99
Valid Test with nat
Test accuracy: 92.92% (4646/5000), Test loss:0.3110
Epoch [77/100], Passed time:[22.649/1743.968]
learning rate: 0.0010000000000000002
Batch [0/352] training loss = 0.0312, training acc = 0.98
Batch [200/352] training loss = 0.0319, training acc = 0.99
Valid Test with nat
Test accuracy: 92.82% (4641/5000), Test loss:0.3042
Epoch [78/100], Passed time:[22.653/1766.942]
learning rate: 0.0010000000000000002
Batch [0/352] training loss = 0.0098, training acc = 1.00
Batch [200/352] training loss = 0.0099, training acc = 1.00
Valid Test with nat
Test accuracy: 92.82% (4641/5000), Test loss:0.3136
Epoch [79/100], Passed time:[22.673/1791.162]
learning rate: 0.0010000000000000002
Batch [0/352] training loss = 0.0360, training acc = 0.98
Batch [200/352] training loss = 0.0272, training acc = 0.98
Valid Test with nat
Test accuracy: 92.78% (4639/5000), Test loss:0.2998
Epoch [80/100], Passed time:[22.774/1821.952]
learning rate: 0.0010000000000000002
Batch [0/352] training loss = 0.0365, training acc = 0.98
Batch [200/352] training loss = 0.0305, training acc = 0.98
Valid Test with nat
Test accuracy: 92.94% (4647/5000), Test loss:0.3006
Epoch [81/100], Passed time:[22.887/1853.883]
learning rate: 0.0010000000000000002
Batch [0/352] training loss = 0.0235, training acc = 1.00
Batch [200/352] training loss = 0.0396, training acc = 0.98
Valid Test with nat
Test accuracy: 92.88% (4644/5000), Test loss:0.3052
Epoch [82/100], Passed time:[22.992/1885.320]
learning rate: 0.0010000000000000002
Batch [0/352] training loss = 0.0657, training acc = 0.98
Batch [200/352] training loss = 0.0499, training acc = 0.98
Valid Test with nat
Test accuracy: 92.82% (4641/5000), Test loss:0.2993
Epoch [83/100], Passed time:[23.101/1917.359]
learning rate: 0.0010000000000000002
Batch [0/352] training loss = 0.0344, training acc = 0.98
Batch [200/352] training loss = 0.0280, training acc = 0.99
Valid Test with nat
Test accuracy: 92.80% (4640/5000), Test loss:0.3299
Epoch [84/100], Passed time:[23.217/1950.263]
learning rate: 0.0010000000000000002
Batch [0/352] training loss = 0.0367, training acc = 0.99
Batch [200/352] training loss = 0.0262, training acc = 0.99
Valid Test with nat
Test accuracy: 92.80% (4640/5000), Test loss:0.3154
Epoch [85/100], Passed time:[23.327/1982.826]
learning rate: 0.0010000000000000002
Batch [0/352] training loss = 0.0612, training acc = 0.98
Batch [200/352] training loss = 0.0316, training acc = 0.99
Valid Test with nat
Test accuracy: 92.92% (4646/5000), Test loss:0.3014
Epoch [86/100], Passed time:[23.425/2014.509]
learning rate: 0.0010000000000000002
Batch [0/352] training loss = 0.0246, training acc = 0.99
Batch [200/352] training loss = 0.0350, training acc = 0.98
Valid Test with nat
Test accuracy: 92.84% (4642/5000), Test loss:0.3085
Epoch [87/100], Passed time:[23.518/2046.058]
learning rate: 0.0010000000000000002
Batch [0/352] training loss = 0.0519, training acc = 0.98
Batch [200/352] training loss = 0.0145, training acc = 1.00
Valid Test with nat
Test accuracy: 92.80% (4640/5000), Test loss:0.3027
Epoch [88/100], Passed time:[23.611/2077.752]
learning rate: 0.0010000000000000002
Batch [0/352] training loss = 0.0564, training acc = 0.98
Batch [200/352] training loss = 0.0671, training acc = 0.98
Valid Test with nat
Test accuracy: 92.76% (4638/5000), Test loss:0.2991
Epoch [89/100], Passed time:[23.710/2110.199]
learning rate: 0.0010000000000000002
Batch [0/352] training loss = 0.0273, training acc = 0.99
Batch [200/352] training loss = 0.0443, training acc = 0.98
Valid Test with nat
Test accuracy: 92.82% (4641/5000), Test loss:0.3269
Epoch [90/100], Passed time:[23.818/2143.665]
learning rate: 0.0010000000000000002
Batch [0/352] training loss = 0.0547, training acc = 0.98
Batch [200/352] training loss = 0.0514, training acc = 0.98
Valid Test with nat
Test accuracy: 93.02% (4651/5000), Test loss:0.3035
Epoch [91/100], Passed time:[23.913/2176.114]
learning rate: 0.0010000000000000002
Batch [0/352] training loss = 0.0422, training acc = 0.98
Batch [200/352] training loss = 0.0300, training acc = 0.99
Valid Test with nat
Test accuracy: 92.90% (4645/5000), Test loss:0.3013
Epoch [92/100], Passed time:[23.998/2207.810]
learning rate: 0.0010000000000000002
Batch [0/352] training loss = 0.0275, training acc = 0.98
Batch [200/352] training loss = 0.0152, training acc = 1.00
Valid Test with nat
Test accuracy: 92.92% (4646/5000), Test loss:0.3314
Epoch [93/100], Passed time:[24.080/2239.414]
learning rate: 0.0010000000000000002
Batch [0/352] training loss = 0.0480, training acc = 0.98
Batch [200/352] training loss = 0.0202, training acc = 0.99
Valid Test with nat
Test accuracy: 92.74% (4637/5000), Test loss:0.3023
Epoch [94/100], Passed time:[24.168/2271.757]
learning rate: 0.0010000000000000002
Batch [0/352] training loss = 0.0989, training acc = 0.96
Batch [200/352] training loss = 0.0323, training acc = 0.98
Valid Test with nat
Test accuracy: 92.86% (4643/5000), Test loss:0.3024
Epoch [95/100], Passed time:[24.268/2305.430]
learning rate: 0.0010000000000000002
Batch [0/352] training loss = 0.0110, training acc = 1.00
Batch [200/352] training loss = 0.0171, training acc = 0.99
Valid Test with nat
Test accuracy: 92.88% (4644/5000), Test loss:0.3168
Epoch [96/100], Passed time:[24.358/2338.399]
learning rate: 0.0010000000000000002
Batch [0/352] training loss = 0.0386, training acc = 0.98
Batch [200/352] training loss = 0.0159, training acc = 1.00
Valid Test with nat
Test accuracy: 92.78% (4639/5000), Test loss:0.3031
Epoch [97/100], Passed time:[24.447/2371.338]
learning rate: 0.0010000000000000002
Batch [0/352] training loss = 0.0336, training acc = 0.98
Batch [200/352] training loss = 0.0373, training acc = 0.98
Valid Test with nat
Test accuracy: 92.74% (4637/5000), Test loss:0.3100
Epoch [98/100], Passed time:[24.538/2404.753]
learning rate: 0.0010000000000000002
Batch [0/352] training loss = 0.0204, training acc = 0.99
Batch [200/352] training loss = 0.0286, training acc = 0.99
Valid Test with nat
Test accuracy: 92.88% (4644/5000), Test loss:0.3186
Epoch [99/100], Passed time:[24.622/2437.613]
learning rate: 0.0010000000000000002
Batch [0/352] training loss = 0.0275, training acc = 0.99
Batch [200/352] training loss = 0.0142, training acc = 0.99
Valid Test with nat
Test accuracy: 92.84% (4642/5000), Test loss:0.3051
Training done, model saved in ./trained_models_new/cifar/wideresnet_34_2/nat/pruned1_epoch100_r80/init_pure/init_enhance_m0.05_warmup0.1.pth
Test on test set:
Test accuracy: 92.66% (9266/10000), Test loss:0.3395
